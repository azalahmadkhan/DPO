{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.87936,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0064,
      "grad_norm": 7.8004679679870605,
      "learning_rate": 8.510638297872341e-06,
      "logits/chosen": -11.459388732910156,
      "logits/rejected": -12.308486938476562,
      "logps/chosen": -76.03191375732422,
      "logps/rejected": -78.4967269897461,
      "loss": 1.8319,
      "rewards/accuracies": 0.4046874940395355,
      "rewards/chosen": -0.008286922238767147,
      "rewards/margins": 0.0007601666147820652,
      "rewards/rejected": -0.009047090075910091,
      "step": 10
    },
    {
      "epoch": 0.0128,
      "grad_norm": 7.174546718597412,
      "learning_rate": 1.7021276595744682e-05,
      "logits/chosen": -11.230249404907227,
      "logits/rejected": -10.961506843566895,
      "logps/chosen": -78.06494903564453,
      "logps/rejected": -75.63517761230469,
      "loss": 1.8068,
      "rewards/accuracies": 0.5406249761581421,
      "rewards/chosen": 0.004275868646800518,
      "rewards/margins": 0.017346855252981186,
      "rewards/rejected": -0.013070985674858093,
      "step": 20
    },
    {
      "epoch": 0.0192,
      "grad_norm": 7.543515205383301,
      "learning_rate": 2.5531914893617022e-05,
      "logits/chosen": -9.335143089294434,
      "logits/rejected": -9.74752426147461,
      "logps/chosen": -77.07172393798828,
      "logps/rejected": -81.79060363769531,
      "loss": 1.8074,
      "rewards/accuracies": 0.5328124761581421,
      "rewards/chosen": -0.06034268066287041,
      "rewards/margins": 0.011414761655032635,
      "rewards/rejected": -0.07175743579864502,
      "step": 30
    },
    {
      "epoch": 0.0256,
      "grad_norm": 7.739124774932861,
      "learning_rate": 3.4042553191489365e-05,
      "logits/chosen": -8.74012565612793,
      "logits/rejected": -8.725939750671387,
      "logps/chosen": -79.7139663696289,
      "logps/rejected": -80.59090423583984,
      "loss": 1.8954,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -0.22849325835704803,
      "rewards/margins": -0.007524068467319012,
      "rewards/rejected": -0.22096917033195496,
      "step": 40
    },
    {
      "epoch": 0.032,
      "grad_norm": 7.125268459320068,
      "learning_rate": 4.2553191489361704e-05,
      "logits/chosen": -11.615299224853516,
      "logits/rejected": -12.901741027832031,
      "logps/chosen": -77.98541259765625,
      "logps/rejected": -80.45976257324219,
      "loss": 1.8617,
      "rewards/accuracies": 0.535937488079071,
      "rewards/chosen": -0.17232120037078857,
      "rewards/margins": 0.05019044131040573,
      "rewards/rejected": -0.22251161932945251,
      "step": 50
    },
    {
      "epoch": 0.0384,
      "grad_norm": 8.244085311889648,
      "learning_rate": 5.1063829787234044e-05,
      "logits/chosen": -12.627859115600586,
      "logits/rejected": -13.196409225463867,
      "logps/chosen": -77.65972137451172,
      "logps/rejected": -79.80516052246094,
      "loss": 1.8874,
      "rewards/accuracies": 0.5171874761581421,
      "rewards/chosen": -0.3121097683906555,
      "rewards/margins": 0.04679636284708977,
      "rewards/rejected": -0.3589061200618744,
      "step": 60
    },
    {
      "epoch": 0.0448,
      "grad_norm": 8.791929244995117,
      "learning_rate": 5.9574468085106384e-05,
      "logits/chosen": -11.337431907653809,
      "logits/rejected": -12.19059944152832,
      "logps/chosen": -78.95246887207031,
      "logps/rejected": -82.63225555419922,
      "loss": 1.9018,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -0.5789386034011841,
      "rewards/margins": 0.05962610989809036,
      "rewards/rejected": -0.6385647058486938,
      "step": 70
    },
    {
      "epoch": 0.0512,
      "grad_norm": 9.546869277954102,
      "learning_rate": 6.808510638297873e-05,
      "logits/chosen": -12.779312133789062,
      "logits/rejected": -13.220044136047363,
      "logps/chosen": -84.57601928710938,
      "logps/rejected": -81.83634185791016,
      "loss": 1.9361,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -0.6881511807441711,
      "rewards/margins": 0.045768093317747116,
      "rewards/rejected": -0.7339192628860474,
      "step": 80
    },
    {
      "epoch": 0.0576,
      "grad_norm": 6.577422142028809,
      "learning_rate": 7.659574468085106e-05,
      "logits/chosen": -10.559528350830078,
      "logits/rejected": -11.426776885986328,
      "logps/chosen": -82.53303527832031,
      "logps/rejected": -84.55938720703125,
      "loss": 1.8195,
      "rewards/accuracies": 0.5171874761581421,
      "rewards/chosen": -0.6168731451034546,
      "rewards/margins": 0.09215305745601654,
      "rewards/rejected": -0.7090262174606323,
      "step": 90
    },
    {
      "epoch": 0.064,
      "grad_norm": 6.845731735229492,
      "learning_rate": 8.510638297872341e-05,
      "logits/chosen": -16.200674057006836,
      "logits/rejected": -16.85662269592285,
      "logps/chosen": -82.73394775390625,
      "logps/rejected": -86.77546691894531,
      "loss": 1.8784,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -0.7978262901306152,
      "rewards/margins": 0.13116782903671265,
      "rewards/rejected": -0.9289940595626831,
      "step": 100
    },
    {
      "epoch": 0.0704,
      "grad_norm": 6.447977542877197,
      "learning_rate": 9.361702127659576e-05,
      "logits/chosen": -22.471954345703125,
      "logits/rejected": -23.158491134643555,
      "logps/chosen": -86.5622787475586,
      "logps/rejected": -89.70335388183594,
      "loss": 1.9002,
      "rewards/accuracies": 0.526562511920929,
      "rewards/chosen": -1.1179147958755493,
      "rewards/margins": 0.0532926507294178,
      "rewards/rejected": -1.1712071895599365,
      "step": 110
    },
    {
      "epoch": 0.0768,
      "grad_norm": 7.723550319671631,
      "learning_rate": 0.00010212765957446809,
      "logits/chosen": -20.79469871520996,
      "logits/rejected": -21.553546905517578,
      "logps/chosen": -83.49109649658203,
      "logps/rejected": -89.25755310058594,
      "loss": 1.8786,
      "rewards/accuracies": 0.5390625,
      "rewards/chosen": -1.0935494899749756,
      "rewards/margins": 0.08047603070735931,
      "rewards/rejected": -1.174025535583496,
      "step": 120
    },
    {
      "epoch": 0.0832,
      "grad_norm": 7.186120986938477,
      "learning_rate": 0.00011063829787234043,
      "logits/chosen": -17.99892807006836,
      "logits/rejected": -18.528095245361328,
      "logps/chosen": -90.0219955444336,
      "logps/rejected": -90.98796081542969,
      "loss": 1.9882,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": -1.3668725490570068,
      "rewards/margins": 0.03863837942481041,
      "rewards/rejected": -1.4055111408233643,
      "step": 130
    },
    {
      "epoch": 0.0896,
      "grad_norm": 6.906707286834717,
      "learning_rate": 0.00011914893617021277,
      "logits/chosen": -15.693655014038086,
      "logits/rejected": -16.259246826171875,
      "logps/chosen": -92.43582153320312,
      "logps/rejected": -93.29813385009766,
      "loss": 2.1145,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -1.6068979501724243,
      "rewards/margins": -0.009223252534866333,
      "rewards/rejected": -1.5976746082305908,
      "step": 140
    },
    {
      "epoch": 0.096,
      "grad_norm": 7.135695934295654,
      "learning_rate": 0.00012765957446808513,
      "logits/chosen": -12.586740493774414,
      "logits/rejected": -13.555981636047363,
      "logps/chosen": -92.44515991210938,
      "logps/rejected": -95.81991577148438,
      "loss": 2.0692,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -1.7582298517227173,
      "rewards/margins": 0.07242835313081741,
      "rewards/rejected": -1.8306583166122437,
      "step": 150
    },
    {
      "epoch": 0.1024,
      "grad_norm": 6.526954650878906,
      "learning_rate": 0.00013617021276595746,
      "logits/chosen": -13.854043960571289,
      "logits/rejected": -14.315755844116211,
      "logps/chosen": -93.67269134521484,
      "logps/rejected": -96.27054595947266,
      "loss": 2.0541,
      "rewards/accuracies": 0.5328124761581421,
      "rewards/chosen": -1.7017837762832642,
      "rewards/margins": 0.08408663421869278,
      "rewards/rejected": -1.7858703136444092,
      "step": 160
    },
    {
      "epoch": 0.1088,
      "grad_norm": 7.097743511199951,
      "learning_rate": 0.0001446808510638298,
      "logits/chosen": -15.536972045898438,
      "logits/rejected": -15.997736930847168,
      "logps/chosen": -92.2611083984375,
      "logps/rejected": -98.55390167236328,
      "loss": 2.1262,
      "rewards/accuracies": 0.5015624761581421,
      "rewards/chosen": -1.9552192687988281,
      "rewards/margins": 0.024202000349760056,
      "rewards/rejected": -1.9794212579727173,
      "step": 170
    },
    {
      "epoch": 0.1152,
      "grad_norm": 5.96502685546875,
      "learning_rate": 0.00015319148936170213,
      "logits/chosen": -21.83175277709961,
      "logits/rejected": -21.966949462890625,
      "logps/chosen": -99.22178649902344,
      "logps/rejected": -101.28031921386719,
      "loss": 2.0279,
      "rewards/accuracies": 0.5296875238418579,
      "rewards/chosen": -2.462470531463623,
      "rewards/margins": 0.14614221453666687,
      "rewards/rejected": -2.608612537384033,
      "step": 180
    },
    {
      "epoch": 0.1216,
      "grad_norm": 5.500585079193115,
      "learning_rate": 0.00016170212765957446,
      "logits/chosen": -14.62468433380127,
      "logits/rejected": -16.009326934814453,
      "logps/chosen": -103.99395751953125,
      "logps/rejected": -107.33735656738281,
      "loss": 2.0511,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": -2.81589412689209,
      "rewards/margins": 0.10312479734420776,
      "rewards/rejected": -2.9190189838409424,
      "step": 190
    },
    {
      "epoch": 0.128,
      "grad_norm": 8.185760498046875,
      "learning_rate": 0.00017021276595744682,
      "logits/chosen": -8.369461059570312,
      "logits/rejected": -8.60525131225586,
      "logps/chosen": -106.19084167480469,
      "logps/rejected": -106.73161315917969,
      "loss": 2.1325,
      "rewards/accuracies": 0.4984374940395355,
      "rewards/chosen": -3.0325376987457275,
      "rewards/margins": -0.02011100947856903,
      "rewards/rejected": -3.0124268531799316,
      "step": 200
    },
    {
      "epoch": 0.1344,
      "grad_norm": 8.326458930969238,
      "learning_rate": 0.00017872340425531915,
      "logits/chosen": -12.087959289550781,
      "logits/rejected": -12.275687217712402,
      "logps/chosen": -108.48265075683594,
      "logps/rejected": -109.8548812866211,
      "loss": 2.0673,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -3.2911887168884277,
      "rewards/margins": 0.12358205020427704,
      "rewards/rejected": -3.414771318435669,
      "step": 210
    },
    {
      "epoch": 0.1408,
      "grad_norm": 6.919588565826416,
      "learning_rate": 0.0001872340425531915,
      "logits/chosen": -17.183759689331055,
      "logits/rejected": -17.16450309753418,
      "logps/chosen": -108.1689682006836,
      "logps/rejected": -112.55792236328125,
      "loss": 2.2002,
      "rewards/accuracies": 0.528124988079071,
      "rewards/chosen": -3.2888526916503906,
      "rewards/margins": 0.13686498999595642,
      "rewards/rejected": -3.425717830657959,
      "step": 220
    },
    {
      "epoch": 0.1472,
      "grad_norm": 6.7186808586120605,
      "learning_rate": 0.00019574468085106384,
      "logits/chosen": -10.688310623168945,
      "logits/rejected": -11.114250183105469,
      "logps/chosen": -111.86962890625,
      "logps/rejected": -116.05826568603516,
      "loss": 2.0437,
      "rewards/accuracies": 0.582812488079071,
      "rewards/chosen": -3.8066258430480957,
      "rewards/margins": 0.30659645795822144,
      "rewards/rejected": -4.113222122192383,
      "step": 230
    },
    {
      "epoch": 0.1536,
      "grad_norm": 7.07916259765625,
      "learning_rate": 0.00019999937727812906,
      "logits/chosen": -13.695907592773438,
      "logits/rejected": -13.715948104858398,
      "logps/chosen": -116.11518859863281,
      "logps/rejected": -120.95626068115234,
      "loss": 2.1748,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": -4.1683783531188965,
      "rewards/margins": 0.11103391647338867,
      "rewards/rejected": -4.279412269592285,
      "step": 240
    },
    {
      "epoch": 0.16,
      "grad_norm": 6.871638298034668,
      "learning_rate": 0.00019999439554969515,
      "logits/chosen": -15.168787002563477,
      "logits/rejected": -15.585054397583008,
      "logps/chosen": -118.4803237915039,
      "logps/rejected": -120.47103118896484,
      "loss": 2.2308,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -4.294334888458252,
      "rewards/margins": 0.07552085816860199,
      "rewards/rejected": -4.369855880737305,
      "step": 250
    },
    {
      "epoch": 0.1664,
      "grad_norm": 4.945406436920166,
      "learning_rate": 0.00019998443234100504,
      "logits/chosen": -15.778890609741211,
      "logits/rejected": -16.584514617919922,
      "logps/chosen": -120.68077087402344,
      "logps/rejected": -126.41374206542969,
      "loss": 2.1477,
      "rewards/accuracies": 0.5328124761581421,
      "rewards/chosen": -4.655592918395996,
      "rewards/margins": 0.2366667538881302,
      "rewards/rejected": -4.89225959777832,
      "step": 260
    },
    {
      "epoch": 0.1728,
      "grad_norm": 6.537258625030518,
      "learning_rate": 0.00019996948814840186,
      "logits/chosen": -13.676960945129395,
      "logits/rejected": -13.985410690307617,
      "logps/chosen": -118.81221008300781,
      "logps/rejected": -121.31201171875,
      "loss": 2.2748,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": -4.230830669403076,
      "rewards/margins": 0.15454648435115814,
      "rewards/rejected": -4.385377883911133,
      "step": 270
    },
    {
      "epoch": 0.1792,
      "grad_norm": 6.491273880004883,
      "learning_rate": 0.0001999495637163693,
      "logits/chosen": -17.018823623657227,
      "logits/rejected": -17.069808959960938,
      "logps/chosen": -130.62252807617188,
      "logps/rejected": -134.1787567138672,
      "loss": 2.214,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -5.482893466949463,
      "rewards/margins": 0.12797434628009796,
      "rewards/rejected": -5.610867977142334,
      "step": 280
    },
    {
      "epoch": 0.1856,
      "grad_norm": 6.00372314453125,
      "learning_rate": 0.0001999246600374947,
      "logits/chosen": -14.223672866821289,
      "logits/rejected": -14.63574504852295,
      "logps/chosen": -127.4508285522461,
      "logps/rejected": -130.40890502929688,
      "loss": 2.1722,
      "rewards/accuracies": 0.5328124761581421,
      "rewards/chosen": -5.399691581726074,
      "rewards/margins": 0.19182950258255005,
      "rewards/rejected": -5.591521263122559,
      "step": 290
    },
    {
      "epoch": 0.192,
      "grad_norm": 6.740767002105713,
      "learning_rate": 0.00019989477835241935,
      "logits/chosen": -19.314346313476562,
      "logits/rejected": -19.26157569885254,
      "logps/chosen": -129.0776824951172,
      "logps/rejected": -134.9615020751953,
      "loss": 2.2272,
      "rewards/accuracies": 0.5453125238418579,
      "rewards/chosen": -5.585552215576172,
      "rewards/margins": 0.1476650834083557,
      "rewards/rejected": -5.733217716217041,
      "step": 300
    },
    {
      "epoch": 0.1984,
      "grad_norm": 5.27039098739624,
      "learning_rate": 0.00019985992014977697,
      "logits/chosen": -18.89995765686035,
      "logits/rejected": -18.924266815185547,
      "logps/chosen": -130.31861877441406,
      "logps/rejected": -134.41702270507812,
      "loss": 2.2747,
      "rewards/accuracies": 0.5546875,
      "rewards/chosen": -5.3939104080200195,
      "rewards/margins": 0.14727343618869781,
      "rewards/rejected": -5.541184425354004,
      "step": 310
    },
    {
      "epoch": 0.2048,
      "grad_norm": 6.643387317657471,
      "learning_rate": 0.00019982008716611937,
      "logits/chosen": -11.975275039672852,
      "logits/rejected": -12.145977973937988,
      "logps/chosen": -126.5341567993164,
      "logps/rejected": -129.14712524414062,
      "loss": 2.1633,
      "rewards/accuracies": 0.5171874761581421,
      "rewards/chosen": -5.11699104309082,
      "rewards/margins": 0.17162898182868958,
      "rewards/rejected": -5.288619518280029,
      "step": 320
    },
    {
      "epoch": 0.2112,
      "grad_norm": 6.5948944091796875,
      "learning_rate": 0.00019977528138582996,
      "logits/chosen": -11.022644996643066,
      "logits/rejected": -10.890674591064453,
      "logps/chosen": -131.9832305908203,
      "logps/rejected": -135.79579162597656,
      "loss": 2.3248,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": -5.497715950012207,
      "rewards/margins": 0.05931759625673294,
      "rewards/rejected": -5.557033538818359,
      "step": 330
    },
    {
      "epoch": 0.2176,
      "grad_norm": 5.37385368347168,
      "learning_rate": 0.00019972550504102494,
      "logits/chosen": -5.940343379974365,
      "logits/rejected": -6.675148963928223,
      "logps/chosen": -133.10464477539062,
      "logps/rejected": -136.15725708007812,
      "loss": 2.187,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": -5.881710052490234,
      "rewards/margins": 0.07067815959453583,
      "rewards/rejected": -5.952387809753418,
      "step": 340
    },
    {
      "epoch": 0.224,
      "grad_norm": 5.424749374389648,
      "learning_rate": 0.0001996707606114421,
      "logits/chosen": -11.053110122680664,
      "logits/rejected": -10.943615913391113,
      "logps/chosen": -142.70294189453125,
      "logps/rejected": -144.52484130859375,
      "loss": 2.2122,
      "rewards/accuracies": 0.535937488079071,
      "rewards/chosen": -6.744719505310059,
      "rewards/margins": 0.08802387118339539,
      "rewards/rejected": -6.8327436447143555,
      "step": 350
    },
    {
      "epoch": 0.2304,
      "grad_norm": 5.332963943481445,
      "learning_rate": 0.0001996110508243172,
      "logits/chosen": -13.23888874053955,
      "logits/rejected": -13.494783401489258,
      "logps/chosen": -135.39796447753906,
      "logps/rejected": -137.09136962890625,
      "loss": 2.2397,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -5.8934006690979,
      "rewards/margins": 0.09461243450641632,
      "rewards/rejected": -5.98801326751709,
      "step": 360
    },
    {
      "epoch": 0.2368,
      "grad_norm": 5.255241394042969,
      "learning_rate": 0.00019954637865424825,
      "logits/chosen": -8.027807235717773,
      "logits/rejected": -8.152868270874023,
      "logps/chosen": -134.46463012695312,
      "logps/rejected": -138.82582092285156,
      "loss": 2.2489,
      "rewards/accuracies": 0.5390625,
      "rewards/chosen": -5.971274375915527,
      "rewards/margins": 0.15753673017024994,
      "rewards/rejected": -6.128810882568359,
      "step": 370
    },
    {
      "epoch": 0.2432,
      "grad_norm": 5.327723503112793,
      "learning_rate": 0.00019947674732304714,
      "logits/chosen": -6.677804470062256,
      "logits/rejected": -6.554234981536865,
      "logps/chosen": -142.33531188964844,
      "logps/rejected": -144.85975646972656,
      "loss": 2.2726,
      "rewards/accuracies": 0.4984374940395355,
      "rewards/chosen": -6.662171840667725,
      "rewards/margins": 0.09727209806442261,
      "rewards/rejected": -6.759443759918213,
      "step": 380
    },
    {
      "epoch": 0.2496,
      "grad_norm": 6.147292613983154,
      "learning_rate": 0.00019940216029957936,
      "logits/chosen": -8.26363754272461,
      "logits/rejected": -8.190214157104492,
      "logps/chosen": -137.78805541992188,
      "logps/rejected": -143.3493194580078,
      "loss": 2.1608,
      "rewards/accuracies": 0.546875,
      "rewards/chosen": -6.307153224945068,
      "rewards/margins": 0.2706247568130493,
      "rewards/rejected": -6.5777788162231445,
      "step": 390
    },
    {
      "epoch": 0.256,
      "grad_norm": 5.384225845336914,
      "learning_rate": 0.00019932262129959097,
      "logits/chosen": -14.845739364624023,
      "logits/rejected": -14.953781127929688,
      "logps/chosen": -140.229248046875,
      "logps/rejected": -141.5185089111328,
      "loss": 2.2972,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -6.532282829284668,
      "rewards/margins": 0.1141534075140953,
      "rewards/rejected": -6.646437168121338,
      "step": 400
    },
    {
      "epoch": 0.2624,
      "grad_norm": 5.373996257781982,
      "learning_rate": 0.00019923813428552364,
      "logits/chosen": -16.81275749206543,
      "logits/rejected": -16.987159729003906,
      "logps/chosen": -148.57382202148438,
      "logps/rejected": -149.09231567382812,
      "loss": 2.2498,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -7.24799108505249,
      "rewards/margins": 0.1582460105419159,
      "rewards/rejected": -7.4062371253967285,
      "step": 410
    },
    {
      "epoch": 0.2688,
      "grad_norm": 5.166287899017334,
      "learning_rate": 0.00019914870346631714,
      "logits/chosen": -14.834432601928711,
      "logits/rejected": -14.349645614624023,
      "logps/chosen": -147.6258087158203,
      "logps/rejected": -149.5486297607422,
      "loss": 2.1768,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -7.059144020080566,
      "rewards/margins": 0.18668393790721893,
      "rewards/rejected": -7.245827674865723,
      "step": 420
    },
    {
      "epoch": 0.2752,
      "grad_norm": 4.905771732330322,
      "learning_rate": 0.0001990543332971998,
      "logits/chosen": -15.988740921020508,
      "logits/rejected": -15.869667053222656,
      "logps/chosen": -144.21420288085938,
      "logps/rejected": -143.09390258789062,
      "loss": 2.201,
      "rewards/accuracies": 0.5296875238418579,
      "rewards/chosen": -6.6029372215271,
      "rewards/margins": 0.10149369388818741,
      "rewards/rejected": -6.704431056976318,
      "step": 430
    },
    {
      "epoch": 0.2816,
      "grad_norm": 4.237423896789551,
      "learning_rate": 0.00019895502847946643,
      "logits/chosen": -19.24428367614746,
      "logits/rejected": -19.272445678710938,
      "logps/chosen": -149.499755859375,
      "logps/rejected": -149.3072967529297,
      "loss": 2.2554,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": -7.0944318771362305,
      "rewards/margins": 0.06578187644481659,
      "rewards/rejected": -7.160214424133301,
      "step": 440
    },
    {
      "epoch": 0.288,
      "grad_norm": 5.78451681137085,
      "learning_rate": 0.0001988507939602442,
      "logits/chosen": -17.60099220275879,
      "logits/rejected": -17.876127243041992,
      "logps/chosen": -147.40574645996094,
      "logps/rejected": -149.53201293945312,
      "loss": 2.2919,
      "rewards/accuracies": 0.5140625238418579,
      "rewards/chosen": -7.2303643226623535,
      "rewards/margins": 0.04936767369508743,
      "rewards/rejected": -7.279732704162598,
      "step": 450
    },
    {
      "epoch": 0.2944,
      "grad_norm": 5.465995788574219,
      "learning_rate": 0.00019874163493224613,
      "logits/chosen": -13.73729419708252,
      "logits/rejected": -13.568153381347656,
      "logps/chosen": -145.01853942871094,
      "logps/rejected": -145.85084533691406,
      "loss": 2.3348,
      "rewards/accuracies": 0.48750001192092896,
      "rewards/chosen": -6.800295352935791,
      "rewards/margins": 0.04970135539770126,
      "rewards/rejected": -6.849997043609619,
      "step": 460
    },
    {
      "epoch": 0.3008,
      "grad_norm": 4.9218316078186035,
      "learning_rate": 0.0001986275568335124,
      "logits/chosen": -8.464105606079102,
      "logits/rejected": -8.477779388427734,
      "logps/chosen": -139.93975830078125,
      "logps/rejected": -142.385498046875,
      "loss": 2.3084,
      "rewards/accuracies": 0.4984374940395355,
      "rewards/chosen": -6.403477668762207,
      "rewards/margins": 0.08003182709217072,
      "rewards/rejected": -6.483509063720703,
      "step": 470
    },
    {
      "epoch": 0.3072,
      "grad_norm": 4.086503982543945,
      "learning_rate": 0.00019850856534713945,
      "logits/chosen": -10.642488479614258,
      "logits/rejected": -10.778980255126953,
      "logps/chosen": -141.68246459960938,
      "logps/rejected": -142.69271850585938,
      "loss": 2.2544,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": -6.515505790710449,
      "rewards/margins": 0.12055785953998566,
      "rewards/rejected": -6.636064052581787,
      "step": 480
    },
    {
      "epoch": 0.3136,
      "grad_norm": 5.812575817108154,
      "learning_rate": 0.00019838466640099698,
      "logits/chosen": -11.795984268188477,
      "logits/rejected": -11.450839042663574,
      "logps/chosen": -147.49623107910156,
      "logps/rejected": -149.49374389648438,
      "loss": 2.3036,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -7.3245439529418945,
      "rewards/margins": 0.058316636830568314,
      "rewards/rejected": -7.382859706878662,
      "step": 490
    },
    {
      "epoch": 0.32,
      "grad_norm": 4.847046375274658,
      "learning_rate": 0.0001982558661674324,
      "logits/chosen": -13.36860466003418,
      "logits/rejected": -13.439374923706055,
      "logps/chosen": -145.3318328857422,
      "logps/rejected": -148.19638061523438,
      "loss": 2.3326,
      "rewards/accuracies": 0.5328124761581421,
      "rewards/chosen": -7.017112731933594,
      "rewards/margins": 0.168993279337883,
      "rewards/rejected": -7.186106204986572,
      "step": 500
    },
    {
      "epoch": 0.3264,
      "grad_norm": 5.617142200469971,
      "learning_rate": 0.00019812217106296353,
      "logits/chosen": -15.490017890930176,
      "logits/rejected": -15.447113037109375,
      "logps/chosen": -146.38587951660156,
      "logps/rejected": -148.8731231689453,
      "loss": 2.3364,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -7.304892063140869,
      "rewards/margins": 0.043753866106271744,
      "rewards/rejected": -7.348646640777588,
      "step": 510
    },
    {
      "epoch": 0.3328,
      "grad_norm": 5.601942539215088,
      "learning_rate": 0.0001979835877479589,
      "logits/chosen": -14.132287979125977,
      "logits/rejected": -14.21571159362793,
      "logps/chosen": -154.41403198242188,
      "logps/rejected": -157.9801788330078,
      "loss": 2.4123,
      "rewards/accuracies": 0.5296875238418579,
      "rewards/chosen": -7.886404514312744,
      "rewards/margins": 0.07898655533790588,
      "rewards/rejected": -7.965391635894775,
      "step": 520
    },
    {
      "epoch": 0.3392,
      "grad_norm": 4.907313346862793,
      "learning_rate": 0.00019784012312630593,
      "logits/chosen": -13.477399826049805,
      "logits/rejected": -13.42725658416748,
      "logps/chosen": -147.72994995117188,
      "logps/rejected": -152.09976196289062,
      "loss": 2.1505,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -7.260328769683838,
      "rewards/margins": 0.254489541053772,
      "rewards/rejected": -7.514817714691162,
      "step": 530
    },
    {
      "epoch": 0.3456,
      "grad_norm": 5.81899881362915,
      "learning_rate": 0.00019769178434506692,
      "logits/chosen": -13.40693473815918,
      "logits/rejected": -13.64069938659668,
      "logps/chosen": -149.59738159179688,
      "logps/rejected": -151.77008056640625,
      "loss": 2.3048,
      "rewards/accuracies": 0.534375011920929,
      "rewards/chosen": -7.575823783874512,
      "rewards/margins": 0.14570418000221252,
      "rewards/rejected": -7.721528053283691,
      "step": 540
    },
    {
      "epoch": 0.352,
      "grad_norm": 3.8376379013061523,
      "learning_rate": 0.00019753857879412318,
      "logits/chosen": -14.53821849822998,
      "logits/rejected": -14.972726821899414,
      "logps/chosen": -137.37246704101562,
      "logps/rejected": -141.07998657226562,
      "loss": 2.2238,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -6.414131164550781,
      "rewards/margins": 0.1663341224193573,
      "rewards/rejected": -6.580465793609619,
      "step": 550
    },
    {
      "epoch": 0.3584,
      "grad_norm": 4.600607395172119,
      "learning_rate": 0.00019738051410580666,
      "logits/chosen": -15.013097763061523,
      "logits/rejected": -14.968966484069824,
      "logps/chosen": -143.30807495117188,
      "logps/rejected": -148.64913940429688,
      "loss": 2.198,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -6.971334934234619,
      "rewards/margins": 0.2868967056274414,
      "rewards/rejected": -7.258232116699219,
      "step": 560
    },
    {
      "epoch": 0.3648,
      "grad_norm": 4.129358768463135,
      "learning_rate": 0.00019721759815452,
      "logits/chosen": -14.079602241516113,
      "logits/rejected": -13.983884811401367,
      "logps/chosen": -146.3037109375,
      "logps/rejected": -152.1462860107422,
      "loss": 2.1541,
      "rewards/accuracies": 0.528124988079071,
      "rewards/chosen": -7.3456130027771,
      "rewards/margins": 0.1804303228855133,
      "rewards/rejected": -7.526043891906738,
      "step": 570
    },
    {
      "epoch": 0.3712,
      "grad_norm": 4.762234687805176,
      "learning_rate": 0.00019704983905634397,
      "logits/chosen": -11.935567855834961,
      "logits/rejected": -11.64802360534668,
      "logps/chosen": -152.68362426757812,
      "logps/rejected": -153.60067749023438,
      "loss": 2.2499,
      "rewards/accuracies": 0.5390625,
      "rewards/chosen": -7.656833648681641,
      "rewards/margins": 0.11981894820928574,
      "rewards/rejected": -7.776651859283447,
      "step": 580
    },
    {
      "epoch": 0.3776,
      "grad_norm": 4.004851818084717,
      "learning_rate": 0.00019687724516863334,
      "logits/chosen": -10.787308692932129,
      "logits/rejected": -10.87376594543457,
      "logps/chosen": -156.25289916992188,
      "logps/rejected": -161.54891967773438,
      "loss": 2.3748,
      "rewards/accuracies": 0.4984374940395355,
      "rewards/chosen": -8.221757888793945,
      "rewards/margins": 0.030724596232175827,
      "rewards/rejected": -8.252481460571289,
      "step": 590
    },
    {
      "epoch": 0.384,
      "grad_norm": 5.474732398986816,
      "learning_rate": 0.0001966998250896004,
      "logits/chosen": -11.410440444946289,
      "logits/rejected": -11.447904586791992,
      "logps/chosen": -154.06784057617188,
      "logps/rejected": -160.88111877441406,
      "loss": 2.2352,
      "rewards/accuracies": 0.534375011920929,
      "rewards/chosen": -7.8875837326049805,
      "rewards/margins": 0.21227474510669708,
      "rewards/rejected": -8.099859237670898,
      "step": 600
    },
    {
      "epoch": 0.3904,
      "grad_norm": 5.9412102699279785,
      "learning_rate": 0.00019651758765788668,
      "logits/chosen": -13.503924369812012,
      "logits/rejected": -13.161832809448242,
      "logps/chosen": -156.009521484375,
      "logps/rejected": -159.04298400878906,
      "loss": 2.2569,
      "rewards/accuracies": 0.5296875238418579,
      "rewards/chosen": -8.074140548706055,
      "rewards/margins": 0.2107139527797699,
      "rewards/rejected": -8.284854888916016,
      "step": 610
    },
    {
      "epoch": 0.3968,
      "grad_norm": 4.205077171325684,
      "learning_rate": 0.00019633054195212276,
      "logits/chosen": -14.695698738098145,
      "logits/rejected": -15.084246635437012,
      "logps/chosen": -146.99258422851562,
      "logps/rejected": -153.78677368164062,
      "loss": 2.1968,
      "rewards/accuracies": 0.5640624761581421,
      "rewards/chosen": -7.495205879211426,
      "rewards/margins": 0.31971439719200134,
      "rewards/rejected": -7.814920902252197,
      "step": 620
    },
    {
      "epoch": 0.4032,
      "grad_norm": 5.387725830078125,
      "learning_rate": 0.00019613869729047568,
      "logits/chosen": -13.059694290161133,
      "logits/rejected": -13.107856750488281,
      "logps/chosen": -159.43804931640625,
      "logps/rejected": -158.69097900390625,
      "loss": 2.2741,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -8.133427619934082,
      "rewards/margins": 0.23846714198589325,
      "rewards/rejected": -8.371893882751465,
      "step": 630
    },
    {
      "epoch": 0.4096,
      "grad_norm": 4.187761306762695,
      "learning_rate": 0.00019594206323018511,
      "logits/chosen": -11.241408348083496,
      "logits/rejected": -11.463961601257324,
      "logps/chosen": -158.06581115722656,
      "logps/rejected": -164.7178497314453,
      "loss": 2.2466,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": -8.289371490478516,
      "rewards/margins": 0.10193745791912079,
      "rewards/rejected": -8.39130973815918,
      "step": 640
    },
    {
      "epoch": 0.416,
      "grad_norm": 4.168437957763672,
      "learning_rate": 0.00019574064956708685,
      "logits/chosen": -10.258631706237793,
      "logits/rejected": -10.658308029174805,
      "logps/chosen": -151.3792724609375,
      "logps/rejected": -158.47193908691406,
      "loss": 2.1172,
      "rewards/accuracies": 0.5640624761581421,
      "rewards/chosen": -7.947151184082031,
      "rewards/margins": 0.2941151261329651,
      "rewards/rejected": -8.241266250610352,
      "step": 650
    },
    {
      "epoch": 0.4224,
      "grad_norm": 4.665964126586914,
      "learning_rate": 0.00019553446633512517,
      "logits/chosen": -12.755880355834961,
      "logits/rejected": -12.6646089553833,
      "logps/chosen": -150.8579559326172,
      "logps/rejected": -155.6990203857422,
      "loss": 2.2665,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": -7.733367919921875,
      "rewards/margins": 0.0716136246919632,
      "rewards/rejected": -7.8049821853637695,
      "step": 660
    },
    {
      "epoch": 0.4288,
      "grad_norm": 5.162397861480713,
      "learning_rate": 0.0001953235238058527,
      "logits/chosen": -14.757904052734375,
      "logits/rejected": -14.788267135620117,
      "logps/chosen": -154.90625,
      "logps/rejected": -159.24777221679688,
      "loss": 2.2497,
      "rewards/accuracies": 0.510937511920929,
      "rewards/chosen": -7.800801753997803,
      "rewards/margins": 0.14432771503925323,
      "rewards/rejected": -7.94512939453125,
      "step": 670
    },
    {
      "epoch": 0.4352,
      "grad_norm": 4.036409378051758,
      "learning_rate": 0.00019510783248791885,
      "logits/chosen": -13.102520942687988,
      "logits/rejected": -13.108637809753418,
      "logps/chosen": -149.3737335205078,
      "logps/rejected": -152.1457061767578,
      "loss": 2.2989,
      "rewards/accuracies": 0.518750011920929,
      "rewards/chosen": -7.4499921798706055,
      "rewards/margins": 0.1587875485420227,
      "rewards/rejected": -7.608780860900879,
      "step": 680
    },
    {
      "epoch": 0.4416,
      "grad_norm": 4.227682590484619,
      "learning_rate": 0.0001948874031265462,
      "logits/chosen": -9.846640586853027,
      "logits/rejected": -10.186864852905273,
      "logps/chosen": -152.61984252929688,
      "logps/rejected": -160.01568603515625,
      "loss": 2.1511,
      "rewards/accuracies": 0.5484374761581421,
      "rewards/chosen": -7.869420051574707,
      "rewards/margins": 0.31748688220977783,
      "rewards/rejected": -8.186905860900879,
      "step": 690
    },
    {
      "epoch": 0.448,
      "grad_norm": 3.167340040206909,
      "learning_rate": 0.0001946622467029954,
      "logits/chosen": -12.24177360534668,
      "logits/rejected": -12.355122566223145,
      "logps/chosen": -147.04727172851562,
      "logps/rejected": -153.60507202148438,
      "loss": 2.2079,
      "rewards/accuracies": 0.535937488079071,
      "rewards/chosen": -7.1258955001831055,
      "rewards/margins": 0.3055524230003357,
      "rewards/rejected": -7.431447505950928,
      "step": 700
    },
    {
      "epoch": 0.4544,
      "grad_norm": 4.444572448730469,
      "learning_rate": 0.00019443237443401778,
      "logits/chosen": -14.04418659210205,
      "logits/rejected": -14.239166259765625,
      "logps/chosen": -145.5061798095703,
      "logps/rejected": -149.51113891601562,
      "loss": 2.2458,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": -6.925439357757568,
      "rewards/margins": 0.19120202958583832,
      "rewards/rejected": -7.116641044616699,
      "step": 710
    },
    {
      "epoch": 0.4608,
      "grad_norm": 3.826504945755005,
      "learning_rate": 0.0001941977977712969,
      "logits/chosen": -13.533604621887207,
      "logits/rejected": -13.547845840454102,
      "logps/chosen": -152.51522827148438,
      "logps/rejected": -158.5709228515625,
      "loss": 2.1786,
      "rewards/accuracies": 0.578125,
      "rewards/chosen": -7.712267875671387,
      "rewards/margins": 0.3943943381309509,
      "rewards/rejected": -8.106663703918457,
      "step": 720
    },
    {
      "epoch": 0.4672,
      "grad_norm": 5.240883827209473,
      "learning_rate": 0.0001939585284008778,
      "logits/chosen": -12.774930953979492,
      "logits/rejected": -12.924173355102539,
      "logps/chosen": -156.06930541992188,
      "logps/rejected": -158.29129028320312,
      "loss": 2.3554,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -7.953235626220703,
      "rewards/margins": 0.1759992092847824,
      "rewards/rejected": -8.129234313964844,
      "step": 730
    },
    {
      "epoch": 0.4736,
      "grad_norm": 3.368074417114258,
      "learning_rate": 0.000193714578242585,
      "logits/chosen": -10.657219886779785,
      "logits/rejected": -10.96560001373291,
      "logps/chosen": -154.93991088867188,
      "logps/rejected": -153.54190063476562,
      "loss": 2.2723,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -7.742082118988037,
      "rewards/margins": 0.049996644258499146,
      "rewards/rejected": -7.792078971862793,
      "step": 740
    },
    {
      "epoch": 0.48,
      "grad_norm": 5.873342514038086,
      "learning_rate": 0.00019346595944942855,
      "logits/chosen": -8.159457206726074,
      "logits/rejected": -8.671529769897461,
      "logps/chosen": -155.94583129882812,
      "logps/rejected": -158.51644897460938,
      "loss": 2.319,
      "rewards/accuracies": 0.535937488079071,
      "rewards/chosen": -8.190475463867188,
      "rewards/margins": 0.09578946232795715,
      "rewards/rejected": -8.286264419555664,
      "step": 750
    },
    {
      "epoch": 0.4864,
      "grad_norm": 3.8626699447631836,
      "learning_rate": 0.00019321268440699866,
      "logits/chosen": -11.3740234375,
      "logits/rejected": -11.734855651855469,
      "logps/chosen": -162.34963989257812,
      "logps/rejected": -164.96580505371094,
      "loss": 2.2636,
      "rewards/accuracies": 0.504687488079071,
      "rewards/chosen": -8.532607078552246,
      "rewards/margins": 0.1392623484134674,
      "rewards/rejected": -8.671870231628418,
      "step": 760
    },
    {
      "epoch": 0.4928,
      "grad_norm": 4.6373209953308105,
      "learning_rate": 0.0001929547657328488,
      "logits/chosen": -10.799249649047852,
      "logits/rejected": -11.087814331054688,
      "logps/chosen": -156.5037384033203,
      "logps/rejected": -157.09109497070312,
      "loss": 2.3411,
      "rewards/accuracies": 0.4765625,
      "rewards/chosen": -8.105443954467773,
      "rewards/margins": 0.0003136441227979958,
      "rewards/rejected": -8.105756759643555,
      "step": 770
    },
    {
      "epoch": 0.4992,
      "grad_norm": 3.7600343227386475,
      "learning_rate": 0.00019269221627586685,
      "logits/chosen": -7.849891662597656,
      "logits/rejected": -7.889505863189697,
      "logps/chosen": -162.930908203125,
      "logps/rejected": -165.55038452148438,
      "loss": 2.2768,
      "rewards/accuracies": 0.504687488079071,
      "rewards/chosen": -8.672675132751465,
      "rewards/margins": 0.13221228122711182,
      "rewards/rejected": -8.804887771606445,
      "step": 780
    },
    {
      "epoch": 0.5056,
      "grad_norm": 3.627530574798584,
      "learning_rate": 0.0001924250491156352,
      "logits/chosen": -8.549558639526367,
      "logits/rejected": -8.538981437683105,
      "logps/chosen": -165.07406616210938,
      "logps/rejected": -168.42764282226562,
      "loss": 2.2314,
      "rewards/accuracies": 0.5484374761581421,
      "rewards/chosen": -8.936864852905273,
      "rewards/margins": 0.21778476238250732,
      "rewards/rejected": -9.15464973449707,
      "step": 790
    },
    {
      "epoch": 0.512,
      "grad_norm": 4.764116287231445,
      "learning_rate": 0.00019215327756177914,
      "logits/chosen": -10.594252586364746,
      "logits/rejected": -10.554040908813477,
      "logps/chosen": -164.56790161132812,
      "logps/rejected": -164.62594604492188,
      "loss": 2.3697,
      "rewards/accuracies": 0.4765625,
      "rewards/chosen": -8.927833557128906,
      "rewards/margins": -0.14795275032520294,
      "rewards/rejected": -8.77988052368164,
      "step": 800
    },
    {
      "epoch": 0.5184,
      "grad_norm": 4.459149360656738,
      "learning_rate": 0.00019187691515330375,
      "logits/chosen": -13.345309257507324,
      "logits/rejected": -13.695419311523438,
      "logps/chosen": -158.17617797851562,
      "logps/rejected": -159.33326721191406,
      "loss": 2.2265,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -8.214726448059082,
      "rewards/margins": 0.08895718306303024,
      "rewards/rejected": -8.30368423461914,
      "step": 810
    },
    {
      "epoch": 0.5248,
      "grad_norm": 5.036744594573975,
      "learning_rate": 0.00019159597565791944,
      "logits/chosen": -15.715347290039062,
      "logits/rejected": -15.83081340789795,
      "logps/chosen": -161.44821166992188,
      "logps/rejected": -163.7431640625,
      "loss": 2.3261,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -8.752760887145996,
      "rewards/margins": 0.08124736696481705,
      "rewards/rejected": -8.834009170532227,
      "step": 820
    },
    {
      "epoch": 0.5312,
      "grad_norm": 4.590063571929932,
      "learning_rate": 0.0001913104730713561,
      "logits/chosen": -17.767349243164062,
      "logits/rejected": -17.88936996459961,
      "logps/chosen": -166.60617065429688,
      "logps/rejected": -169.95863342285156,
      "loss": 2.2438,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -9.253320693969727,
      "rewards/margins": 0.09029585868120193,
      "rewards/rejected": -9.34361743927002,
      "step": 830
    },
    {
      "epoch": 0.5376,
      "grad_norm": 4.1542510986328125,
      "learning_rate": 0.00019102042161666584,
      "logits/chosen": -15.576312065124512,
      "logits/rejected": -15.731829643249512,
      "logps/chosen": -161.67156982421875,
      "logps/rejected": -166.19705200195312,
      "loss": 2.2486,
      "rewards/accuracies": 0.534375011920929,
      "rewards/chosen": -8.745976448059082,
      "rewards/margins": 0.11324447393417358,
      "rewards/rejected": -8.859220504760742,
      "step": 840
    },
    {
      "epoch": 0.544,
      "grad_norm": 4.011021614074707,
      "learning_rate": 0.00019072583574351442,
      "logits/chosen": -14.6940336227417,
      "logits/rejected": -14.644015312194824,
      "logps/chosen": -160.75059509277344,
      "logps/rejected": -164.80711364746094,
      "loss": 2.2291,
      "rewards/accuracies": 0.5406249761581421,
      "rewards/chosen": -8.562231063842773,
      "rewards/margins": 0.18580631911754608,
      "rewards/rejected": -8.748037338256836,
      "step": 850
    },
    {
      "epoch": 0.5504,
      "grad_norm": 4.617904186248779,
      "learning_rate": 0.00019042673012746142,
      "logits/chosen": -14.722493171691895,
      "logits/rejected": -14.788335800170898,
      "logps/chosen": -155.09329223632812,
      "logps/rejected": -160.6209259033203,
      "loss": 2.2112,
      "rewards/accuracies": 0.546875,
      "rewards/chosen": -8.175302505493164,
      "rewards/margins": 0.21072563529014587,
      "rewards/rejected": -8.386027336120605,
      "step": 860
    },
    {
      "epoch": 0.5568,
      "grad_norm": 3.712458848953247,
      "learning_rate": 0.0001901231196692292,
      "logits/chosen": -11.749856948852539,
      "logits/rejected": -11.832087516784668,
      "logps/chosen": -157.29075622558594,
      "logps/rejected": -159.625244140625,
      "loss": 2.2777,
      "rewards/accuracies": 0.5296875238418579,
      "rewards/chosen": -8.181986808776855,
      "rewards/margins": 0.0492241345345974,
      "rewards/rejected": -8.231210708618164,
      "step": 870
    },
    {
      "epoch": 0.5632,
      "grad_norm": 4.443964958190918,
      "learning_rate": 0.0001898150194939604,
      "logits/chosen": -10.18810749053955,
      "logits/rejected": -10.555586814880371,
      "logps/chosen": -158.89376831054688,
      "logps/rejected": -161.74864196777344,
      "loss": 2.2033,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": -8.516886711120605,
      "rewards/margins": 0.16838929057121277,
      "rewards/rejected": -8.685276985168457,
      "step": 880
    },
    {
      "epoch": 0.5696,
      "grad_norm": 4.169440746307373,
      "learning_rate": 0.00018950244495046471,
      "logits/chosen": -9.411477088928223,
      "logits/rejected": -9.488877296447754,
      "logps/chosen": -161.15115356445312,
      "logps/rejected": -162.9627227783203,
      "loss": 2.3735,
      "rewards/accuracies": 0.503125011920929,
      "rewards/chosen": -8.669588088989258,
      "rewards/margins": 0.07764144241809845,
      "rewards/rejected": -8.747228622436523,
      "step": 890
    },
    {
      "epoch": 0.576,
      "grad_norm": 3.933069944381714,
      "learning_rate": 0.00018918541161045397,
      "logits/chosen": -10.229317665100098,
      "logits/rejected": -10.28536605834961,
      "logps/chosen": -164.39007568359375,
      "logps/rejected": -165.9033203125,
      "loss": 2.2495,
      "rewards/accuracies": 0.528124988079071,
      "rewards/chosen": -8.812982559204102,
      "rewards/margins": 0.08906205743551254,
      "rewards/rejected": -8.902044296264648,
      "step": 900
    },
    {
      "epoch": 0.5824,
      "grad_norm": 4.421942710876465,
      "learning_rate": 0.00018886393526776658,
      "logits/chosen": -9.647706985473633,
      "logits/rejected": -9.673694610595703,
      "logps/chosen": -159.45562744140625,
      "logps/rejected": -165.05157470703125,
      "loss": 2.2007,
      "rewards/accuracies": 0.5406249761581421,
      "rewards/chosen": -8.545400619506836,
      "rewards/margins": 0.18951384723186493,
      "rewards/rejected": -8.734912872314453,
      "step": 910
    },
    {
      "epoch": 0.5888,
      "grad_norm": 4.274374008178711,
      "learning_rate": 0.00018853803193758065,
      "logits/chosen": -9.836542129516602,
      "logits/rejected": -9.660662651062012,
      "logps/chosen": -156.59036254882812,
      "logps/rejected": -162.12777709960938,
      "loss": 2.2204,
      "rewards/accuracies": 0.528124988079071,
      "rewards/chosen": -8.153477668762207,
      "rewards/margins": 0.16155597567558289,
      "rewards/rejected": -8.315034866333008,
      "step": 920
    },
    {
      "epoch": 0.5952,
      "grad_norm": 4.786525726318359,
      "learning_rate": 0.00018820771785561615,
      "logits/chosen": -11.096819877624512,
      "logits/rejected": -10.940194129943848,
      "logps/chosen": -151.5009307861328,
      "logps/rejected": -154.76878356933594,
      "loss": 2.2555,
      "rewards/accuracies": 0.5140625238418579,
      "rewards/chosen": -7.7845001220703125,
      "rewards/margins": 0.12009841203689575,
      "rewards/rejected": -7.904598236083984,
      "step": 930
    },
    {
      "epoch": 0.6016,
      "grad_norm": 4.3183488845825195,
      "learning_rate": 0.0001878730094773261,
      "logits/chosen": -10.556731224060059,
      "logits/rejected": -10.778318405151367,
      "logps/chosen": -165.40396118164062,
      "logps/rejected": -167.31503295898438,
      "loss": 2.2364,
      "rewards/accuracies": 0.551562488079071,
      "rewards/chosen": -8.873983383178711,
      "rewards/margins": 0.24818527698516846,
      "rewards/rejected": -9.122169494628906,
      "step": 940
    },
    {
      "epoch": 0.608,
      "grad_norm": 3.712207078933716,
      "learning_rate": 0.00018753392347707675,
      "logits/chosen": -12.477164268493652,
      "logits/rejected": -12.72382926940918,
      "logps/chosen": -161.3638153076172,
      "logps/rejected": -167.3403778076172,
      "loss": 2.1658,
      "rewards/accuracies": 0.5234375,
      "rewards/chosen": -8.5724515914917,
      "rewards/margins": 0.2345971167087555,
      "rewards/rejected": -8.807048797607422,
      "step": 950
    },
    {
      "epoch": 0.6144,
      "grad_norm": 3.813816785812378,
      "learning_rate": 0.00018719047674731703,
      "logits/chosen": -11.204431533813477,
      "logits/rejected": -10.997085571289062,
      "logps/chosen": -161.06802368164062,
      "logps/rejected": -160.59823608398438,
      "loss": 2.3056,
      "rewards/accuracies": 0.49531251192092896,
      "rewards/chosen": -8.593124389648438,
      "rewards/margins": -0.008275163359940052,
      "rewards/rejected": -8.58484935760498,
      "step": 960
    },
    {
      "epoch": 0.6208,
      "grad_norm": 5.27523136138916,
      "learning_rate": 0.00018684268639773682,
      "logits/chosen": -11.021921157836914,
      "logits/rejected": -11.156942367553711,
      "logps/chosen": -163.65414428710938,
      "logps/rejected": -163.89810180664062,
      "loss": 2.3182,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.693037986755371,
      "rewards/margins": 0.07870147377252579,
      "rewards/rejected": -8.77173900604248,
      "step": 970
    },
    {
      "epoch": 0.6272,
      "grad_norm": 3.459425210952759,
      "learning_rate": 0.0001864905697544148,
      "logits/chosen": -11.911492347717285,
      "logits/rejected": -11.902815818786621,
      "logps/chosen": -168.63235473632812,
      "logps/rejected": -169.9945831298828,
      "loss": 2.2738,
      "rewards/accuracies": 0.5078125,
      "rewards/chosen": -9.31171703338623,
      "rewards/margins": 0.02348111942410469,
      "rewards/rejected": -9.335198402404785,
      "step": 980
    },
    {
      "epoch": 0.6336,
      "grad_norm": 3.6808109283447266,
      "learning_rate": 0.00018613414435895517,
      "logits/chosen": -11.056382179260254,
      "logits/rejected": -11.231585502624512,
      "logps/chosen": -174.70590209960938,
      "logps/rejected": -178.85731506347656,
      "loss": 2.1614,
      "rewards/accuracies": 0.5546875,
      "rewards/chosen": -10.053116798400879,
      "rewards/margins": 0.3540183901786804,
      "rewards/rejected": -10.407135963439941,
      "step": 990
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.6839563846588135,
      "learning_rate": 0.0001857734279676137,
      "logits/chosen": -8.770746231079102,
      "logits/rejected": -8.790983200073242,
      "logps/chosen": -166.52426147460938,
      "logps/rejected": -167.25765991210938,
      "loss": 2.2609,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -9.1412353515625,
      "rewards/margins": 0.16176322102546692,
      "rewards/rejected": -9.302999496459961,
      "step": 1000
    },
    {
      "epoch": 0.6464,
      "grad_norm": 3.430278778076172,
      "learning_rate": 0.00018540843855041338,
      "logits/chosen": -6.7583465576171875,
      "logits/rejected": -6.9551262855529785,
      "logps/chosen": -163.86151123046875,
      "logps/rejected": -170.10031127929688,
      "loss": 2.2127,
      "rewards/accuracies": 0.5140625238418579,
      "rewards/chosen": -8.966833114624023,
      "rewards/margins": 0.11294932663440704,
      "rewards/rejected": -9.079782485961914,
      "step": 1010
    },
    {
      "epoch": 0.6528,
      "grad_norm": 3.7983651161193848,
      "learning_rate": 0.000185039194290249,
      "logits/chosen": -6.5977983474731445,
      "logits/rejected": -6.559876918792725,
      "logps/chosen": -157.75709533691406,
      "logps/rejected": -162.54039001464844,
      "loss": 2.107,
      "rewards/accuracies": 0.551562488079071,
      "rewards/chosen": -8.414275169372559,
      "rewards/margins": 0.2878798842430115,
      "rewards/rejected": -8.702154159545898,
      "step": 1020
    },
    {
      "epoch": 0.6592,
      "grad_norm": 3.572852373123169,
      "learning_rate": 0.00018466571358198138,
      "logits/chosen": -4.075730323791504,
      "logits/rejected": -4.007142066955566,
      "logps/chosen": -165.6727294921875,
      "logps/rejected": -169.94883728027344,
      "loss": 2.2445,
      "rewards/accuracies": 0.5375000238418579,
      "rewards/chosen": -9.095596313476562,
      "rewards/margins": 0.10364414751529694,
      "rewards/rejected": -9.199241638183594,
      "step": 1030
    },
    {
      "epoch": 0.6656,
      "grad_norm": 3.9158833026885986,
      "learning_rate": 0.00018428801503152107,
      "logits/chosen": -3.491083860397339,
      "logits/rejected": -3.4044227600097656,
      "logps/chosen": -169.64486694335938,
      "logps/rejected": -171.66470336914062,
      "loss": 2.2183,
      "rewards/accuracies": 0.5328124761581421,
      "rewards/chosen": -9.371761322021484,
      "rewards/margins": 0.17721091210842133,
      "rewards/rejected": -9.548973083496094,
      "step": 1040
    },
    {
      "epoch": 0.672,
      "grad_norm": 3.2390151023864746,
      "learning_rate": 0.00018390611745490128,
      "logits/chosen": -7.030238151550293,
      "logits/rejected": -7.117221832275391,
      "logps/chosen": -168.98037719726562,
      "logps/rejected": -171.2002716064453,
      "loss": 2.1731,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": -9.215532302856445,
      "rewards/margins": 0.07713986933231354,
      "rewards/rejected": -9.292672157287598,
      "step": 1050
    },
    {
      "epoch": 0.6784,
      "grad_norm": 4.353446960449219,
      "learning_rate": 0.00018352003987734072,
      "logits/chosen": -9.389262199401855,
      "logits/rejected": -9.378026008605957,
      "logps/chosen": -160.41238403320312,
      "logps/rejected": -161.18423461914062,
      "loss": 2.262,
      "rewards/accuracies": 0.53125,
      "rewards/chosen": -8.327309608459473,
      "rewards/margins": 0.21457679569721222,
      "rewards/rejected": -8.541887283325195,
      "step": 1060
    },
    {
      "epoch": 0.6848,
      "grad_norm": 3.7628486156463623,
      "learning_rate": 0.00018312980153229553,
      "logits/chosen": -12.101557731628418,
      "logits/rejected": -12.213603973388672,
      "logps/chosen": -157.75445556640625,
      "logps/rejected": -160.42520141601562,
      "loss": 2.1754,
      "rewards/accuracies": 0.543749988079071,
      "rewards/chosen": -8.318660736083984,
      "rewards/margins": 0.21642974019050598,
      "rewards/rejected": -8.535089492797852,
      "step": 1070
    },
    {
      "epoch": 0.6912,
      "grad_norm": 3.714179515838623,
      "learning_rate": 0.0001827354218605014,
      "logits/chosen": -11.774975776672363,
      "logits/rejected": -11.736936569213867,
      "logps/chosen": -165.5501708984375,
      "logps/rejected": -166.80551147460938,
      "loss": 2.2312,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -8.987822532653809,
      "rewards/margins": 0.16332301497459412,
      "rewards/rejected": -9.151145935058594,
      "step": 1080
    },
    {
      "epoch": 0.6976,
      "grad_norm": 3.743403673171997,
      "learning_rate": 0.00018233692050900494,
      "logits/chosen": -11.730963706970215,
      "logits/rejected": -11.612123489379883,
      "logps/chosen": -163.60324096679688,
      "logps/rejected": -166.8255615234375,
      "loss": 2.176,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": -9.03366756439209,
      "rewards/margins": 0.09892599284648895,
      "rewards/rejected": -9.132593154907227,
      "step": 1090
    },
    {
      "epoch": 0.704,
      "grad_norm": 3.81796932220459,
      "learning_rate": 0.0001819343173301849,
      "logits/chosen": -11.835189819335938,
      "logits/rejected": -12.252685546875,
      "logps/chosen": -159.96804809570312,
      "logps/rejected": -165.99070739746094,
      "loss": 2.1866,
      "rewards/accuracies": 0.4937500059604645,
      "rewards/chosen": -8.624673843383789,
      "rewards/margins": 0.11822439730167389,
      "rewards/rejected": -8.742898941040039,
      "step": 1100
    },
    {
      "epoch": 0.7104,
      "grad_norm": 3.484145402908325,
      "learning_rate": 0.00018152763238076322,
      "logits/chosen": -12.481897354125977,
      "logits/rejected": -12.483851432800293,
      "logps/chosen": -159.4421844482422,
      "logps/rejected": -164.20596313476562,
      "loss": 2.1512,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -8.466054916381836,
      "rewards/margins": 0.30139511823654175,
      "rewards/rejected": -8.767449378967285,
      "step": 1110
    },
    {
      "epoch": 0.7168,
      "grad_norm": 5.130704879760742,
      "learning_rate": 0.0001811168859208058,
      "logits/chosen": -12.055752754211426,
      "logits/rejected": -12.193679809570312,
      "logps/chosen": -168.075439453125,
      "logps/rejected": -169.4871063232422,
      "loss": 2.2752,
      "rewards/accuracies": 0.49687498807907104,
      "rewards/chosen": -9.246270179748535,
      "rewards/margins": 0.06141187995672226,
      "rewards/rejected": -9.307682991027832,
      "step": 1120
    },
    {
      "epoch": 0.7232,
      "grad_norm": 8.078761100769043,
      "learning_rate": 0.00018070209841271334,
      "logits/chosen": -11.527442932128906,
      "logits/rejected": -11.385893821716309,
      "logps/chosen": -164.27310180664062,
      "logps/rejected": -164.83914184570312,
      "loss": 2.2671,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": -8.7625093460083,
      "rewards/margins": 0.06567231565713882,
      "rewards/rejected": -8.828182220458984,
      "step": 1130
    },
    {
      "epoch": 0.7296,
      "grad_norm": 4.320767879486084,
      "learning_rate": 0.0001802832905202016,
      "logits/chosen": -11.503683090209961,
      "logits/rejected": -11.677352905273438,
      "logps/chosen": -170.61280822753906,
      "logps/rejected": -173.509521484375,
      "loss": 2.3147,
      "rewards/accuracies": 0.48124998807907104,
      "rewards/chosen": -9.576624870300293,
      "rewards/margins": 0.06437276303768158,
      "rewards/rejected": -9.640996932983398,
      "step": 1140
    },
    {
      "epoch": 0.736,
      "grad_norm": 3.692176342010498,
      "learning_rate": 0.00017986048310727248,
      "logits/chosen": -11.922633171081543,
      "logits/rejected": -11.866327285766602,
      "logps/chosen": -162.48716735839844,
      "logps/rejected": -167.03697204589844,
      "loss": 2.2051,
      "rewards/accuracies": 0.526562511920929,
      "rewards/chosen": -8.981283187866211,
      "rewards/margins": 0.19720768928527832,
      "rewards/rejected": -9.178489685058594,
      "step": 1150
    },
    {
      "epoch": 0.7424,
      "grad_norm": 3.126681089401245,
      "learning_rate": 0.00017943369723717422,
      "logits/chosen": -11.199416160583496,
      "logits/rejected": -11.352619171142578,
      "logps/chosen": -158.50880432128906,
      "logps/rejected": -162.33261108398438,
      "loss": 2.3138,
      "rewards/accuracies": 0.5234375,
      "rewards/chosen": -8.353769302368164,
      "rewards/margins": 0.1306082308292389,
      "rewards/rejected": -8.48437786102295,
      "step": 1160
    },
    {
      "epoch": 0.7488,
      "grad_norm": 3.699162483215332,
      "learning_rate": 0.00017900295417135227,
      "logits/chosen": -10.787195205688477,
      "logits/rejected": -11.072074890136719,
      "logps/chosen": -152.85755920410156,
      "logps/rejected": -158.26312255859375,
      "loss": 2.1085,
      "rewards/accuracies": 0.5765625238418579,
      "rewards/chosen": -7.6925249099731445,
      "rewards/margins": 0.2987697422504425,
      "rewards/rejected": -7.991294860839844,
      "step": 1170
    },
    {
      "epoch": 0.7552,
      "grad_norm": 2.63289737701416,
      "learning_rate": 0.00017856827536839005,
      "logits/chosen": -9.623017311096191,
      "logits/rejected": -9.573531150817871,
      "logps/chosen": -158.64517211914062,
      "logps/rejected": -157.5666046142578,
      "loss": 2.2726,
      "rewards/accuracies": 0.5,
      "rewards/chosen": -8.337953567504883,
      "rewards/margins": 0.0922895297408104,
      "rewards/rejected": -8.430242538452148,
      "step": 1180
    },
    {
      "epoch": 0.7616,
      "grad_norm": 3.2260708808898926,
      "learning_rate": 0.00017812968248293991,
      "logits/chosen": -10.018274307250977,
      "logits/rejected": -9.977689743041992,
      "logps/chosen": -165.8662109375,
      "logps/rejected": -170.7134246826172,
      "loss": 2.3081,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -9.098533630371094,
      "rewards/margins": 0.18118467926979065,
      "rewards/rejected": -9.279718399047852,
      "step": 1190
    },
    {
      "epoch": 0.768,
      "grad_norm": 3.837357759475708,
      "learning_rate": 0.00017768719736464442,
      "logits/chosen": -8.988496780395508,
      "logits/rejected": -9.007795333862305,
      "logps/chosen": -164.48101806640625,
      "logps/rejected": -165.59690856933594,
      "loss": 2.2691,
      "rewards/accuracies": 0.503125011920929,
      "rewards/chosen": -8.745577812194824,
      "rewards/margins": 0.155770942568779,
      "rewards/rejected": -8.901349067687988,
      "step": 1200
    },
    {
      "epoch": 0.7744,
      "grad_norm": 3.432112455368042,
      "learning_rate": 0.00017724084205704776,
      "logits/chosen": -11.04189395904541,
      "logits/rejected": -11.01146411895752,
      "logps/chosen": -163.3198699951172,
      "logps/rejected": -165.76461791992188,
      "loss": 2.2558,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -8.56974983215332,
      "rewards/margins": 0.14284993708133698,
      "rewards/rejected": -8.71259880065918,
      "step": 1210
    },
    {
      "epoch": 0.7808,
      "grad_norm": 3.6149117946624756,
      "learning_rate": 0.00017679063879649776,
      "logits/chosen": -13.271206855773926,
      "logits/rejected": -13.29156494140625,
      "logps/chosen": -161.55517578125,
      "logps/rejected": -164.15316772460938,
      "loss": 2.1873,
      "rewards/accuracies": 0.5171874761581421,
      "rewards/chosen": -8.789281845092773,
      "rewards/margins": 0.1381334662437439,
      "rewards/rejected": -8.927414894104004,
      "step": 1220
    },
    {
      "epoch": 0.7872,
      "grad_norm": 3.253044843673706,
      "learning_rate": 0.00017633661001103783,
      "logits/chosen": -12.841773986816406,
      "logits/rejected": -12.988919258117676,
      "logps/chosen": -164.9778289794922,
      "logps/rejected": -168.43026733398438,
      "loss": 2.2928,
      "rewards/accuracies": 0.504687488079071,
      "rewards/chosen": -9.008550643920898,
      "rewards/margins": 0.0543643943965435,
      "rewards/rejected": -9.062915802001953,
      "step": 1230
    },
    {
      "epoch": 0.7936,
      "grad_norm": 3.1571550369262695,
      "learning_rate": 0.00017587877831928998,
      "logits/chosen": -11.608686447143555,
      "logits/rejected": -11.602067947387695,
      "logps/chosen": -169.56288146972656,
      "logps/rejected": -170.74330139160156,
      "loss": 2.1896,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -9.348756790161133,
      "rewards/margins": 0.047924697399139404,
      "rewards/rejected": -9.396681785583496,
      "step": 1240
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.629073143005371,
      "learning_rate": 0.00017541716652932782,
      "logits/chosen": -10.42814826965332,
      "logits/rejected": -10.50387954711914,
      "logps/chosen": -171.3457489013672,
      "logps/rejected": -175.32656860351562,
      "loss": 2.1789,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -9.612035751342773,
      "rewards/margins": 0.13513663411140442,
      "rewards/rejected": -9.747173309326172,
      "step": 1250
    },
    {
      "epoch": 0.8064,
      "grad_norm": 3.774327516555786,
      "learning_rate": 0.0001749517976375403,
      "logits/chosen": -9.602819442749023,
      "logits/rejected": -9.741631507873535,
      "logps/chosen": -157.62841796875,
      "logps/rejected": -158.49966430664062,
      "loss": 2.3135,
      "rewards/accuracies": 0.5015624761581421,
      "rewards/chosen": -8.315744400024414,
      "rewards/margins": -0.006131267640739679,
      "rewards/rejected": -8.309614181518555,
      "step": 1260
    },
    {
      "epoch": 0.8128,
      "grad_norm": 5.116117477416992,
      "learning_rate": 0.00017448269482748624,
      "logits/chosen": -8.483343124389648,
      "logits/rejected": -8.419857025146484,
      "logps/chosen": -168.76651000976562,
      "logps/rejected": -170.73895263671875,
      "loss": 2.1907,
      "rewards/accuracies": 0.510937511920929,
      "rewards/chosen": -9.290855407714844,
      "rewards/margins": 0.05294708162546158,
      "rewards/rejected": -9.343801498413086,
      "step": 1270
    },
    {
      "epoch": 0.8192,
      "grad_norm": 4.168303489685059,
      "learning_rate": 0.0001740098814687392,
      "logits/chosen": -10.989495277404785,
      "logits/rejected": -11.042230606079102,
      "logps/chosen": -166.14100646972656,
      "logps/rejected": -166.7833251953125,
      "loss": 2.2355,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -9.079909324645996,
      "rewards/margins": 0.08284374326467514,
      "rewards/rejected": -9.162753105163574,
      "step": 1280
    },
    {
      "epoch": 0.8256,
      "grad_norm": 3.33935809135437,
      "learning_rate": 0.00017353338111572342,
      "logits/chosen": -13.469858169555664,
      "logits/rejected": -13.469827651977539,
      "logps/chosen": -168.3229217529297,
      "logps/rejected": -171.45838928222656,
      "loss": 2.1246,
      "rewards/accuracies": 0.542187511920929,
      "rewards/chosen": -9.335555076599121,
      "rewards/margins": 0.15873360633850098,
      "rewards/rejected": -9.494288444519043,
      "step": 1290
    },
    {
      "epoch": 0.832,
      "grad_norm": 3.747843027114868,
      "learning_rate": 0.00017305321750654028,
      "logits/chosen": -12.770607948303223,
      "logits/rejected": -12.835169792175293,
      "logps/chosen": -168.26751708984375,
      "logps/rejected": -174.56289672851562,
      "loss": 2.1634,
      "rewards/accuracies": 0.551562488079071,
      "rewards/chosen": -9.419952392578125,
      "rewards/margins": 0.2352207601070404,
      "rewards/rejected": -9.655172348022461,
      "step": 1300
    },
    {
      "epoch": 0.8384,
      "grad_norm": 4.29435396194458,
      "learning_rate": 0.00017256941456178577,
      "logits/chosen": -12.087297439575195,
      "logits/rejected": -12.031888008117676,
      "logps/chosen": -165.26516723632812,
      "logps/rejected": -167.6045684814453,
      "loss": 2.2694,
      "rewards/accuracies": 0.5296875238418579,
      "rewards/chosen": -9.087212562561035,
      "rewards/margins": 0.06883610785007477,
      "rewards/rejected": -9.156048774719238,
      "step": 1310
    },
    {
      "epoch": 0.8448,
      "grad_norm": 4.325253963470459,
      "learning_rate": 0.0001720819963833589,
      "logits/chosen": -10.675257682800293,
      "logits/rejected": -10.712491989135742,
      "logps/chosen": -170.04457092285156,
      "logps/rejected": -174.35340881347656,
      "loss": 2.2038,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -9.429298400878906,
      "rewards/margins": 0.05241555720567703,
      "rewards/rejected": -9.481714248657227,
      "step": 1320
    },
    {
      "epoch": 0.8512,
      "grad_norm": 3.0531888008117676,
      "learning_rate": 0.0001715909872532608,
      "logits/chosen": -8.766252517700195,
      "logits/rejected": -8.631307601928711,
      "logps/chosen": -160.50588989257812,
      "logps/rejected": -163.45602416992188,
      "loss": 2.1928,
      "rewards/accuracies": 0.528124988079071,
      "rewards/chosen": -8.653818130493164,
      "rewards/margins": 0.12946943938732147,
      "rewards/rejected": -8.78328800201416,
      "step": 1330
    },
    {
      "epoch": 0.8576,
      "grad_norm": 3.5578107833862305,
      "learning_rate": 0.0001710964116323853,
      "logits/chosen": -7.910663604736328,
      "logits/rejected": -7.800065517425537,
      "logps/chosen": -161.83631896972656,
      "logps/rejected": -164.8699493408203,
      "loss": 2.2212,
      "rewards/accuracies": 0.5406249761581421,
      "rewards/chosen": -8.839201927185059,
      "rewards/margins": 0.16114142537117004,
      "rewards/rejected": -9.000343322753906,
      "step": 1340
    },
    {
      "epoch": 0.864,
      "grad_norm": 4.069018840789795,
      "learning_rate": 0.0001705982941593001,
      "logits/chosen": -6.033444404602051,
      "logits/rejected": -6.094761848449707,
      "logps/chosen": -174.014892578125,
      "logps/rejected": -173.545654296875,
      "loss": 2.2451,
      "rewards/accuracies": 0.5078125,
      "rewards/chosen": -9.666715621948242,
      "rewards/margins": 0.0486912727355957,
      "rewards/rejected": -9.71540641784668,
      "step": 1350
    },
    {
      "epoch": 0.8704,
      "grad_norm": 3.061572551727295,
      "learning_rate": 0.00017009665964901958,
      "logits/chosen": -4.962749481201172,
      "logits/rejected": -4.97132682800293,
      "logps/chosen": -166.25546264648438,
      "logps/rejected": -170.2348175048828,
      "loss": 2.1664,
      "rewards/accuracies": 0.5140625238418579,
      "rewards/chosen": -9.092363357543945,
      "rewards/margins": 0.1486321985721588,
      "rewards/rejected": -9.240995407104492,
      "step": 1360
    },
    {
      "epoch": 0.8768,
      "grad_norm": 3.5358879566192627,
      "learning_rate": 0.00016959153309176837,
      "logits/chosen": -7.007691860198975,
      "logits/rejected": -6.990869045257568,
      "logps/chosen": -163.12071228027344,
      "logps/rejected": -166.72215270996094,
      "loss": 2.1766,
      "rewards/accuracies": 0.5609375238418579,
      "rewards/chosen": -8.820959091186523,
      "rewards/margins": 0.1674678772687912,
      "rewards/rejected": -8.98842716217041,
      "step": 1370
    },
    {
      "epoch": 0.8832,
      "grad_norm": 3.018706798553467,
      "learning_rate": 0.00016908293965173647,
      "logits/chosen": -9.76591682434082,
      "logits/rejected": -9.659721374511719,
      "logps/chosen": -163.0511932373047,
      "logps/rejected": -162.64566040039062,
      "loss": 2.2822,
      "rewards/accuracies": 0.5062500238418579,
      "rewards/chosen": -8.709479331970215,
      "rewards/margins": -0.0656307190656662,
      "rewards/rejected": -8.64384937286377,
      "step": 1380
    },
    {
      "epoch": 0.8896,
      "grad_norm": 3.0287458896636963,
      "learning_rate": 0.0001685709046658257,
      "logits/chosen": -11.272747039794922,
      "logits/rejected": -11.50857925415039,
      "logps/chosen": -167.57644653320312,
      "logps/rejected": -166.18272399902344,
      "loss": 2.1691,
      "rewards/accuracies": 0.4984374940395355,
      "rewards/chosen": -9.06457805633545,
      "rewards/margins": 0.02000097930431366,
      "rewards/rejected": -9.084578514099121,
      "step": 1390
    },
    {
      "epoch": 0.896,
      "grad_norm": 3.2298548221588135,
      "learning_rate": 0.00016805545364238742,
      "logits/chosen": -11.182902336120605,
      "logits/rejected": -11.362761497497559,
      "logps/chosen": -163.9131317138672,
      "logps/rejected": -168.52423095703125,
      "loss": 2.1242,
      "rewards/accuracies": 0.5453125238418579,
      "rewards/chosen": -9.0311279296875,
      "rewards/margins": 0.17400269210338593,
      "rewards/rejected": -9.205130577087402,
      "step": 1400
    },
    {
      "epoch": 0.9024,
      "grad_norm": 3.7543816566467285,
      "learning_rate": 0.00016753661225995167,
      "logits/chosen": -9.80344009399414,
      "logits/rejected": -9.923258781433105,
      "logps/chosen": -160.96957397460938,
      "logps/rejected": -166.22291564941406,
      "loss": 2.2272,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -8.689610481262207,
      "rewards/margins": 0.08632082492113113,
      "rewards/rejected": -8.775931358337402,
      "step": 1410
    },
    {
      "epoch": 0.9088,
      "grad_norm": 3.747035026550293,
      "learning_rate": 0.00016701440636594813,
      "logits/chosen": -10.439889907836914,
      "logits/rejected": -10.374776840209961,
      "logps/chosen": -173.2485809326172,
      "logps/rejected": -174.408203125,
      "loss": 2.2394,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": -9.627799034118652,
      "rewards/margins": 0.07862964272499084,
      "rewards/rejected": -9.706428527832031,
      "step": 1420
    },
    {
      "epoch": 0.9152,
      "grad_norm": 3.309446096420288,
      "learning_rate": 0.0001664888619754183,
      "logits/chosen": -10.159797668457031,
      "logits/rejected": -10.433038711547852,
      "logps/chosen": -174.3883819580078,
      "logps/rejected": -176.055908203125,
      "loss": 2.2553,
      "rewards/accuracies": 0.503125011920929,
      "rewards/chosen": -9.819378852844238,
      "rewards/margins": 0.07974501699209213,
      "rewards/rejected": -9.899124145507812,
      "step": 1430
    },
    {
      "epoch": 0.9216,
      "grad_norm": 3.5922915935516357,
      "learning_rate": 0.00016596000526971952,
      "logits/chosen": -10.796953201293945,
      "logits/rejected": -10.954156875610352,
      "logps/chosen": -165.26803588867188,
      "logps/rejected": -167.8671875,
      "loss": 2.1805,
      "rewards/accuracies": 0.551562488079071,
      "rewards/chosen": -8.852864265441895,
      "rewards/margins": 0.21113798022270203,
      "rewards/rejected": -9.064001083374023,
      "step": 1440
    },
    {
      "epoch": 0.928,
      "grad_norm": 3.1420252323150635,
      "learning_rate": 0.0001654278625952208,
      "logits/chosen": -11.135896682739258,
      "logits/rejected": -11.089228630065918,
      "logps/chosen": -173.77090454101562,
      "logps/rejected": -170.384521484375,
      "loss": 2.2767,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -9.58642864227295,
      "rewards/margins": 0.0631142407655716,
      "rewards/rejected": -9.649543762207031,
      "step": 1450
    },
    {
      "epoch": 0.9344,
      "grad_norm": 3.3245112895965576,
      "learning_rate": 0.0001648924604619901,
      "logits/chosen": -12.726564407348633,
      "logits/rejected": -12.723307609558105,
      "logps/chosen": -168.53836059570312,
      "logps/rejected": -172.23263549804688,
      "loss": 2.1683,
      "rewards/accuracies": 0.5218750238418579,
      "rewards/chosen": -9.392132759094238,
      "rewards/margins": 0.1711519956588745,
      "rewards/rejected": -9.563283920288086,
      "step": 1460
    },
    {
      "epoch": 0.9408,
      "grad_norm": 3.4824271202087402,
      "learning_rate": 0.00016435382554247382,
      "logits/chosen": -12.328094482421875,
      "logits/rejected": -12.44399642944336,
      "logps/chosen": -172.01419067382812,
      "logps/rejected": -175.72564697265625,
      "loss": 2.1053,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": -9.512375831604004,
      "rewards/margins": 0.08250149339437485,
      "rewards/rejected": -9.594877243041992,
      "step": 1470
    },
    {
      "epoch": 0.9472,
      "grad_norm": 3.579042434692383,
      "learning_rate": 0.00016381198467016806,
      "logits/chosen": -12.354829788208008,
      "logits/rejected": -12.597892761230469,
      "logps/chosen": -163.05050659179688,
      "logps/rejected": -167.27870178222656,
      "loss": 2.2109,
      "rewards/accuracies": 0.520312488079071,
      "rewards/chosen": -8.659170150756836,
      "rewards/margins": 0.12106269598007202,
      "rewards/rejected": -8.780232429504395,
      "step": 1480
    },
    {
      "epoch": 0.9536,
      "grad_norm": 3.2753753662109375,
      "learning_rate": 0.0001632669648382816,
      "logits/chosen": -12.015053749084473,
      "logits/rejected": -11.983448028564453,
      "logps/chosen": -161.43174743652344,
      "logps/rejected": -163.05026245117188,
      "loss": 2.1462,
      "rewards/accuracies": 0.535937488079071,
      "rewards/chosen": -8.539812088012695,
      "rewards/margins": 0.11230790615081787,
      "rewards/rejected": -8.652120590209961,
      "step": 1490
    },
    {
      "epoch": 0.96,
      "grad_norm": 3.9253926277160645,
      "learning_rate": 0.00016271879319839155,
      "logits/chosen": -10.670557022094727,
      "logits/rejected": -10.837163925170898,
      "logps/chosen": -169.21885681152344,
      "logps/rejected": -172.83786010742188,
      "loss": 2.1513,
      "rewards/accuracies": 0.5093749761581421,
      "rewards/chosen": -9.554901123046875,
      "rewards/margins": 0.13204219937324524,
      "rewards/rejected": -9.686944007873535,
      "step": 1500
    },
    {
      "epoch": 0.9664,
      "grad_norm": 3.599804639816284,
      "learning_rate": 0.00016216749705909043,
      "logits/chosen": -11.699225425720215,
      "logits/rejected": -11.633599281311035,
      "logps/chosen": -175.03550720214844,
      "logps/rejected": -178.16542053222656,
      "loss": 2.1739,
      "rewards/accuracies": 0.5015624761581421,
      "rewards/chosen": -9.942098617553711,
      "rewards/margins": 0.11610988527536392,
      "rewards/rejected": -10.058209419250488,
      "step": 1510
    },
    {
      "epoch": 0.9728,
      "grad_norm": 3.7188920974731445,
      "learning_rate": 0.00016161310388462571,
      "logits/chosen": -11.492910385131836,
      "logits/rejected": -11.39363956451416,
      "logps/chosen": -176.20181274414062,
      "logps/rejected": -173.8027801513672,
      "loss": 2.3277,
      "rewards/accuracies": 0.4703125059604645,
      "rewards/chosen": -9.915266036987305,
      "rewards/margins": -0.0678534284234047,
      "rewards/rejected": -9.847414016723633,
      "step": 1520
    },
    {
      "epoch": 0.9792,
      "grad_norm": 3.5917739868164062,
      "learning_rate": 0.00016105564129353182,
      "logits/chosen": -9.272394180297852,
      "logits/rejected": -9.293726921081543,
      "logps/chosen": -176.5831298828125,
      "logps/rejected": -177.0620880126953,
      "loss": 2.2009,
      "rewards/accuracies": 0.5140625238418579,
      "rewards/chosen": -10.060989379882812,
      "rewards/margins": 0.08201707154512405,
      "rewards/rejected": -10.143007278442383,
      "step": 1530
    },
    {
      "epoch": 0.9856,
      "grad_norm": 3.347285270690918,
      "learning_rate": 0.00016049513705725414,
      "logits/chosen": -7.090076446533203,
      "logits/rejected": -6.989572048187256,
      "logps/chosen": -173.42613220214844,
      "logps/rejected": -177.4744110107422,
      "loss": 2.1447,
      "rewards/accuracies": 0.5234375,
      "rewards/chosen": -9.709634780883789,
      "rewards/margins": 0.14576777815818787,
      "rewards/rejected": -9.855402946472168,
      "step": 1540
    },
    {
      "epoch": 0.992,
      "grad_norm": 3.6328206062316895,
      "learning_rate": 0.00015993161909876543,
      "logits/chosen": -6.687477111816406,
      "logits/rejected": -6.76375675201416,
      "logps/chosen": -166.49411010742188,
      "logps/rejected": -171.2296142578125,
      "loss": 2.1742,
      "rewards/accuracies": 0.515625,
      "rewards/chosen": -9.202909469604492,
      "rewards/margins": 0.22241568565368652,
      "rewards/rejected": -9.425325393676758,
      "step": 1550
    },
    {
      "epoch": 0.9984,
      "grad_norm": 2.9366865158081055,
      "learning_rate": 0.00015936511549117488,
      "logits/chosen": -7.262281894683838,
      "logits/rejected": -7.399430751800537,
      "logps/chosen": -169.55238342285156,
      "logps/rejected": -173.52032470703125,
      "loss": 2.0922,
      "rewards/accuracies": 0.567187488079071,
      "rewards/chosen": -9.556982040405273,
      "rewards/margins": 0.28070443868637085,
      "rewards/rejected": -9.837686538696289,
      "step": 1560
    },
    {
      "epoch": 1.00448,
      "grad_norm": 2.448105573654175,
      "learning_rate": 0.00015879565445632956,
      "logits/chosen": -8.792634963989258,
      "logits/rejected": -9.06413459777832,
      "logps/chosen": -164.64219665527344,
      "logps/rejected": -176.92625427246094,
      "loss": 1.7721,
      "rewards/accuracies": 0.6710526347160339,
      "rewards/chosen": -9.104253768920898,
      "rewards/margins": 0.8702870607376099,
      "rewards/rejected": -9.974541664123535,
      "step": 1570
    },
    {
      "epoch": 1.01088,
      "grad_norm": 2.743285655975342,
      "learning_rate": 0.00015822326436340837,
      "logits/chosen": -9.806174278259277,
      "logits/rejected": -9.909940719604492,
      "logps/chosen": -157.09994506835938,
      "logps/rejected": -170.2405548095703,
      "loss": 1.7499,
      "rewards/accuracies": 0.745312511920929,
      "rewards/chosen": -8.173135757446289,
      "rewards/margins": 1.3147895336151123,
      "rewards/rejected": -9.48792552947998,
      "step": 1580
    },
    {
      "epoch": 1.01728,
      "grad_norm": 4.0199055671691895,
      "learning_rate": 0.00015764797372750893,
      "logits/chosen": -12.648092269897461,
      "logits/rejected": -12.767992973327637,
      "logps/chosen": -154.98562622070312,
      "logps/rejected": -174.18077087402344,
      "loss": 1.7493,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -8.077580451965332,
      "rewards/margins": 1.4254709482192993,
      "rewards/rejected": -9.503049850463867,
      "step": 1590
    },
    {
      "epoch": 1.02368,
      "grad_norm": 2.7527170181274414,
      "learning_rate": 0.0001570698112082269,
      "logits/chosen": -14.879133224487305,
      "logits/rejected": -14.9249849319458,
      "logps/chosen": -156.85601806640625,
      "logps/rejected": -171.85635375976562,
      "loss": 1.6548,
      "rewards/accuracies": 0.734375,
      "rewards/chosen": -7.972421169281006,
      "rewards/margins": 1.42502760887146,
      "rewards/rejected": -9.397449493408203,
      "step": 1600
    },
    {
      "epoch": 1.03008,
      "grad_norm": 3.2522120475769043,
      "learning_rate": 0.00015648880560822822,
      "logits/chosen": -14.342313766479492,
      "logits/rejected": -14.305618286132812,
      "logps/chosen": -165.20755004882812,
      "logps/rejected": -176.38600158691406,
      "loss": 1.7528,
      "rewards/accuracies": 0.7015625238418579,
      "rewards/chosen": -8.741283416748047,
      "rewards/margins": 1.1308987140655518,
      "rewards/rejected": -9.872182846069336,
      "step": 1610
    },
    {
      "epoch": 1.03648,
      "grad_norm": 2.862647294998169,
      "learning_rate": 0.00015590498587181436,
      "logits/chosen": -15.211618423461914,
      "logits/rejected": -15.338717460632324,
      "logps/chosen": -163.05905151367188,
      "logps/rejected": -176.23260498046875,
      "loss": 1.7231,
      "rewards/accuracies": 0.7281249761581421,
      "rewards/chosen": -8.68237018585205,
      "rewards/margins": 1.296817660331726,
      "rewards/rejected": -9.97918701171875,
      "step": 1620
    },
    {
      "epoch": 1.04288,
      "grad_norm": 2.233276605606079,
      "learning_rate": 0.00015531838108348022,
      "logits/chosen": -16.073062896728516,
      "logits/rejected": -16.138141632080078,
      "logps/chosen": -155.5609893798828,
      "logps/rejected": -171.75332641601562,
      "loss": 1.7224,
      "rewards/accuracies": 0.7265625,
      "rewards/chosen": -8.161127090454102,
      "rewards/margins": 1.3491376638412476,
      "rewards/rejected": -9.51026439666748,
      "step": 1630
    },
    {
      "epoch": 1.04928,
      "grad_norm": 2.5837202072143555,
      "learning_rate": 0.0001547290204664653,
      "logits/chosen": -15.877766609191895,
      "logits/rejected": -15.765332221984863,
      "logps/chosen": -162.35684204101562,
      "logps/rejected": -177.3230438232422,
      "loss": 1.6616,
      "rewards/accuracies": 0.7562500238418579,
      "rewards/chosen": -8.488410949707031,
      "rewards/margins": 1.418255090713501,
      "rewards/rejected": -9.906665802001953,
      "step": 1640
    },
    {
      "epoch": 1.05568,
      "grad_norm": 3.272193431854248,
      "learning_rate": 0.0001541369333812979,
      "logits/chosen": -15.937965393066406,
      "logits/rejected": -15.885757446289062,
      "logps/chosen": -155.0772247314453,
      "logps/rejected": -170.62380981445312,
      "loss": 1.729,
      "rewards/accuracies": 0.7359374761581421,
      "rewards/chosen": -8.031198501586914,
      "rewards/margins": 1.4014636278152466,
      "rewards/rejected": -9.432662010192871,
      "step": 1650
    },
    {
      "epoch": 1.06208,
      "grad_norm": 2.361166477203369,
      "learning_rate": 0.0001535421493243324,
      "logits/chosen": -15.342641830444336,
      "logits/rejected": -15.557943344116211,
      "logps/chosen": -155.83038330078125,
      "logps/rejected": -170.91793823242188,
      "loss": 1.6026,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -8.195014953613281,
      "rewards/margins": 1.506528615951538,
      "rewards/rejected": -9.701543807983398,
      "step": 1660
    },
    {
      "epoch": 1.06848,
      "grad_norm": 3.1932804584503174,
      "learning_rate": 0.0001529446979262797,
      "logits/chosen": -15.250028610229492,
      "logits/rejected": -15.120165824890137,
      "logps/chosen": -155.81288146972656,
      "logps/rejected": -173.31924438476562,
      "loss": 1.7569,
      "rewards/accuracies": 0.723437488079071,
      "rewards/chosen": -8.082544326782227,
      "rewards/margins": 1.432628870010376,
      "rewards/rejected": -9.515172958374023,
      "step": 1670
    },
    {
      "epoch": 1.07488,
      "grad_norm": 2.8603997230529785,
      "learning_rate": 0.00015234460895073142,
      "logits/chosen": -14.843234062194824,
      "logits/rejected": -14.726921081542969,
      "logps/chosen": -157.62875366210938,
      "logps/rejected": -171.30908203125,
      "loss": 1.6996,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -8.176542282104492,
      "rewards/margins": 1.464599847793579,
      "rewards/rejected": -9.641141891479492,
      "step": 1680
    },
    {
      "epoch": 1.08128,
      "grad_norm": 2.690098762512207,
      "learning_rate": 0.00015174191229267684,
      "logits/chosen": -13.764431953430176,
      "logits/rejected": -13.728460311889648,
      "logps/chosen": -161.85983276367188,
      "logps/rejected": -176.21255493164062,
      "loss": 1.7407,
      "rewards/accuracies": 0.7109375,
      "rewards/chosen": -8.377401351928711,
      "rewards/margins": 1.3720781803131104,
      "rewards/rejected": -9.749481201171875,
      "step": 1690
    },
    {
      "epoch": 1.08768,
      "grad_norm": 2.1579275131225586,
      "learning_rate": 0.00015113663797701365,
      "logits/chosen": -12.566583633422852,
      "logits/rejected": -12.933636665344238,
      "logps/chosen": -157.82391357421875,
      "logps/rejected": -174.48976135253906,
      "loss": 1.574,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -8.330343246459961,
      "rewards/margins": 1.3388721942901611,
      "rewards/rejected": -9.669215202331543,
      "step": 1700
    },
    {
      "epoch": 1.09408,
      "grad_norm": 2.974168300628662,
      "learning_rate": 0.00015052881615705237,
      "logits/chosen": -12.567286491394043,
      "logits/rejected": -12.415933609008789,
      "logps/chosen": -153.26718139648438,
      "logps/rejected": -171.19522094726562,
      "loss": 1.6119,
      "rewards/accuracies": 0.770312488079071,
      "rewards/chosen": -7.777098655700684,
      "rewards/margins": 1.6485611200332642,
      "rewards/rejected": -9.4256591796875,
      "step": 1710
    },
    {
      "epoch": 1.10048,
      "grad_norm": 2.446274518966675,
      "learning_rate": 0.00014991847711301394,
      "logits/chosen": -7.998588562011719,
      "logits/rejected": -7.753011226654053,
      "logps/chosen": -162.5478515625,
      "logps/rejected": -176.6874237060547,
      "loss": 1.7247,
      "rewards/accuracies": 0.7328125238418579,
      "rewards/chosen": -8.590906143188477,
      "rewards/margins": 1.4454675912857056,
      "rewards/rejected": -10.03637409210205,
      "step": 1720
    },
    {
      "epoch": 1.10688,
      "grad_norm": 3.002528190612793,
      "learning_rate": 0.00014930565125052144,
      "logits/chosen": -5.472768783569336,
      "logits/rejected": -5.5923075675964355,
      "logps/chosen": -158.20420837402344,
      "logps/rejected": -172.4139862060547,
      "loss": 1.7212,
      "rewards/accuracies": 0.729687511920929,
      "rewards/chosen": -8.423742294311523,
      "rewards/margins": 1.2998988628387451,
      "rewards/rejected": -9.723642349243164,
      "step": 1730
    },
    {
      "epoch": 1.11328,
      "grad_norm": 2.816875457763672,
      "learning_rate": 0.00014869036909908524,
      "logits/chosen": -8.187597274780273,
      "logits/rejected": -8.353755950927734,
      "logps/chosen": -157.21337890625,
      "logps/rejected": -171.73143005371094,
      "loss": 1.7264,
      "rewards/accuracies": 0.7515624761581421,
      "rewards/chosen": -8.118722915649414,
      "rewards/margins": 1.3705003261566162,
      "rewards/rejected": -9.48922348022461,
      "step": 1740
    },
    {
      "epoch": 1.11968,
      "grad_norm": 3.4165968894958496,
      "learning_rate": 0.0001480726613105821,
      "logits/chosen": -10.876441955566406,
      "logits/rejected": -11.092374801635742,
      "logps/chosen": -160.2606964111328,
      "logps/rejected": -174.50808715820312,
      "loss": 1.7366,
      "rewards/accuracies": 0.721875011920929,
      "rewards/chosen": -8.492707252502441,
      "rewards/margins": 1.247520923614502,
      "rewards/rejected": -9.740228652954102,
      "step": 1750
    },
    {
      "epoch": 1.12608,
      "grad_norm": 2.939852714538574,
      "learning_rate": 0.00014745255865772816,
      "logits/chosen": -12.164281845092773,
      "logits/rejected": -11.967123985290527,
      "logps/chosen": -159.91632080078125,
      "logps/rejected": -175.27964782714844,
      "loss": 1.6419,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -8.478250503540039,
      "rewards/margins": 1.387609839439392,
      "rewards/rejected": -9.86585807800293,
      "step": 1760
    },
    {
      "epoch": 1.13248,
      "grad_norm": 2.9286584854125977,
      "learning_rate": 0.00014683009203254597,
      "logits/chosen": -13.11848258972168,
      "logits/rejected": -13.15654468536377,
      "logps/chosen": -160.15357971191406,
      "logps/rejected": -174.3344268798828,
      "loss": 1.6342,
      "rewards/accuracies": 0.765625,
      "rewards/chosen": -8.370901107788086,
      "rewards/margins": 1.5095419883728027,
      "rewards/rejected": -9.880444526672363,
      "step": 1770
    },
    {
      "epoch": 1.13888,
      "grad_norm": 2.9002981185913086,
      "learning_rate": 0.0001462052924448255,
      "logits/chosen": -14.88294792175293,
      "logits/rejected": -14.805450439453125,
      "logps/chosen": -157.4772491455078,
      "logps/rejected": -172.34246826171875,
      "loss": 1.6444,
      "rewards/accuracies": 0.729687511920929,
      "rewards/chosen": -8.209248542785645,
      "rewards/margins": 1.5042356252670288,
      "rewards/rejected": -9.713483810424805,
      "step": 1780
    },
    {
      "epoch": 1.14528,
      "grad_norm": 3.486943483352661,
      "learning_rate": 0.00014557819102057926,
      "logits/chosen": -13.91557502746582,
      "logits/rejected": -14.156927108764648,
      "logps/chosen": -162.78932189941406,
      "logps/rejected": -177.43069458007812,
      "loss": 1.5865,
      "rewards/accuracies": 0.7328125238418579,
      "rewards/chosen": -8.686504364013672,
      "rewards/margins": 1.4378414154052734,
      "rewards/rejected": -10.124345779418945,
      "step": 1790
    },
    {
      "epoch": 1.15168,
      "grad_norm": 2.7565557956695557,
      "learning_rate": 0.00014494881900049185,
      "logits/chosen": -11.96634292602539,
      "logits/rejected": -11.701539039611816,
      "logps/chosen": -159.68125915527344,
      "logps/rejected": -173.40040588378906,
      "loss": 1.6956,
      "rewards/accuracies": 0.723437488079071,
      "rewards/chosen": -8.451472282409668,
      "rewards/margins": 1.2823983430862427,
      "rewards/rejected": -9.733872413635254,
      "step": 1800
    },
    {
      "epoch": 1.15808,
      "grad_norm": 2.7967350482940674,
      "learning_rate": 0.0001443172077383633,
      "logits/chosen": -10.38396167755127,
      "logits/rejected": -10.57539176940918,
      "logps/chosen": -152.4137725830078,
      "logps/rejected": -169.12158203125,
      "loss": 1.7228,
      "rewards/accuracies": 0.7281249761581421,
      "rewards/chosen": -7.9045891761779785,
      "rewards/margins": 1.2062089443206787,
      "rewards/rejected": -9.110797882080078,
      "step": 1810
    },
    {
      "epoch": 1.16448,
      "grad_norm": 3.1003119945526123,
      "learning_rate": 0.00014368338869954746,
      "logits/chosen": -11.189654350280762,
      "logits/rejected": -11.248568534851074,
      "logps/chosen": -159.66891479492188,
      "logps/rejected": -175.43960571289062,
      "loss": 1.688,
      "rewards/accuracies": 0.765625,
      "rewards/chosen": -8.365842819213867,
      "rewards/margins": 1.5045340061187744,
      "rewards/rejected": -9.870376586914062,
      "step": 1820
    },
    {
      "epoch": 1.17088,
      "grad_norm": 3.236785650253296,
      "learning_rate": 0.00014304739345938415,
      "logits/chosen": -13.136541366577148,
      "logits/rejected": -12.798707008361816,
      "logps/chosen": -165.50962829589844,
      "logps/rejected": -181.29135131835938,
      "loss": 1.7021,
      "rewards/accuracies": 0.734375,
      "rewards/chosen": -8.958740234375,
      "rewards/margins": 1.3802598714828491,
      "rewards/rejected": -10.338998794555664,
      "step": 1830
    },
    {
      "epoch": 1.17728,
      "grad_norm": 2.4715819358825684,
      "learning_rate": 0.00014240925370162646,
      "logits/chosen": -13.049321174621582,
      "logits/rejected": -13.092462539672852,
      "logps/chosen": -157.5144500732422,
      "logps/rejected": -174.9036865234375,
      "loss": 1.6825,
      "rewards/accuracies": 0.7359374761581421,
      "rewards/chosen": -8.543167114257812,
      "rewards/margins": 1.3911988735198975,
      "rewards/rejected": -9.934366226196289,
      "step": 1840
    },
    {
      "epoch": 1.18368,
      "grad_norm": 2.8774678707122803,
      "learning_rate": 0.0001417690012168621,
      "logits/chosen": -10.977560997009277,
      "logits/rejected": -10.873296737670898,
      "logps/chosen": -154.66830444335938,
      "logps/rejected": -172.54945373535156,
      "loss": 1.6743,
      "rewards/accuracies": 0.7515624761581421,
      "rewards/chosen": -8.09846019744873,
      "rewards/margins": 1.4332401752471924,
      "rewards/rejected": -9.53170108795166,
      "step": 1850
    },
    {
      "epoch": 1.19008,
      "grad_norm": 4.310963153839111,
      "learning_rate": 0.00014112666790092973,
      "logits/chosen": -11.159524917602539,
      "logits/rejected": -11.183958053588867,
      "logps/chosen": -155.65541076660156,
      "logps/rejected": -170.28616333007812,
      "loss": 1.7823,
      "rewards/accuracies": 0.7265625,
      "rewards/chosen": -8.085692405700684,
      "rewards/margins": 1.3038671016693115,
      "rewards/rejected": -9.389559745788574,
      "step": 1860
    },
    {
      "epoch": 1.19648,
      "grad_norm": 3.423954963684082,
      "learning_rate": 0.00014048228575333014,
      "logits/chosen": -10.79924488067627,
      "logits/rejected": -10.712087631225586,
      "logps/chosen": -155.6945343017578,
      "logps/rejected": -172.7296600341797,
      "loss": 1.7442,
      "rewards/accuracies": 0.745312511920929,
      "rewards/chosen": -8.027517318725586,
      "rewards/margins": 1.4831348657608032,
      "rewards/rejected": -9.510652542114258,
      "step": 1870
    },
    {
      "epoch": 1.20288,
      "grad_norm": 2.7281887531280518,
      "learning_rate": 0.00013983588687563187,
      "logits/chosen": -10.949028968811035,
      "logits/rejected": -11.075804710388184,
      "logps/chosen": -158.1617889404297,
      "logps/rejected": -173.6666259765625,
      "loss": 1.6685,
      "rewards/accuracies": 0.7671874761581421,
      "rewards/chosen": -8.347513198852539,
      "rewards/margins": 1.4622251987457275,
      "rewards/rejected": -9.809738159179688,
      "step": 1880
    },
    {
      "epoch": 1.20928,
      "grad_norm": 2.955286979675293,
      "learning_rate": 0.0001391875034698721,
      "logits/chosen": -12.510692596435547,
      "logits/rejected": -12.558691024780273,
      "logps/chosen": -162.5229949951172,
      "logps/rejected": -176.87989807128906,
      "loss": 1.7514,
      "rewards/accuracies": 0.7015625238418579,
      "rewards/chosen": -8.694967269897461,
      "rewards/margins": 1.1946455240249634,
      "rewards/rejected": -9.889612197875977,
      "step": 1890
    },
    {
      "epoch": 1.21568,
      "grad_norm": 4.092676639556885,
      "learning_rate": 0.0001385371678369525,
      "logits/chosen": -14.697726249694824,
      "logits/rejected": -14.331016540527344,
      "logps/chosen": -159.51315307617188,
      "logps/rejected": -174.65330505371094,
      "loss": 1.7173,
      "rewards/accuracies": 0.7281249761581421,
      "rewards/chosen": -8.491495132446289,
      "rewards/margins": 1.2956202030181885,
      "rewards/rejected": -9.787116050720215,
      "step": 1900
    },
    {
      "epoch": 1.22208,
      "grad_norm": 3.3975143432617188,
      "learning_rate": 0.00013788491237502992,
      "logits/chosen": -13.746088027954102,
      "logits/rejected": -13.894098281860352,
      "logps/chosen": -157.0726776123047,
      "logps/rejected": -175.70492553710938,
      "loss": 1.6955,
      "rewards/accuracies": 0.7484375238418579,
      "rewards/chosen": -8.093671798706055,
      "rewards/margins": 1.5895265340805054,
      "rewards/rejected": -9.683197021484375,
      "step": 1910
    },
    {
      "epoch": 1.22848,
      "grad_norm": 2.894618034362793,
      "learning_rate": 0.00013723076957790258,
      "logits/chosen": -11.986807823181152,
      "logits/rejected": -12.106657028198242,
      "logps/chosen": -159.49728393554688,
      "logps/rejected": -174.13626098632812,
      "loss": 1.7017,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -8.107397079467773,
      "rewards/margins": 1.4896152019500732,
      "rewards/rejected": -9.597013473510742,
      "step": 1920
    },
    {
      "epoch": 1.23488,
      "grad_norm": 3.219984292984009,
      "learning_rate": 0.00013657477203339108,
      "logits/chosen": -10.380437850952148,
      "logits/rejected": -10.311944007873535,
      "logps/chosen": -160.3615264892578,
      "logps/rejected": -175.19229125976562,
      "loss": 1.7879,
      "rewards/accuracies": 0.7171875238418579,
      "rewards/chosen": -8.585573196411133,
      "rewards/margins": 1.1955386400222778,
      "rewards/rejected": -9.781110763549805,
      "step": 1930
    },
    {
      "epoch": 1.24128,
      "grad_norm": 3.0978496074676514,
      "learning_rate": 0.00013591695242171515,
      "logits/chosen": -7.963534355163574,
      "logits/rejected": -7.811949253082275,
      "logps/chosen": -162.76284790039062,
      "logps/rejected": -175.0464324951172,
      "loss": 1.7315,
      "rewards/accuracies": 0.7015625238418579,
      "rewards/chosen": -8.745792388916016,
      "rewards/margins": 1.0725239515304565,
      "rewards/rejected": -9.818317413330078,
      "step": 1940
    },
    {
      "epoch": 1.24768,
      "grad_norm": 2.9530863761901855,
      "learning_rate": 0.0001352573435138655,
      "logits/chosen": -6.436352729797363,
      "logits/rejected": -6.360939025878906,
      "logps/chosen": -164.7979278564453,
      "logps/rejected": -182.0880584716797,
      "loss": 1.6483,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -8.694364547729492,
      "rewards/margins": 1.5559186935424805,
      "rewards/rejected": -10.250284194946289,
      "step": 1950
    },
    {
      "epoch": 1.25408,
      "grad_norm": 2.61635422706604,
      "learning_rate": 0.00013459597816997123,
      "logits/chosen": -7.580008029937744,
      "logits/rejected": -7.551710605621338,
      "logps/chosen": -159.2777557373047,
      "logps/rejected": -178.27865600585938,
      "loss": 1.6891,
      "rewards/accuracies": 0.739062488079071,
      "rewards/chosen": -8.481788635253906,
      "rewards/margins": 1.3830921649932861,
      "rewards/rejected": -9.864879608154297,
      "step": 1960
    },
    {
      "epoch": 1.26048,
      "grad_norm": 2.699190616607666,
      "learning_rate": 0.00013393288933766297,
      "logits/chosen": -10.641430854797363,
      "logits/rejected": -10.72678279876709,
      "logps/chosen": -160.75991821289062,
      "logps/rejected": -178.28395080566406,
      "loss": 1.6856,
      "rewards/accuracies": 0.7640625238418579,
      "rewards/chosen": -8.510175704956055,
      "rewards/margins": 1.469089150428772,
      "rewards/rejected": -9.979265213012695,
      "step": 1970
    },
    {
      "epoch": 1.26688,
      "grad_norm": 2.707321882247925,
      "learning_rate": 0.0001332681100504313,
      "logits/chosen": -11.330686569213867,
      "logits/rejected": -11.508524894714355,
      "logps/chosen": -156.82635498046875,
      "logps/rejected": -172.2116241455078,
      "loss": 1.6938,
      "rewards/accuracies": 0.7640625238418579,
      "rewards/chosen": -8.30526351928711,
      "rewards/margins": 1.370674967765808,
      "rewards/rejected": -9.675938606262207,
      "step": 1980
    },
    {
      "epoch": 1.27328,
      "grad_norm": 2.8239636421203613,
      "learning_rate": 0.0001326016734259812,
      "logits/chosen": -10.62530517578125,
      "logits/rejected": -10.758617401123047,
      "logps/chosen": -153.2906951904297,
      "logps/rejected": -169.53262329101562,
      "loss": 1.726,
      "rewards/accuracies": 0.7171875238418579,
      "rewards/chosen": -8.07170295715332,
      "rewards/margins": 1.339235544204712,
      "rewards/rejected": -9.410937309265137,
      "step": 1990
    },
    {
      "epoch": 1.27968,
      "grad_norm": 2.8158836364746094,
      "learning_rate": 0.00013193361266458227,
      "logits/chosen": -9.886503219604492,
      "logits/rejected": -9.917642593383789,
      "logps/chosen": -157.9275360107422,
      "logps/rejected": -173.32931518554688,
      "loss": 1.6582,
      "rewards/accuracies": 0.745312511920929,
      "rewards/chosen": -8.109076499938965,
      "rewards/margins": 1.3841396570205688,
      "rewards/rejected": -9.493216514587402,
      "step": 2000
    },
    {
      "epoch": 1.2860800000000001,
      "grad_norm": 2.9917891025543213,
      "learning_rate": 0.00013126396104741462,
      "logits/chosen": -8.9553861618042,
      "logits/rejected": -8.797320365905762,
      "logps/chosen": -155.9310302734375,
      "logps/rejected": -168.61666870117188,
      "loss": 1.6908,
      "rewards/accuracies": 0.731249988079071,
      "rewards/chosen": -8.22843074798584,
      "rewards/margins": 1.2057985067367554,
      "rewards/rejected": -9.434228897094727,
      "step": 2010
    },
    {
      "epoch": 1.29248,
      "grad_norm": 2.7728943824768066,
      "learning_rate": 0.00013059275193491108,
      "logits/chosen": -10.790156364440918,
      "logits/rejected": -10.893714904785156,
      "logps/chosen": -153.7485809326172,
      "logps/rejected": -171.44847106933594,
      "loss": 1.6692,
      "rewards/accuracies": 0.7406250238418579,
      "rewards/chosen": -8.192346572875977,
      "rewards/margins": 1.4246318340301514,
      "rewards/rejected": -9.616978645324707,
      "step": 2020
    },
    {
      "epoch": 1.29888,
      "grad_norm": 2.3509368896484375,
      "learning_rate": 0.00012992001876509503,
      "logits/chosen": -11.144579887390137,
      "logits/rejected": -11.428284645080566,
      "logps/chosen": -156.5750732421875,
      "logps/rejected": -175.36322021484375,
      "loss": 1.6423,
      "rewards/accuracies": 0.746874988079071,
      "rewards/chosen": -8.21934700012207,
      "rewards/margins": 1.405991554260254,
      "rewards/rejected": -9.62533950805664,
      "step": 2030
    },
    {
      "epoch": 1.30528,
      "grad_norm": 2.564466714859009,
      "learning_rate": 0.0001292457950519148,
      "logits/chosen": -9.939190864562988,
      "logits/rejected": -9.803438186645508,
      "logps/chosen": -159.64309692382812,
      "logps/rejected": -172.6637725830078,
      "loss": 1.6431,
      "rewards/accuracies": 0.7515624761581421,
      "rewards/chosen": -8.300497055053711,
      "rewards/margins": 1.4060680866241455,
      "rewards/rejected": -9.706565856933594,
      "step": 2040
    },
    {
      "epoch": 1.31168,
      "grad_norm": 3.215975046157837,
      "learning_rate": 0.00012857011438357393,
      "logits/chosen": -8.873250007629395,
      "logits/rejected": -8.705349922180176,
      "logps/chosen": -161.2798614501953,
      "logps/rejected": -175.0360870361328,
      "loss": 1.6536,
      "rewards/accuracies": 0.746874988079071,
      "rewards/chosen": -8.60193920135498,
      "rewards/margins": 1.3316514492034912,
      "rewards/rejected": -9.93359088897705,
      "step": 2050
    },
    {
      "epoch": 1.31808,
      "grad_norm": 2.491194486618042,
      "learning_rate": 0.0001278930104208581,
      "logits/chosen": -8.77529525756836,
      "logits/rejected": -8.667472839355469,
      "logps/chosen": -162.3097686767578,
      "logps/rejected": -177.04635620117188,
      "loss": 1.7298,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -8.643129348754883,
      "rewards/margins": 1.3790333271026611,
      "rewards/rejected": -10.022163391113281,
      "step": 2060
    },
    {
      "epoch": 1.3244799999999999,
      "grad_norm": 2.391118049621582,
      "learning_rate": 0.0001272145168954579,
      "logits/chosen": -9.14219856262207,
      "logits/rejected": -9.226075172424316,
      "logps/chosen": -158.74810791015625,
      "logps/rejected": -173.70242309570312,
      "loss": 1.6908,
      "rewards/accuracies": 0.768750011920929,
      "rewards/chosen": -8.248926162719727,
      "rewards/margins": 1.3772342205047607,
      "rewards/rejected": -9.626161575317383,
      "step": 2070
    },
    {
      "epoch": 1.33088,
      "grad_norm": 2.9335060119628906,
      "learning_rate": 0.00012653466760828878,
      "logits/chosen": -10.003621101379395,
      "logits/rejected": -10.076767921447754,
      "logps/chosen": -158.78219604492188,
      "logps/rejected": -171.45986938476562,
      "loss": 1.6845,
      "rewards/accuracies": 0.7124999761581421,
      "rewards/chosen": -8.3162841796875,
      "rewards/margins": 1.1981148719787598,
      "rewards/rejected": -9.514398574829102,
      "step": 2080
    },
    {
      "epoch": 1.33728,
      "grad_norm": 2.748520612716675,
      "learning_rate": 0.0001258534964278068,
      "logits/chosen": -9.05868148803711,
      "logits/rejected": -9.107335090637207,
      "logps/chosen": -159.30767822265625,
      "logps/rejected": -174.3665008544922,
      "loss": 1.6602,
      "rewards/accuracies": 0.7671874761581421,
      "rewards/chosen": -8.38839340209961,
      "rewards/margins": 1.4337712526321411,
      "rewards/rejected": -9.822164535522461,
      "step": 2090
    },
    {
      "epoch": 1.34368,
      "grad_norm": 2.3438003063201904,
      "learning_rate": 0.00012517103728832177,
      "logits/chosen": -9.749611854553223,
      "logits/rejected": -9.749051094055176,
      "logps/chosen": -156.60543823242188,
      "logps/rejected": -169.92372131347656,
      "loss": 1.6449,
      "rewards/accuracies": 0.7281249761581421,
      "rewards/chosen": -8.243650436401367,
      "rewards/margins": 1.2715638875961304,
      "rewards/rejected": -9.515214920043945,
      "step": 2100
    },
    {
      "epoch": 1.35008,
      "grad_norm": 2.2856850624084473,
      "learning_rate": 0.00012448732418830633,
      "logits/chosen": -10.095052719116211,
      "logits/rejected": -10.071288108825684,
      "logps/chosen": -157.70870971679688,
      "logps/rejected": -169.84426879882812,
      "loss": 1.7743,
      "rewards/accuracies": 0.7046874761581421,
      "rewards/chosen": -8.059846878051758,
      "rewards/margins": 1.1737658977508545,
      "rewards/rejected": -9.233613014221191,
      "step": 2110
    },
    {
      "epoch": 1.35648,
      "grad_norm": 3.2185773849487305,
      "learning_rate": 0.00012380239118870253,
      "logits/chosen": -9.227420806884766,
      "logits/rejected": -9.084573745727539,
      "logps/chosen": -159.68157958984375,
      "logps/rejected": -175.28997802734375,
      "loss": 1.7249,
      "rewards/accuracies": 0.7484375238418579,
      "rewards/chosen": -8.329865455627441,
      "rewards/margins": 1.3942008018493652,
      "rewards/rejected": -9.724066734313965,
      "step": 2120
    },
    {
      "epoch": 1.36288,
      "grad_norm": 3.4000191688537598,
      "learning_rate": 0.00012311627241122484,
      "logits/chosen": -8.414541244506836,
      "logits/rejected": -8.34267520904541,
      "logps/chosen": -163.7307891845703,
      "logps/rejected": -175.4353485107422,
      "loss": 1.65,
      "rewards/accuracies": 0.7406250238418579,
      "rewards/chosen": -8.596944808959961,
      "rewards/margins": 1.3783780336380005,
      "rewards/rejected": -9.975322723388672,
      "step": 2130
    },
    {
      "epoch": 1.36928,
      "grad_norm": 3.126098155975342,
      "learning_rate": 0.0001224290020366603,
      "logits/chosen": -8.729089736938477,
      "logits/rejected": -8.616083145141602,
      "logps/chosen": -160.57095336914062,
      "logps/rejected": -176.22833251953125,
      "loss": 1.7345,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -8.505839347839355,
      "rewards/margins": 1.3147608041763306,
      "rewards/rejected": -9.820599555969238,
      "step": 2140
    },
    {
      "epoch": 1.37568,
      "grad_norm": 2.57574725151062,
      "learning_rate": 0.00012174061430316584,
      "logits/chosen": -7.1678948402404785,
      "logits/rejected": -7.198220252990723,
      "logps/chosen": -155.49583435058594,
      "logps/rejected": -170.7270965576172,
      "loss": 1.7201,
      "rewards/accuracies": 0.731249988079071,
      "rewards/chosen": -8.221003532409668,
      "rewards/margins": 1.2496639490127563,
      "rewards/rejected": -9.470667839050293,
      "step": 2150
    },
    {
      "epoch": 1.38208,
      "grad_norm": 2.6973628997802734,
      "learning_rate": 0.00012105114350456243,
      "logits/chosen": -8.470382690429688,
      "logits/rejected": -8.634445190429688,
      "logps/chosen": -155.42271423339844,
      "logps/rejected": -168.00830078125,
      "loss": 1.7229,
      "rewards/accuracies": 0.7281249761581421,
      "rewards/chosen": -7.9332733154296875,
      "rewards/margins": 1.2474665641784668,
      "rewards/rejected": -9.18073844909668,
      "step": 2160
    },
    {
      "epoch": 1.38848,
      "grad_norm": 3.0032317638397217,
      "learning_rate": 0.00012036062398862685,
      "logits/chosen": -9.302780151367188,
      "logits/rejected": -9.477182388305664,
      "logps/chosen": -153.96603393554688,
      "logps/rejected": -169.54954528808594,
      "loss": 1.6467,
      "rewards/accuracies": 0.7484375238418579,
      "rewards/chosen": -7.9913506507873535,
      "rewards/margins": 1.2912969589233398,
      "rewards/rejected": -9.282648086547852,
      "step": 2170
    },
    {
      "epoch": 1.3948800000000001,
      "grad_norm": 2.5936145782470703,
      "learning_rate": 0.00011966909015538031,
      "logits/chosen": -10.747135162353516,
      "logits/rejected": -10.750259399414062,
      "logps/chosen": -159.1223602294922,
      "logps/rejected": -174.6461181640625,
      "loss": 1.7479,
      "rewards/accuracies": 0.7171875238418579,
      "rewards/chosen": -8.217333793640137,
      "rewards/margins": 1.2978380918502808,
      "rewards/rejected": -9.515172004699707,
      "step": 2180
    },
    {
      "epoch": 1.40128,
      "grad_norm": 2.618767023086548,
      "learning_rate": 0.00011897657645537492,
      "logits/chosen": -12.53624153137207,
      "logits/rejected": -12.681727409362793,
      "logps/chosen": -157.00180053710938,
      "logps/rejected": -173.11854553222656,
      "loss": 1.6818,
      "rewards/accuracies": 0.7562500238418579,
      "rewards/chosen": -8.186680793762207,
      "rewards/margins": 1.3463165760040283,
      "rewards/rejected": -9.532997131347656,
      "step": 2190
    },
    {
      "epoch": 1.40768,
      "grad_norm": 3.040530204772949,
      "learning_rate": 0.00011828311738797748,
      "logits/chosen": -12.371105194091797,
      "logits/rejected": -12.276103019714355,
      "logps/chosen": -158.4402618408203,
      "logps/rejected": -173.40603637695312,
      "loss": 1.646,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -8.193422317504883,
      "rewards/margins": 1.4244036674499512,
      "rewards/rejected": -9.617826461791992,
      "step": 2200
    },
    {
      "epoch": 1.41408,
      "grad_norm": 3.3896360397338867,
      "learning_rate": 0.00011758874749965065,
      "logits/chosen": -9.76368522644043,
      "logits/rejected": -9.897856712341309,
      "logps/chosen": -158.94371032714844,
      "logps/rejected": -172.39967346191406,
      "loss": 1.7114,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -8.27457046508789,
      "rewards/margins": 1.3502106666564941,
      "rewards/rejected": -9.624780654907227,
      "step": 2210
    },
    {
      "epoch": 1.42048,
      "grad_norm": 2.5645127296447754,
      "learning_rate": 0.000116893501382232,
      "logits/chosen": -9.15594482421875,
      "logits/rejected": -9.252359390258789,
      "logps/chosen": -152.62948608398438,
      "logps/rejected": -169.04978942871094,
      "loss": 1.5762,
      "rewards/accuracies": 0.7828124761581421,
      "rewards/chosen": -7.724005222320557,
      "rewards/margins": 1.493287444114685,
      "rewards/rejected": -9.217292785644531,
      "step": 2220
    },
    {
      "epoch": 1.42688,
      "grad_norm": 2.444417953491211,
      "learning_rate": 0.00011619741367121069,
      "logits/chosen": -8.596498489379883,
      "logits/rejected": -8.453043937683105,
      "logps/chosen": -150.2427520751953,
      "logps/rejected": -164.637451171875,
      "loss": 1.6728,
      "rewards/accuracies": 0.734375,
      "rewards/chosen": -7.551142692565918,
      "rewards/margins": 1.2045297622680664,
      "rewards/rejected": -8.755671501159668,
      "step": 2230
    },
    {
      "epoch": 1.4332799999999999,
      "grad_norm": 2.7621395587921143,
      "learning_rate": 0.00011550051904400217,
      "logits/chosen": -9.053661346435547,
      "logits/rejected": -8.97739315032959,
      "logps/chosen": -152.9693603515625,
      "logps/rejected": -167.22044372558594,
      "loss": 1.6671,
      "rewards/accuracies": 0.7437499761581421,
      "rewards/chosen": -7.624552249908447,
      "rewards/margins": 1.4420040845870972,
      "rewards/rejected": -9.066556930541992,
      "step": 2240
    },
    {
      "epoch": 1.43968,
      "grad_norm": 2.5190412998199463,
      "learning_rate": 0.00011480285221822034,
      "logits/chosen": -9.469426155090332,
      "logits/rejected": -9.462926864624023,
      "logps/chosen": -156.03317260742188,
      "logps/rejected": -174.66830444335938,
      "loss": 1.5992,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -8.131101608276367,
      "rewards/margins": 1.516923427581787,
      "rewards/rejected": -9.648025512695312,
      "step": 2250
    },
    {
      "epoch": 1.44608,
      "grad_norm": 3.266167402267456,
      "learning_rate": 0.00011410444794994832,
      "logits/chosen": -10.172538757324219,
      "logits/rejected": -10.47927474975586,
      "logps/chosen": -158.3643798828125,
      "logps/rejected": -173.12828063964844,
      "loss": 1.6919,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -8.243884086608887,
      "rewards/margins": 1.3064109086990356,
      "rewards/rejected": -9.550294876098633,
      "step": 2260
    },
    {
      "epoch": 1.45248,
      "grad_norm": 1.9904011487960815,
      "learning_rate": 0.00011340534103200677,
      "logits/chosen": -10.730539321899414,
      "logits/rejected": -10.861699104309082,
      "logps/chosen": -159.044677734375,
      "logps/rejected": -173.3614501953125,
      "loss": 1.658,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -8.329638481140137,
      "rewards/margins": 1.4036891460418701,
      "rewards/rejected": -9.733327865600586,
      "step": 2270
    },
    {
      "epoch": 1.45888,
      "grad_norm": 3.3805155754089355,
      "learning_rate": 0.00011270556629222069,
      "logits/chosen": -12.323959350585938,
      "logits/rejected": -12.270915985107422,
      "logps/chosen": -159.66038513183594,
      "logps/rejected": -171.92637634277344,
      "loss": 1.7223,
      "rewards/accuracies": 0.699999988079071,
      "rewards/chosen": -8.441449165344238,
      "rewards/margins": 1.2040064334869385,
      "rewards/rejected": -9.645454406738281,
      "step": 2280
    },
    {
      "epoch": 1.46528,
      "grad_norm": 2.5117669105529785,
      "learning_rate": 0.00011200515859168436,
      "logits/chosen": -11.769891738891602,
      "logits/rejected": -11.839441299438477,
      "logps/chosen": -159.886474609375,
      "logps/rejected": -181.6136932373047,
      "loss": 1.6504,
      "rewards/accuracies": 0.760937511920929,
      "rewards/chosen": -8.698452949523926,
      "rewards/margins": 1.451475977897644,
      "rewards/rejected": -10.14992904663086,
      "step": 2290
    },
    {
      "epoch": 1.47168,
      "grad_norm": 2.7349014282226562,
      "learning_rate": 0.00011130415282302467,
      "logits/chosen": -11.519424438476562,
      "logits/rejected": -11.35506820678711,
      "logps/chosen": -157.8602294921875,
      "logps/rejected": -170.51730346679688,
      "loss": 1.6508,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -8.266101837158203,
      "rewards/margins": 1.3422290086746216,
      "rewards/rejected": -9.608330726623535,
      "step": 2300
    },
    {
      "epoch": 1.47808,
      "grad_norm": 2.925361394882202,
      "learning_rate": 0.00011060258390866271,
      "logits/chosen": -9.989765167236328,
      "logits/rejected": -9.914156913757324,
      "logps/chosen": -158.02569580078125,
      "logps/rejected": -175.65792846679688,
      "loss": 1.6663,
      "rewards/accuracies": 0.7562500238418579,
      "rewards/chosen": -8.30293083190918,
      "rewards/margins": 1.3243074417114258,
      "rewards/rejected": -9.627238273620605,
      "step": 2310
    },
    {
      "epoch": 1.48448,
      "grad_norm": 2.5080618858337402,
      "learning_rate": 0.00010990048679907428,
      "logits/chosen": -8.187490463256836,
      "logits/rejected": -8.211634635925293,
      "logps/chosen": -153.1887664794922,
      "logps/rejected": -169.1476287841797,
      "loss": 1.7199,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -7.964331150054932,
      "rewards/margins": 1.3533557653427124,
      "rewards/rejected": -9.317687034606934,
      "step": 2320
    },
    {
      "epoch": 1.49088,
      "grad_norm": 3.64512300491333,
      "learning_rate": 0.00010919789647104848,
      "logits/chosen": -7.067101955413818,
      "logits/rejected": -6.921568393707275,
      "logps/chosen": -159.1411895751953,
      "logps/rejected": -171.80044555664062,
      "loss": 1.7353,
      "rewards/accuracies": 0.7203124761581421,
      "rewards/chosen": -8.220987319946289,
      "rewards/margins": 1.275538444519043,
      "rewards/rejected": -9.496526718139648,
      "step": 2330
    },
    {
      "epoch": 1.49728,
      "grad_norm": 2.8570704460144043,
      "learning_rate": 0.00010849484792594544,
      "logits/chosen": -6.401536464691162,
      "logits/rejected": -6.259440898895264,
      "logps/chosen": -155.96104431152344,
      "logps/rejected": -170.20352172851562,
      "loss": 1.683,
      "rewards/accuracies": 0.7437499761581421,
      "rewards/chosen": -7.972283840179443,
      "rewards/margins": 1.347644567489624,
      "rewards/rejected": -9.319929122924805,
      "step": 2340
    },
    {
      "epoch": 1.5036800000000001,
      "grad_norm": 3.0046472549438477,
      "learning_rate": 0.00010779137618795259,
      "logits/chosen": -7.012655735015869,
      "logits/rejected": -7.085110664367676,
      "logps/chosen": -152.38250732421875,
      "logps/rejected": -162.56045532226562,
      "loss": 1.6189,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -7.6786017417907715,
      "rewards/margins": 1.3241535425186157,
      "rewards/rejected": -9.002756118774414,
      "step": 2350
    },
    {
      "epoch": 1.5100799999999999,
      "grad_norm": 2.624722719192505,
      "learning_rate": 0.00010708751630233967,
      "logits/chosen": -7.991641044616699,
      "logits/rejected": -7.94384765625,
      "logps/chosen": -150.83290100097656,
      "logps/rejected": -167.5382537841797,
      "loss": 1.7353,
      "rewards/accuracies": 0.7406250238418579,
      "rewards/chosen": -7.768712043762207,
      "rewards/margins": 1.380430817604065,
      "rewards/rejected": -9.14914321899414,
      "step": 2360
    },
    {
      "epoch": 1.51648,
      "grad_norm": 4.74288272857666,
      "learning_rate": 0.00010638330333371313,
      "logits/chosen": -8.012381553649902,
      "logits/rejected": -7.854803562164307,
      "logps/chosen": -155.00779724121094,
      "logps/rejected": -168.6499786376953,
      "loss": 1.6934,
      "rewards/accuracies": 0.7734375,
      "rewards/chosen": -7.861273765563965,
      "rewards/margins": 1.328492522239685,
      "rewards/rejected": -9.189767837524414,
      "step": 2370
    },
    {
      "epoch": 1.52288,
      "grad_norm": 3.108410596847534,
      "learning_rate": 0.00010567877236426915,
      "logits/chosen": -7.095422267913818,
      "logits/rejected": -7.0003981590271,
      "logps/chosen": -155.97731018066406,
      "logps/rejected": -171.2231903076172,
      "loss": 1.669,
      "rewards/accuracies": 0.753125011920929,
      "rewards/chosen": -7.987506866455078,
      "rewards/margins": 1.4165562391281128,
      "rewards/rejected": -9.40406322479248,
      "step": 2380
    },
    {
      "epoch": 1.52928,
      "grad_norm": 3.6951828002929688,
      "learning_rate": 0.00010497395849204588,
      "logits/chosen": -6.557191371917725,
      "logits/rejected": -6.6280927658081055,
      "logps/chosen": -156.69699096679688,
      "logps/rejected": -172.6389617919922,
      "loss": 1.6577,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -8.319246292114258,
      "rewards/margins": 1.3092267513275146,
      "rewards/rejected": -9.628473281860352,
      "step": 2390
    },
    {
      "epoch": 1.5356800000000002,
      "grad_norm": 3.384439706802368,
      "learning_rate": 0.00010426889682917512,
      "logits/chosen": -7.106848239898682,
      "logits/rejected": -6.8396430015563965,
      "logps/chosen": -157.59402465820312,
      "logps/rejected": -170.50796508789062,
      "loss": 1.69,
      "rewards/accuracies": 0.7281249761581421,
      "rewards/chosen": -8.201208114624023,
      "rewards/margins": 1.354688048362732,
      "rewards/rejected": -9.55589485168457,
      "step": 2400
    },
    {
      "epoch": 1.54208,
      "grad_norm": 3.0593783855438232,
      "learning_rate": 0.00010356362250013283,
      "logits/chosen": -7.037381172180176,
      "logits/rejected": -7.0336480140686035,
      "logps/chosen": -158.3107147216797,
      "logps/rejected": -174.7897186279297,
      "loss": 1.6645,
      "rewards/accuracies": 0.7578125,
      "rewards/chosen": -8.359881401062012,
      "rewards/margins": 1.3423718214035034,
      "rewards/rejected": -9.702253341674805,
      "step": 2410
    },
    {
      "epoch": 1.54848,
      "grad_norm": 3.137732982635498,
      "learning_rate": 0.00010285817063998968,
      "logits/chosen": -7.651319980621338,
      "logits/rejected": -7.457177639007568,
      "logps/chosen": -159.08908081054688,
      "logps/rejected": -173.9360809326172,
      "loss": 1.6758,
      "rewards/accuracies": 0.7484375238418579,
      "rewards/chosen": -8.275012016296387,
      "rewards/margins": 1.3919150829315186,
      "rewards/rejected": -9.666926383972168,
      "step": 2420
    },
    {
      "epoch": 1.55488,
      "grad_norm": 3.6656503677368164,
      "learning_rate": 0.0001021525763926604,
      "logits/chosen": -9.228160858154297,
      "logits/rejected": -9.165223121643066,
      "logps/chosen": -159.57644653320312,
      "logps/rejected": -171.63671875,
      "loss": 1.7613,
      "rewards/accuracies": 0.7171875238418579,
      "rewards/chosen": -8.39185905456543,
      "rewards/margins": 1.2763751745224,
      "rewards/rejected": -9.668234825134277,
      "step": 2430
    },
    {
      "epoch": 1.56128,
      "grad_norm": 3.101384401321411,
      "learning_rate": 0.0001014468749091531,
      "logits/chosen": -10.871586799621582,
      "logits/rejected": -10.86372184753418,
      "logps/chosen": -158.31358337402344,
      "logps/rejected": -173.1486053466797,
      "loss": 1.6511,
      "rewards/accuracies": 0.731249988079071,
      "rewards/chosen": -8.260492324829102,
      "rewards/margins": 1.293846845626831,
      "rewards/rejected": -9.554339408874512,
      "step": 2440
    },
    {
      "epoch": 1.56768,
      "grad_norm": 2.9594106674194336,
      "learning_rate": 0.00010074110134581823,
      "logits/chosen": -11.351845741271973,
      "logits/rejected": -11.64906120300293,
      "logps/chosen": -153.35252380371094,
      "logps/rejected": -170.74078369140625,
      "loss": 1.6831,
      "rewards/accuracies": 0.7578125,
      "rewards/chosen": -7.912308692932129,
      "rewards/margins": 1.3242082595825195,
      "rewards/rejected": -9.236516952514648,
      "step": 2450
    },
    {
      "epoch": 1.57408,
      "grad_norm": 3.4303715229034424,
      "learning_rate": 0.00010003529086259693,
      "logits/chosen": -11.229408264160156,
      "logits/rejected": -11.273865699768066,
      "logps/chosen": -150.56228637695312,
      "logps/rejected": -167.57235717773438,
      "loss": 1.5938,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -7.52700662612915,
      "rewards/margins": 1.52460515499115,
      "rewards/rejected": -9.051612854003906,
      "step": 2460
    },
    {
      "epoch": 1.58048,
      "grad_norm": 3.257110834121704,
      "learning_rate": 9.932947862126978e-05,
      "logits/chosen": -10.93506908416748,
      "logits/rejected": -10.925040245056152,
      "logps/chosen": -149.98577880859375,
      "logps/rejected": -165.89462280273438,
      "loss": 1.6684,
      "rewards/accuracies": 0.7484375238418579,
      "rewards/chosen": -7.529587745666504,
      "rewards/margins": 1.2926164865493774,
      "rewards/rejected": -8.82220458984375,
      "step": 2470
    },
    {
      "epoch": 1.5868799999999998,
      "grad_norm": 3.0721652507781982,
      "learning_rate": 9.862369978370481e-05,
      "logits/chosen": -9.839729309082031,
      "logits/rejected": -9.947687149047852,
      "logps/chosen": -154.864990234375,
      "logps/rejected": -169.8511199951172,
      "loss": 1.6889,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -7.952020168304443,
      "rewards/margins": 1.4005552530288696,
      "rewards/rejected": -9.352575302124023,
      "step": 2480
    },
    {
      "epoch": 1.59328,
      "grad_norm": 3.2124502658843994,
      "learning_rate": 9.791798951010603e-05,
      "logits/chosen": -8.325605392456055,
      "logits/rejected": -8.2631196975708,
      "logps/chosen": -162.27467346191406,
      "logps/rejected": -175.85153198242188,
      "loss": 1.625,
      "rewards/accuracies": 0.7437499761581421,
      "rewards/chosen": -8.589982986450195,
      "rewards/margins": 1.4122270345687866,
      "rewards/rejected": -10.002209663391113,
      "step": 2490
    },
    {
      "epoch": 1.59968,
      "grad_norm": 3.30818772315979,
      "learning_rate": 9.72123829572617e-05,
      "logits/chosen": -9.325349807739258,
      "logits/rejected": -9.253725051879883,
      "logps/chosen": -158.23593139648438,
      "logps/rejected": -172.10667419433594,
      "loss": 1.6653,
      "rewards/accuracies": 0.7281249761581421,
      "rewards/chosen": -8.253942489624023,
      "rewards/margins": 1.2463303804397583,
      "rewards/rejected": -9.500272750854492,
      "step": 2500
    },
    {
      "epoch": 1.60608,
      "grad_norm": 2.903862237930298,
      "learning_rate": 9.6506915276793e-05,
      "logits/chosen": -10.120710372924805,
      "logits/rejected": -10.131468772888184,
      "logps/chosen": -157.623779296875,
      "logps/rejected": -174.27561950683594,
      "loss": 1.7241,
      "rewards/accuracies": 0.7640625238418579,
      "rewards/chosen": -8.10801887512207,
      "rewards/margins": 1.4419593811035156,
      "rewards/rejected": -9.549978256225586,
      "step": 2510
    },
    {
      "epoch": 1.6124800000000001,
      "grad_norm": 3.1583499908447266,
      "learning_rate": 9.580162161340281e-05,
      "logits/chosen": -10.732784271240234,
      "logits/rejected": -10.954121589660645,
      "logps/chosen": -155.59957885742188,
      "logps/rejected": -168.8732147216797,
      "loss": 1.7414,
      "rewards/accuracies": 0.745312511920929,
      "rewards/chosen": -8.151949882507324,
      "rewards/margins": 1.1903927326202393,
      "rewards/rejected": -9.3423433303833,
      "step": 2520
    },
    {
      "epoch": 1.6188799999999999,
      "grad_norm": 3.4812986850738525,
      "learning_rate": 9.509653710312491e-05,
      "logits/chosen": -11.039082527160645,
      "logits/rejected": -11.239301681518555,
      "logps/chosen": -156.39022827148438,
      "logps/rejected": -169.61753845214844,
      "loss": 1.6879,
      "rewards/accuracies": 0.7515624761581421,
      "rewards/chosen": -8.09439468383789,
      "rewards/margins": 1.3076318502426147,
      "rewards/rejected": -9.402026176452637,
      "step": 2530
    },
    {
      "epoch": 1.62528,
      "grad_norm": 2.761786699295044,
      "learning_rate": 9.439169687157361e-05,
      "logits/chosen": -12.695942878723145,
      "logits/rejected": -12.60787296295166,
      "logps/chosen": -151.54721069335938,
      "logps/rejected": -167.4165496826172,
      "loss": 1.7007,
      "rewards/accuracies": 0.734375,
      "rewards/chosen": -7.660738945007324,
      "rewards/margins": 1.3494144678115845,
      "rewards/rejected": -9.010152816772461,
      "step": 2540
    },
    {
      "epoch": 1.63168,
      "grad_norm": 2.336575984954834,
      "learning_rate": 9.368713603219373e-05,
      "logits/chosen": -11.82984733581543,
      "logits/rejected": -12.027848243713379,
      "logps/chosen": -147.331787109375,
      "logps/rejected": -165.59344482421875,
      "loss": 1.6618,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -7.6244378089904785,
      "rewards/margins": 1.3215339183807373,
      "rewards/rejected": -8.945971488952637,
      "step": 2550
    },
    {
      "epoch": 1.63808,
      "grad_norm": 2.6358118057250977,
      "learning_rate": 9.298288968451155e-05,
      "logits/chosen": -12.011507987976074,
      "logits/rejected": -11.992291450500488,
      "logps/chosen": -154.52171325683594,
      "logps/rejected": -169.41262817382812,
      "loss": 1.6824,
      "rewards/accuracies": 0.7437499761581421,
      "rewards/chosen": -7.852947235107422,
      "rewards/margins": 1.3476680517196655,
      "rewards/rejected": -9.200616836547852,
      "step": 2560
    },
    {
      "epoch": 1.6444800000000002,
      "grad_norm": 2.7529425621032715,
      "learning_rate": 9.227899291238606e-05,
      "logits/chosen": -12.016731262207031,
      "logits/rejected": -12.047189712524414,
      "logps/chosen": -155.84719848632812,
      "logps/rejected": -168.08013916015625,
      "loss": 1.7037,
      "rewards/accuracies": 0.753125011920929,
      "rewards/chosen": -7.911232948303223,
      "rewards/margins": 1.4311511516571045,
      "rewards/rejected": -9.342384338378906,
      "step": 2570
    },
    {
      "epoch": 1.65088,
      "grad_norm": 2.4965391159057617,
      "learning_rate": 9.157548078226128e-05,
      "logits/chosen": -11.759971618652344,
      "logits/rejected": -11.763190269470215,
      "logps/chosen": -155.7173614501953,
      "logps/rejected": -171.5057830810547,
      "loss": 1.6115,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -7.989482879638672,
      "rewards/margins": 1.5200403928756714,
      "rewards/rejected": -9.509522438049316,
      "step": 2580
    },
    {
      "epoch": 1.65728,
      "grad_norm": 2.734125852584839,
      "learning_rate": 9.087238834141929e-05,
      "logits/chosen": -11.230957984924316,
      "logits/rejected": -11.435842514038086,
      "logps/chosen": -157.55308532714844,
      "logps/rejected": -172.6346893310547,
      "loss": 1.6325,
      "rewards/accuracies": 0.746874988079071,
      "rewards/chosen": -8.03799057006836,
      "rewards/margins": 1.3607085943222046,
      "rewards/rejected": -9.398698806762695,
      "step": 2590
    },
    {
      "epoch": 1.66368,
      "grad_norm": 3.322216749191284,
      "learning_rate": 9.016975061623425e-05,
      "logits/chosen": -11.793715476989746,
      "logits/rejected": -11.784695625305176,
      "logps/chosen": -152.82705688476562,
      "logps/rejected": -168.96395874023438,
      "loss": 1.7204,
      "rewards/accuracies": 0.753125011920929,
      "rewards/chosen": -7.834374904632568,
      "rewards/margins": 1.3418939113616943,
      "rewards/rejected": -9.176268577575684,
      "step": 2600
    },
    {
      "epoch": 1.67008,
      "grad_norm": 3.7423555850982666,
      "learning_rate": 8.946760261042749e-05,
      "logits/chosen": -12.011192321777344,
      "logits/rejected": -11.981649398803711,
      "logps/chosen": -153.580810546875,
      "logps/rejected": -168.99810791015625,
      "loss": 1.7086,
      "rewards/accuracies": 0.7109375,
      "rewards/chosen": -8.082605361938477,
      "rewards/margins": 1.200340986251831,
      "rewards/rejected": -9.28294849395752,
      "step": 2610
    },
    {
      "epoch": 1.67648,
      "grad_norm": 3.0761706829071045,
      "learning_rate": 8.876597930332365e-05,
      "logits/chosen": -11.286613464355469,
      "logits/rejected": -11.201553344726562,
      "logps/chosen": -153.26116943359375,
      "logps/rejected": -170.07066345214844,
      "loss": 1.6743,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -7.817051887512207,
      "rewards/margins": 1.2660515308380127,
      "rewards/rejected": -9.08310317993164,
      "step": 2620
    },
    {
      "epoch": 1.68288,
      "grad_norm": 2.977354049682617,
      "learning_rate": 8.806491564810821e-05,
      "logits/chosen": -10.468979835510254,
      "logits/rejected": -10.438498497009277,
      "logps/chosen": -156.0808563232422,
      "logps/rejected": -169.19309997558594,
      "loss": 1.7414,
      "rewards/accuracies": 0.721875011920929,
      "rewards/chosen": -7.941019535064697,
      "rewards/margins": 1.1664029359817505,
      "rewards/rejected": -9.107423782348633,
      "step": 2630
    },
    {
      "epoch": 1.6892800000000001,
      "grad_norm": 2.498448133468628,
      "learning_rate": 8.73644465700861e-05,
      "logits/chosen": -9.447028160095215,
      "logits/rejected": -9.383407592773438,
      "logps/chosen": -157.2378692626953,
      "logps/rejected": -170.4355926513672,
      "loss": 1.6557,
      "rewards/accuracies": 0.7671874761581421,
      "rewards/chosen": -7.984368801116943,
      "rewards/margins": 1.3081433773040771,
      "rewards/rejected": -9.292512893676758,
      "step": 2640
    },
    {
      "epoch": 1.6956799999999999,
      "grad_norm": 2.663395404815674,
      "learning_rate": 8.666460696494186e-05,
      "logits/chosen": -8.58514404296875,
      "logits/rejected": -8.628454208374023,
      "logps/chosen": -154.49560546875,
      "logps/rejected": -171.10250854492188,
      "loss": 1.6751,
      "rewards/accuracies": 0.7515624761581421,
      "rewards/chosen": -8.158346176147461,
      "rewards/margins": 1.2618070840835571,
      "rewards/rejected": -9.420151710510254,
      "step": 2650
    },
    {
      "epoch": 1.70208,
      "grad_norm": 2.978670358657837,
      "learning_rate": 8.596543169700122e-05,
      "logits/chosen": -8.145760536193848,
      "logits/rejected": -8.267912864685059,
      "logps/chosen": -156.5701904296875,
      "logps/rejected": -170.46937561035156,
      "loss": 1.6724,
      "rewards/accuracies": 0.7671874761581421,
      "rewards/chosen": -7.77562952041626,
      "rewards/margins": 1.2866836786270142,
      "rewards/rejected": -9.062313079833984,
      "step": 2660
    },
    {
      "epoch": 1.70848,
      "grad_norm": 2.8955299854278564,
      "learning_rate": 8.526695559749415e-05,
      "logits/chosen": -9.27092456817627,
      "logits/rejected": -9.123242378234863,
      "logps/chosen": -150.77947998046875,
      "logps/rejected": -166.99522399902344,
      "loss": 1.6229,
      "rewards/accuracies": 0.753125011920929,
      "rewards/chosen": -7.6120710372924805,
      "rewards/margins": 1.3354262113571167,
      "rewards/rejected": -8.94749641418457,
      "step": 2670
    },
    {
      "epoch": 1.71488,
      "grad_norm": 2.6245861053466797,
      "learning_rate": 8.456921346281983e-05,
      "logits/chosen": -8.898462295532227,
      "logits/rejected": -8.9207124710083,
      "logps/chosen": -151.6143798828125,
      "logps/rejected": -169.15274047851562,
      "loss": 1.5408,
      "rewards/accuracies": 0.7796875238418579,
      "rewards/chosen": -7.6153459548950195,
      "rewards/margins": 1.5065548419952393,
      "rewards/rejected": -9.12190055847168,
      "step": 2680
    },
    {
      "epoch": 1.7212800000000001,
      "grad_norm": 2.498558759689331,
      "learning_rate": 8.387224005281302e-05,
      "logits/chosen": -9.288784980773926,
      "logits/rejected": -9.38908576965332,
      "logps/chosen": -156.32620239257812,
      "logps/rejected": -173.9667205810547,
      "loss": 1.5765,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -8.19923210144043,
      "rewards/margins": 1.3841168880462646,
      "rewards/rejected": -9.58334732055664,
      "step": 2690
    },
    {
      "epoch": 1.7276799999999999,
      "grad_norm": 3.191528558731079,
      "learning_rate": 8.317607008901247e-05,
      "logits/chosen": -10.414405822753906,
      "logits/rejected": -10.378934860229492,
      "logps/chosen": -155.83358764648438,
      "logps/rejected": -170.26808166503906,
      "loss": 1.7273,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -8.104715347290039,
      "rewards/margins": 1.4463015794754028,
      "rewards/rejected": -9.551017761230469,
      "step": 2700
    },
    {
      "epoch": 1.73408,
      "grad_norm": 2.8300037384033203,
      "learning_rate": 8.248073825293121e-05,
      "logits/chosen": -10.82378101348877,
      "logits/rejected": -10.891008377075195,
      "logps/chosen": -154.15158081054688,
      "logps/rejected": -169.6089324951172,
      "loss": 1.7171,
      "rewards/accuracies": 0.731249988079071,
      "rewards/chosen": -7.940065860748291,
      "rewards/margins": 1.2600901126861572,
      "rewards/rejected": -9.200155258178711,
      "step": 2710
    },
    {
      "epoch": 1.74048,
      "grad_norm": 3.063585042953491,
      "learning_rate": 8.178627918432876e-05,
      "logits/chosen": -9.828643798828125,
      "logits/rejected": -9.807863235473633,
      "logps/chosen": -153.12767028808594,
      "logps/rejected": -169.403076171875,
      "loss": 1.6742,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -7.8971662521362305,
      "rewards/margins": 1.2048406600952148,
      "rewards/rejected": -9.102006912231445,
      "step": 2720
    },
    {
      "epoch": 1.74688,
      "grad_norm": 2.6345183849334717,
      "learning_rate": 8.109272747948537e-05,
      "logits/chosen": -9.736245155334473,
      "logits/rejected": -9.640945434570312,
      "logps/chosen": -154.5370330810547,
      "logps/rejected": -168.52122497558594,
      "loss": 1.692,
      "rewards/accuracies": 0.7562500238418579,
      "rewards/chosen": -7.797238349914551,
      "rewards/margins": 1.366337537765503,
      "rewards/rejected": -9.163576126098633,
      "step": 2730
    },
    {
      "epoch": 1.75328,
      "grad_norm": 2.5784027576446533,
      "learning_rate": 8.040011768947874e-05,
      "logits/chosen": -9.06137466430664,
      "logits/rejected": -9.17845630645752,
      "logps/chosen": -153.7235870361328,
      "logps/rejected": -169.70614624023438,
      "loss": 1.5994,
      "rewards/accuracies": 0.7640625238418579,
      "rewards/chosen": -7.954300880432129,
      "rewards/margins": 1.3989362716674805,
      "rewards/rejected": -9.353238105773926,
      "step": 2740
    },
    {
      "epoch": 1.75968,
      "grad_norm": 3.654067277908325,
      "learning_rate": 7.970848431846259e-05,
      "logits/chosen": -8.995513916015625,
      "logits/rejected": -8.932774543762207,
      "logps/chosen": -158.50123596191406,
      "logps/rejected": -172.24581909179688,
      "loss": 1.6671,
      "rewards/accuracies": 0.721875011920929,
      "rewards/chosen": -8.311970710754395,
      "rewards/margins": 1.2819440364837646,
      "rewards/rejected": -9.593915939331055,
      "step": 2750
    },
    {
      "epoch": 1.76608,
      "grad_norm": 3.1302783489227295,
      "learning_rate": 7.901786182194772e-05,
      "logits/chosen": -9.674699783325195,
      "logits/rejected": -9.628286361694336,
      "logps/chosen": -161.85159301757812,
      "logps/rejected": -175.52569580078125,
      "loss": 1.6742,
      "rewards/accuracies": 0.762499988079071,
      "rewards/chosen": -8.416372299194336,
      "rewards/margins": 1.3600925207138062,
      "rewards/rejected": -9.776464462280273,
      "step": 2760
    },
    {
      "epoch": 1.77248,
      "grad_norm": 3.1255362033843994,
      "learning_rate": 7.832828460508569e-05,
      "logits/chosen": -10.920744895935059,
      "logits/rejected": -11.057398796081543,
      "logps/chosen": -154.05752563476562,
      "logps/rejected": -169.38906860351562,
      "loss": 1.6635,
      "rewards/accuracies": 0.7734375,
      "rewards/chosen": -7.83960485458374,
      "rewards/margins": 1.3146016597747803,
      "rewards/rejected": -9.154205322265625,
      "step": 2770
    },
    {
      "epoch": 1.77888,
      "grad_norm": 3.0659143924713135,
      "learning_rate": 7.76397870209547e-05,
      "logits/chosen": -10.127579689025879,
      "logits/rejected": -10.392334938049316,
      "logps/chosen": -152.8192901611328,
      "logps/rejected": -167.2165069580078,
      "loss": 1.6782,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -7.847228050231934,
      "rewards/margins": 1.2395961284637451,
      "rewards/rejected": -9.086824417114258,
      "step": 2780
    },
    {
      "epoch": 1.78528,
      "grad_norm": 2.860609531402588,
      "learning_rate": 7.695240336884831e-05,
      "logits/chosen": -9.867695808410645,
      "logits/rejected": -9.661972999572754,
      "logps/chosen": -152.49795532226562,
      "logps/rejected": -169.19142150878906,
      "loss": 1.5911,
      "rewards/accuracies": 0.7890625,
      "rewards/chosen": -7.744356632232666,
      "rewards/margins": 1.4672584533691406,
      "rewards/rejected": -9.211614608764648,
      "step": 2790
    },
    {
      "epoch": 1.79168,
      "grad_norm": 2.90651273727417,
      "learning_rate": 7.626616789256654e-05,
      "logits/chosen": -8.742086410522461,
      "logits/rejected": -9.049528121948242,
      "logps/chosen": -152.114013671875,
      "logps/rejected": -171.27752685546875,
      "loss": 1.6662,
      "rewards/accuracies": 0.7796875238418579,
      "rewards/chosen": -7.7613091468811035,
      "rewards/margins": 1.3874101638793945,
      "rewards/rejected": -9.14871883392334,
      "step": 2800
    },
    {
      "epoch": 1.7980800000000001,
      "grad_norm": 3.782972812652588,
      "learning_rate": 7.558111477871014e-05,
      "logits/chosen": -9.046910285949707,
      "logits/rejected": -9.019716262817383,
      "logps/chosen": -150.5299072265625,
      "logps/rejected": -168.10525512695312,
      "loss": 1.6929,
      "rewards/accuracies": 0.75,
      "rewards/chosen": -7.78421688079834,
      "rewards/margins": 1.358345627784729,
      "rewards/rejected": -9.14256477355957,
      "step": 2810
    },
    {
      "epoch": 1.8044799999999999,
      "grad_norm": 2.7696497440338135,
      "learning_rate": 7.489727815497743e-05,
      "logits/chosen": -7.627947807312012,
      "logits/rejected": -7.692172050476074,
      "logps/chosen": -150.177490234375,
      "logps/rejected": -165.11329650878906,
      "loss": 1.6723,
      "rewards/accuracies": 0.715624988079071,
      "rewards/chosen": -7.630091190338135,
      "rewards/margins": 1.2748489379882812,
      "rewards/rejected": -8.904939651489258,
      "step": 2820
    },
    {
      "epoch": 1.81088,
      "grad_norm": 2.5360164642333984,
      "learning_rate": 7.421469208846403e-05,
      "logits/chosen": -6.873513221740723,
      "logits/rejected": -6.586014747619629,
      "logps/chosen": -152.20681762695312,
      "logps/rejected": -165.37449645996094,
      "loss": 1.696,
      "rewards/accuracies": 0.754687488079071,
      "rewards/chosen": -7.743730068206787,
      "rewards/margins": 1.3310893774032593,
      "rewards/rejected": -9.074819564819336,
      "step": 2830
    },
    {
      "epoch": 1.81728,
      "grad_norm": 2.526794672012329,
      "learning_rate": 7.353339058396593e-05,
      "logits/chosen": -6.9463090896606445,
      "logits/rejected": -7.00301456451416,
      "logps/chosen": -153.36473083496094,
      "logps/rejected": -168.8309783935547,
      "loss": 1.6806,
      "rewards/accuracies": 0.71875,
      "rewards/chosen": -7.816435813903809,
      "rewards/margins": 1.2958314418792725,
      "rewards/rejected": -9.112266540527344,
      "step": 2840
    },
    {
      "epoch": 1.82368,
      "grad_norm": 2.498995304107666,
      "learning_rate": 7.285340758228516e-05,
      "logits/chosen": -7.547022342681885,
      "logits/rejected": -7.572850704193115,
      "logps/chosen": -149.97964477539062,
      "logps/rejected": -167.50601196289062,
      "loss": 1.7195,
      "rewards/accuracies": 0.7515624761581421,
      "rewards/chosen": -7.598969459533691,
      "rewards/margins": 1.3542563915252686,
      "rewards/rejected": -8.953226089477539,
      "step": 2850
    },
    {
      "epoch": 1.8300800000000002,
      "grad_norm": 2.9713778495788574,
      "learning_rate": 7.217477695853927e-05,
      "logits/chosen": -8.055380821228027,
      "logits/rejected": -7.794961452484131,
      "logps/chosen": -150.32040405273438,
      "logps/rejected": -164.5763702392578,
      "loss": 1.6315,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -7.471360683441162,
      "rewards/margins": 1.3912668228149414,
      "rewards/rejected": -8.862627029418945,
      "step": 2860
    },
    {
      "epoch": 1.83648,
      "grad_norm": 3.2905588150024414,
      "learning_rate": 7.149753252047351e-05,
      "logits/chosen": -7.96985387802124,
      "logits/rejected": -8.170755386352539,
      "logps/chosen": -150.8933563232422,
      "logps/rejected": -165.92013549804688,
      "loss": 1.5818,
      "rewards/accuracies": 0.7718750238418579,
      "rewards/chosen": -7.500922203063965,
      "rewards/margins": 1.426565408706665,
      "rewards/rejected": -8.927488327026367,
      "step": 2870
    },
    {
      "epoch": 1.84288,
      "grad_norm": 2.1214511394500732,
      "learning_rate": 7.08217080067767e-05,
      "logits/chosen": -8.468923568725586,
      "logits/rejected": -8.5616455078125,
      "logps/chosen": -147.32327270507812,
      "logps/rejected": -163.33358764648438,
      "loss": 1.6445,
      "rewards/accuracies": 0.768750011920929,
      "rewards/chosen": -7.4672675132751465,
      "rewards/margins": 1.3407948017120361,
      "rewards/rejected": -8.808062553405762,
      "step": 2880
    },
    {
      "epoch": 1.84928,
      "grad_norm": 2.74003529548645,
      "learning_rate": 7.01473370854005e-05,
      "logits/chosen": -10.561773300170898,
      "logits/rejected": -10.66132926940918,
      "logps/chosen": -153.65138244628906,
      "logps/rejected": -166.64805603027344,
      "loss": 1.6843,
      "rewards/accuracies": 0.7578125,
      "rewards/chosen": -7.751553535461426,
      "rewards/margins": 1.2825186252593994,
      "rewards/rejected": -9.03407096862793,
      "step": 2890
    },
    {
      "epoch": 1.85568,
      "grad_norm": 2.867384910583496,
      "learning_rate": 6.947445335188204e-05,
      "logits/chosen": -11.574954986572266,
      "logits/rejected": -11.713393211364746,
      "logps/chosen": -154.14529418945312,
      "logps/rejected": -169.46456909179688,
      "loss": 1.6316,
      "rewards/accuracies": 0.7328125238418579,
      "rewards/chosen": -7.598513126373291,
      "rewards/margins": 1.3272123336791992,
      "rewards/rejected": -8.925725936889648,
      "step": 2900
    },
    {
      "epoch": 1.86208,
      "grad_norm": 3.129342794418335,
      "learning_rate": 6.880309032767036e-05,
      "logits/chosen": -11.797591209411621,
      "logits/rejected": -11.872868537902832,
      "logps/chosen": -152.7754364013672,
      "logps/rejected": -168.04153442382812,
      "loss": 1.6661,
      "rewards/accuracies": 0.7421875,
      "rewards/chosen": -7.728580474853516,
      "rewards/margins": 1.3216700553894043,
      "rewards/rejected": -9.050250053405762,
      "step": 2910
    },
    {
      "epoch": 1.86848,
      "grad_norm": 3.1481356620788574,
      "learning_rate": 6.813328145845637e-05,
      "logits/chosen": -11.736977577209473,
      "logits/rejected": -11.682964324951172,
      "logps/chosen": -154.4416046142578,
      "logps/rejected": -168.16140747070312,
      "loss": 1.6532,
      "rewards/accuracies": 0.745312511920929,
      "rewards/chosen": -7.900313377380371,
      "rewards/margins": 1.2771581411361694,
      "rewards/rejected": -9.177472114562988,
      "step": 2920
    },
    {
      "epoch": 1.87488,
      "grad_norm": 2.4645533561706543,
      "learning_rate": 6.746506011250682e-05,
      "logits/chosen": -11.436771392822266,
      "logits/rejected": -11.521682739257812,
      "logps/chosen": -154.70242309570312,
      "logps/rejected": -171.1055908203125,
      "loss": 1.6132,
      "rewards/accuracies": 0.7578125,
      "rewards/chosen": -8.042868614196777,
      "rewards/margins": 1.4357860088348389,
      "rewards/rejected": -9.478654861450195,
      "step": 2930
    },
    {
      "epoch": 1.8812799999999998,
      "grad_norm": 2.436004400253296,
      "learning_rate": 6.67984595790017e-05,
      "logits/chosen": -11.409046173095703,
      "logits/rejected": -11.373705863952637,
      "logps/chosen": -156.3752899169922,
      "logps/rejected": -169.33456420898438,
      "loss": 1.6821,
      "rewards/accuracies": 0.7578125,
      "rewards/chosen": -7.890333652496338,
      "rewards/margins": 1.334059476852417,
      "rewards/rejected": -9.224393844604492,
      "step": 2940
    },
    {
      "epoch": 1.88768,
      "grad_norm": 3.01117205619812,
      "learning_rate": 6.61335130663762e-05,
      "logits/chosen": -11.213541030883789,
      "logits/rejected": -11.14883041381836,
      "logps/chosen": -151.28932189941406,
      "logps/rejected": -162.85789489746094,
      "loss": 1.6699,
      "rewards/accuracies": 0.7671874761581421,
      "rewards/chosen": -7.539093017578125,
      "rewards/margins": 1.3474295139312744,
      "rewards/rejected": -8.88652229309082,
      "step": 2950
    },
    {
      "epoch": 1.89408,
      "grad_norm": 1.9791451692581177,
      "learning_rate": 6.547025370066606e-05,
      "logits/chosen": -11.679694175720215,
      "logits/rejected": -11.886093139648438,
      "logps/chosen": -151.1483154296875,
      "logps/rejected": -162.57962036132812,
      "loss": 1.6331,
      "rewards/accuracies": 0.745312511920929,
      "rewards/chosen": -7.531907558441162,
      "rewards/margins": 1.3214459419250488,
      "rewards/rejected": -8.853353500366211,
      "step": 2960
    },
    {
      "epoch": 1.90048,
      "grad_norm": 3.2782506942749023,
      "learning_rate": 6.480871452385749e-05,
      "logits/chosen": -11.102740287780762,
      "logits/rejected": -11.477952003479004,
      "logps/chosen": -151.28475952148438,
      "logps/rejected": -167.33798217773438,
      "loss": 1.6059,
      "rewards/accuracies": 0.746874988079071,
      "rewards/chosen": -7.705567359924316,
      "rewards/margins": 1.354989767074585,
      "rewards/rejected": -9.06055736541748,
      "step": 2970
    },
    {
      "epoch": 1.9068800000000001,
      "grad_norm": 2.4698240756988525,
      "learning_rate": 6.414892849224092e-05,
      "logits/chosen": -10.949728012084961,
      "logits/rejected": -10.996195793151855,
      "logps/chosen": -153.2389678955078,
      "logps/rejected": -168.85389709472656,
      "loss": 1.6022,
      "rewards/accuracies": 0.753125011920929,
      "rewards/chosen": -7.647320747375488,
      "rewards/margins": 1.3983945846557617,
      "rewards/rejected": -9.045716285705566,
      "step": 2980
    },
    {
      "epoch": 1.9132799999999999,
      "grad_norm": 2.993710994720459,
      "learning_rate": 6.349092847476943e-05,
      "logits/chosen": -11.35173225402832,
      "logits/rejected": -11.125574111938477,
      "logps/chosen": -154.65286254882812,
      "logps/rejected": -171.24356079101562,
      "loss": 1.6011,
      "rewards/accuracies": 0.8046875,
      "rewards/chosen": -7.584958076477051,
      "rewards/margins": 1.5808371305465698,
      "rewards/rejected": -9.16579532623291,
      "step": 2990
    },
    {
      "epoch": 1.91968,
      "grad_norm": 2.972781181335449,
      "learning_rate": 6.283474725142109e-05,
      "logits/chosen": -11.249521255493164,
      "logits/rejected": -11.160322189331055,
      "logps/chosen": -152.03419494628906,
      "logps/rejected": -167.8226318359375,
      "loss": 1.6085,
      "rewards/accuracies": 0.746874988079071,
      "rewards/chosen": -7.730787754058838,
      "rewards/margins": 1.3230706453323364,
      "rewards/rejected": -9.053858757019043,
      "step": 3000
    },
    {
      "epoch": 1.92608,
      "grad_norm": 2.9503471851348877,
      "learning_rate": 6.218041751156607e-05,
      "logits/chosen": -10.124168395996094,
      "logits/rejected": -10.411821365356445,
      "logps/chosen": -152.56976318359375,
      "logps/rejected": -169.56407165527344,
      "loss": 1.6389,
      "rewards/accuracies": 0.7562500238418579,
      "rewards/chosen": -7.82360315322876,
      "rewards/margins": 1.3273998498916626,
      "rewards/rejected": -9.151002883911133,
      "step": 3010
    },
    {
      "epoch": 1.93248,
      "grad_norm": 2.925264835357666,
      "learning_rate": 6.152797185233805e-05,
      "logits/chosen": -9.988465309143066,
      "logits/rejected": -9.960612297058105,
      "logps/chosen": -152.5202178955078,
      "logps/rejected": -167.5731964111328,
      "loss": 1.5768,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -7.731583595275879,
      "rewards/margins": 1.2959957122802734,
      "rewards/rejected": -9.027579307556152,
      "step": 3020
    },
    {
      "epoch": 1.9388800000000002,
      "grad_norm": 2.3345510959625244,
      "learning_rate": 6.087744277701035e-05,
      "logits/chosen": -10.823830604553223,
      "logits/rejected": -10.973323822021484,
      "logps/chosen": -154.18487548828125,
      "logps/rejected": -168.6372528076172,
      "loss": 1.6011,
      "rewards/accuracies": 0.7718750238418579,
      "rewards/chosen": -7.6431074142456055,
      "rewards/margins": 1.483879566192627,
      "rewards/rejected": -9.126986503601074,
      "step": 3030
    },
    {
      "epoch": 1.94528,
      "grad_norm": 3.0691628456115723,
      "learning_rate": 6.022886269337671e-05,
      "logits/chosen": -11.662973403930664,
      "logits/rejected": -11.813746452331543,
      "logps/chosen": -150.13424682617188,
      "logps/rejected": -167.04800415039062,
      "loss": 1.6059,
      "rewards/accuracies": 0.7359374761581421,
      "rewards/chosen": -7.76495885848999,
      "rewards/margins": 1.3093528747558594,
      "rewards/rejected": -9.074312210083008,
      "step": 3040
    },
    {
      "epoch": 1.95168,
      "grad_norm": 2.80753231048584,
      "learning_rate": 5.9582263912136725e-05,
      "logits/chosen": -12.263116836547852,
      "logits/rejected": -12.265740394592285,
      "logps/chosen": -151.22268676757812,
      "logps/rejected": -165.18914794921875,
      "loss": 1.616,
      "rewards/accuracies": 0.778124988079071,
      "rewards/chosen": -7.550936222076416,
      "rewards/margins": 1.3939056396484375,
      "rewards/rejected": -8.944841384887695,
      "step": 3050
    },
    {
      "epoch": 1.95808,
      "grad_norm": 2.770376443862915,
      "learning_rate": 5.8937678645286385e-05,
      "logits/chosen": -12.469328880310059,
      "logits/rejected": -12.462018013000488,
      "logps/chosen": -150.10975646972656,
      "logps/rejected": -163.97706604003906,
      "loss": 1.6367,
      "rewards/accuracies": 0.78125,
      "rewards/chosen": -7.396035671234131,
      "rewards/margins": 1.4427763223648071,
      "rewards/rejected": -8.838811874389648,
      "step": 3060
    },
    {
      "epoch": 1.96448,
      "grad_norm": 2.6223387718200684,
      "learning_rate": 5.829513900451316e-05,
      "logits/chosen": -12.309524536132812,
      "logits/rejected": -12.255575180053711,
      "logps/chosen": -147.83724975585938,
      "logps/rejected": -164.1760711669922,
      "loss": 1.6183,
      "rewards/accuracies": 0.7437499761581421,
      "rewards/chosen": -7.3421831130981445,
      "rewards/margins": 1.32322096824646,
      "rewards/rejected": -8.665403366088867,
      "step": 3070
    },
    {
      "epoch": 1.97088,
      "grad_norm": 4.6475396156311035,
      "learning_rate": 5.765467699959637e-05,
      "logits/chosen": -12.13898754119873,
      "logits/rejected": -12.244446754455566,
      "logps/chosen": -146.0591583251953,
      "logps/rejected": -163.05491638183594,
      "loss": 1.6289,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -7.379118919372559,
      "rewards/margins": 1.3103638887405396,
      "rewards/rejected": -8.689482688903809,
      "step": 3080
    },
    {
      "epoch": 1.97728,
      "grad_norm": 2.422119617462158,
      "learning_rate": 5.701632453681245e-05,
      "logits/chosen": -11.673273086547852,
      "logits/rejected": -11.686714172363281,
      "logps/chosen": -147.59300231933594,
      "logps/rejected": -159.00453186035156,
      "loss": 1.7472,
      "rewards/accuracies": 0.745312511920929,
      "rewards/chosen": -7.237133979797363,
      "rewards/margins": 1.197261095046997,
      "rewards/rejected": -8.434394836425781,
      "step": 3090
    },
    {
      "epoch": 1.98368,
      "grad_norm": 2.7654616832733154,
      "learning_rate": 5.638011341734569e-05,
      "logits/chosen": -12.217208862304688,
      "logits/rejected": -12.448140144348145,
      "logps/chosen": -149.12416076660156,
      "logps/rejected": -164.50686645507812,
      "loss": 1.6156,
      "rewards/accuracies": 0.7749999761581421,
      "rewards/chosen": -7.267575263977051,
      "rewards/margins": 1.4299904108047485,
      "rewards/rejected": -8.697566032409668,
      "step": 3100
    },
    {
      "epoch": 1.9900799999999998,
      "grad_norm": 2.9491097927093506,
      "learning_rate": 5.574607533570364e-05,
      "logits/chosen": -12.398321151733398,
      "logits/rejected": -12.56370735168457,
      "logps/chosen": -150.85354614257812,
      "logps/rejected": -165.83111572265625,
      "loss": 1.6458,
      "rewards/accuracies": 0.7593749761581421,
      "rewards/chosen": -7.365281105041504,
      "rewards/margins": 1.39658522605896,
      "rewards/rejected": -8.761865615844727,
      "step": 3110
    },
    {
      "epoch": 1.99648,
      "grad_norm": 2.4826364517211914,
      "learning_rate": 5.511424187813838e-05,
      "logits/chosen": -12.7197265625,
      "logits/rejected": -12.96233081817627,
      "logps/chosen": -144.1021270751953,
      "logps/rejected": -159.39256286621094,
      "loss": 1.6361,
      "rewards/accuracies": 0.737500011920929,
      "rewards/chosen": -7.165842533111572,
      "rewards/margins": 1.2954344749450684,
      "rewards/rejected": -8.461276054382324,
      "step": 3120
    },
    {
      "epoch": 2.00256,
      "grad_norm": 0.974716305732727,
      "learning_rate": 5.448464452107295e-05,
      "logits/chosen": -12.748659133911133,
      "logits/rejected": -13.032966613769531,
      "logps/chosen": -144.91787719726562,
      "logps/rejected": -168.60928344726562,
      "loss": 1.395,
      "rewards/accuracies": 0.8256579041481018,
      "rewards/chosen": -6.9623122215271,
      "rewards/margins": 2.05228590965271,
      "rewards/rejected": -9.01459789276123,
      "step": 3130
    },
    {
      "epoch": 2.00896,
      "grad_norm": 1.4783283472061157,
      "learning_rate": 5.3857314629533164e-05,
      "logits/chosen": -12.888829231262207,
      "logits/rejected": -12.725194931030273,
      "logps/chosen": -139.9634246826172,
      "logps/rejected": -169.45797729492188,
      "loss": 1.2511,
      "rewards/accuracies": 0.956250011920929,
      "rewards/chosen": -6.592751502990723,
      "rewards/margins": 2.964251756668091,
      "rewards/rejected": -9.55700397491455,
      "step": 3140
    },
    {
      "epoch": 2.01536,
      "grad_norm": 1.4545098543167114,
      "learning_rate": 5.3232283455585306e-05,
      "logits/chosen": -13.183982849121094,
      "logits/rejected": -13.114924430847168,
      "logps/chosen": -144.3741455078125,
      "logps/rejected": -178.94613647460938,
      "loss": 1.2584,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -6.984161376953125,
      "rewards/margins": 3.2060508728027344,
      "rewards/rejected": -10.190211296081543,
      "step": 3150
    },
    {
      "epoch": 2.02176,
      "grad_norm": 1.006056547164917,
      "learning_rate": 5.260958213677891e-05,
      "logits/chosen": -13.941713333129883,
      "logits/rejected": -14.18132495880127,
      "logps/chosen": -151.04104614257812,
      "logps/rejected": -186.76243591308594,
      "loss": 1.2576,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -7.328578948974609,
      "rewards/margins": 3.489727020263672,
      "rewards/rejected": -10.818306922912598,
      "step": 3160
    },
    {
      "epoch": 2.02816,
      "grad_norm": 1.4893629550933838,
      "learning_rate": 5.198924169459589e-05,
      "logits/chosen": -13.167762756347656,
      "logits/rejected": -13.368980407714844,
      "logps/chosen": -150.62355041503906,
      "logps/rejected": -185.3871612548828,
      "loss": 1.2836,
      "rewards/accuracies": 0.948437511920929,
      "rewards/chosen": -7.610593318939209,
      "rewards/margins": 3.4318466186523438,
      "rewards/rejected": -11.042439460754395,
      "step": 3170
    },
    {
      "epoch": 2.03456,
      "grad_norm": 1.1460176706314087,
      "learning_rate": 5.1371293032904846e-05,
      "logits/chosen": -12.27018928527832,
      "logits/rejected": -12.1829195022583,
      "logps/chosen": -148.01393127441406,
      "logps/rejected": -188.88482666015625,
      "loss": 1.2675,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -7.4189887046813965,
      "rewards/margins": 3.6108334064483643,
      "rewards/rejected": -11.02982234954834,
      "step": 3180
    },
    {
      "epoch": 2.04096,
      "grad_norm": 2.1073157787323,
      "learning_rate": 5.0755766936421635e-05,
      "logits/chosen": -11.594023704528809,
      "logits/rejected": -11.495389938354492,
      "logps/chosen": -149.21670532226562,
      "logps/rejected": -184.6704559326172,
      "loss": 1.3226,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -7.502928733825684,
      "rewards/margins": 3.496659517288208,
      "rewards/rejected": -10.999588966369629,
      "step": 3190
    },
    {
      "epoch": 2.04736,
      "grad_norm": 1.3351296186447144,
      "learning_rate": 5.014269406917583e-05,
      "logits/chosen": -10.751213073730469,
      "logits/rejected": -11.140164375305176,
      "logps/chosen": -152.90185546875,
      "logps/rejected": -188.4738006591797,
      "loss": 1.2817,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -7.716320991516113,
      "rewards/margins": 3.4729199409484863,
      "rewards/rejected": -11.189240455627441,
      "step": 3200
    },
    {
      "epoch": 2.05376,
      "grad_norm": 1.5768795013427734,
      "learning_rate": 4.953210497298296e-05,
      "logits/chosen": -11.908607482910156,
      "logits/rejected": -11.92993450164795,
      "logps/chosen": -155.8035125732422,
      "logps/rejected": -193.800537109375,
      "loss": 1.2961,
      "rewards/accuracies": 0.953125,
      "rewards/chosen": -7.827627658843994,
      "rewards/margins": 3.702069044113159,
      "rewards/rejected": -11.529698371887207,
      "step": 3210
    },
    {
      "epoch": 2.06016,
      "grad_norm": 1.7827388048171997,
      "learning_rate": 4.892403006592305e-05,
      "logits/chosen": -13.23426628112793,
      "logits/rejected": -13.293153762817383,
      "logps/chosen": -153.45492553710938,
      "logps/rejected": -195.14895629882812,
      "loss": 1.2691,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -7.842052459716797,
      "rewards/margins": 3.731084108352661,
      "rewards/rejected": -11.573136329650879,
      "step": 3220
    },
    {
      "epoch": 2.06656,
      "grad_norm": 2.1961276531219482,
      "learning_rate": 4.831849964082524e-05,
      "logits/chosen": -13.972722053527832,
      "logits/rejected": -14.120798110961914,
      "logps/chosen": -154.12594604492188,
      "logps/rejected": -191.09471130371094,
      "loss": 1.2971,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -7.795919895172119,
      "rewards/margins": 3.512357234954834,
      "rewards/rejected": -11.30827808380127,
      "step": 3230
    },
    {
      "epoch": 2.07296,
      "grad_norm": 1.6700279712677002,
      "learning_rate": 4.771554386375885e-05,
      "logits/chosen": -13.879186630249023,
      "logits/rejected": -14.10826587677002,
      "logps/chosen": -152.69857788085938,
      "logps/rejected": -190.69078063964844,
      "loss": 1.2582,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -7.8610944747924805,
      "rewards/margins": 3.527055025100708,
      "rewards/rejected": -11.388150215148926,
      "step": 3240
    },
    {
      "epoch": 2.07936,
      "grad_norm": 1.6313109397888184,
      "learning_rate": 4.711519277253025e-05,
      "logits/chosen": -13.724187850952148,
      "logits/rejected": -13.649545669555664,
      "logps/chosen": -153.4436798095703,
      "logps/rejected": -199.21096801757812,
      "loss": 1.2588,
      "rewards/accuracies": 0.964062511920929,
      "rewards/chosen": -8.011777877807617,
      "rewards/margins": 3.8062655925750732,
      "rewards/rejected": -11.81804370880127,
      "step": 3250
    },
    {
      "epoch": 2.08576,
      "grad_norm": 2.2185733318328857,
      "learning_rate": 4.651747627518666e-05,
      "logits/chosen": -13.011591911315918,
      "logits/rejected": -12.996236801147461,
      "logps/chosen": -156.98324584960938,
      "logps/rejected": -198.71774291992188,
      "loss": 1.2185,
      "rewards/accuracies": 0.9765625,
      "rewards/chosen": -8.210034370422363,
      "rewards/margins": 3.84447979927063,
      "rewards/rejected": -12.054512977600098,
      "step": 3260
    },
    {
      "epoch": 2.09216,
      "grad_norm": 1.2688263654708862,
      "learning_rate": 4.592242414852631e-05,
      "logits/chosen": -13.742660522460938,
      "logits/rejected": -13.92210865020752,
      "logps/chosen": -157.44631958007812,
      "logps/rejected": -194.94729614257812,
      "loss": 1.2914,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -8.160654067993164,
      "rewards/margins": 3.8920979499816895,
      "rewards/rejected": -12.052751541137695,
      "step": 3270
    },
    {
      "epoch": 2.09856,
      "grad_norm": 1.6348252296447754,
      "learning_rate": 4.53300660366147e-05,
      "logits/chosen": -14.083722114562988,
      "logits/rejected": -14.258671760559082,
      "logps/chosen": -157.09457397460938,
      "logps/rejected": -199.15814208984375,
      "loss": 1.2929,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.501188278198242,
      "rewards/margins": 3.8539977073669434,
      "rewards/rejected": -12.355186462402344,
      "step": 3280
    },
    {
      "epoch": 2.10496,
      "grad_norm": 1.4674724340438843,
      "learning_rate": 4.4740431449308174e-05,
      "logits/chosen": -13.670036315917969,
      "logits/rejected": -13.784260749816895,
      "logps/chosen": -158.8529815673828,
      "logps/rejected": -199.18197631835938,
      "loss": 1.2905,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -8.525262832641602,
      "rewards/margins": 3.975717067718506,
      "rewards/rejected": -12.500980377197266,
      "step": 3290
    },
    {
      "epoch": 2.11136,
      "grad_norm": 1.4910115003585815,
      "learning_rate": 4.4153549760783496e-05,
      "logits/chosen": -12.881197929382324,
      "logits/rejected": -13.157096862792969,
      "logps/chosen": -160.67701721191406,
      "logps/rejected": -203.49171447753906,
      "loss": 1.2495,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.381969451904297,
      "rewards/margins": 3.9476122856140137,
      "rewards/rejected": -12.329581260681152,
      "step": 3300
    },
    {
      "epoch": 2.11776,
      "grad_norm": 1.643627643585205,
      "learning_rate": 4.356945020807467e-05,
      "logits/chosen": -12.663122177124023,
      "logits/rejected": -12.755266189575195,
      "logps/chosen": -156.5100555419922,
      "logps/rejected": -197.89418029785156,
      "loss": 1.3169,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.1474027633667,
      "rewards/margins": 3.8177943229675293,
      "rewards/rejected": -11.965197563171387,
      "step": 3310
    },
    {
      "epoch": 2.12416,
      "grad_norm": 1.502394437789917,
      "learning_rate": 4.298816188961642e-05,
      "logits/chosen": -12.665655136108398,
      "logits/rejected": -12.683464050292969,
      "logps/chosen": -157.18663024902344,
      "logps/rejected": -198.0449676513672,
      "loss": 1.2889,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.308069229125977,
      "rewards/margins": 3.739952802658081,
      "rewards/rejected": -12.048023223876953,
      "step": 3320
    },
    {
      "epoch": 2.13056,
      "grad_norm": 1.630069613456726,
      "learning_rate": 4.240971376379447e-05,
      "logits/chosen": -11.744314193725586,
      "logits/rejected": -11.583536148071289,
      "logps/chosen": -158.4288330078125,
      "logps/rejected": -198.11474609375,
      "loss": 1.207,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -8.110635757446289,
      "rewards/margins": 3.853381395339966,
      "rewards/rejected": -11.964017868041992,
      "step": 3330
    },
    {
      "epoch": 2.13696,
      "grad_norm": 1.050610899925232,
      "learning_rate": 4.183413464750311e-05,
      "logits/chosen": -12.195784568786621,
      "logits/rejected": -12.079760551452637,
      "logps/chosen": -156.7012481689453,
      "logps/rejected": -193.71018981933594,
      "loss": 1.2704,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.262285232543945,
      "rewards/margins": 3.6697468757629395,
      "rewards/rejected": -11.932031631469727,
      "step": 3340
    },
    {
      "epoch": 2.14336,
      "grad_norm": 1.26113760471344,
      "learning_rate": 4.126145321470931e-05,
      "logits/chosen": -12.27332878112793,
      "logits/rejected": -12.51026725769043,
      "logps/chosen": -159.41818237304688,
      "logps/rejected": -200.93093872070312,
      "loss": 1.2506,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.410055160522461,
      "rewards/margins": 3.826228618621826,
      "rewards/rejected": -12.236284255981445,
      "step": 3350
    },
    {
      "epoch": 2.14976,
      "grad_norm": 1.6053967475891113,
      "learning_rate": 4.069169799502458e-05,
      "logits/chosen": -13.1346435546875,
      "logits/rejected": -13.199081420898438,
      "logps/chosen": -160.0100555419922,
      "logps/rejected": -199.295654296875,
      "loss": 1.2239,
      "rewards/accuracies": 0.9515625238418579,
      "rewards/chosen": -8.394396781921387,
      "rewards/margins": 3.7686362266540527,
      "rewards/rejected": -12.163033485412598,
      "step": 3360
    },
    {
      "epoch": 2.15616,
      "grad_norm": 1.5710631608963013,
      "learning_rate": 4.012489737228343e-05,
      "logits/chosen": -14.437646865844727,
      "logits/rejected": -14.19031047821045,
      "logps/chosen": -159.49493408203125,
      "logps/rejected": -199.29684448242188,
      "loss": 1.1909,
      "rewards/accuracies": 0.9765625,
      "rewards/chosen": -8.475064277648926,
      "rewards/margins": 3.8182125091552734,
      "rewards/rejected": -12.2932767868042,
      "step": 3370
    },
    {
      "epoch": 2.16256,
      "grad_norm": 1.972710132598877,
      "learning_rate": 3.956107958312944e-05,
      "logits/chosen": -15.359423637390137,
      "logits/rejected": -15.383527755737305,
      "logps/chosen": -161.1216583251953,
      "logps/rejected": -201.72824096679688,
      "loss": 1.3271,
      "rewards/accuracies": 0.9515625238418579,
      "rewards/chosen": -8.592381477355957,
      "rewards/margins": 3.968914031982422,
      "rewards/rejected": -12.561295509338379,
      "step": 3380
    },
    {
      "epoch": 2.16896,
      "grad_norm": 2.0541181564331055,
      "learning_rate": 3.90002727156087e-05,
      "logits/chosen": -14.898017883300781,
      "logits/rejected": -14.887571334838867,
      "logps/chosen": -163.031982421875,
      "logps/rejected": -203.6170196533203,
      "loss": 1.277,
      "rewards/accuracies": 0.956250011920929,
      "rewards/chosen": -8.580936431884766,
      "rewards/margins": 4.11796236038208,
      "rewards/rejected": -12.69890022277832,
      "step": 3390
    },
    {
      "epoch": 2.17536,
      "grad_norm": 1.1514461040496826,
      "learning_rate": 3.8442504707770344e-05,
      "logits/chosen": -13.835533142089844,
      "logits/rejected": -13.574037551879883,
      "logps/chosen": -161.2257080078125,
      "logps/rejected": -197.73695373535156,
      "loss": 1.2968,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.54638385772705,
      "rewards/margins": 3.8196377754211426,
      "rewards/rejected": -12.366021156311035,
      "step": 3400
    },
    {
      "epoch": 2.18176,
      "grad_norm": 1.1438510417938232,
      "learning_rate": 3.788780334627484e-05,
      "logits/chosen": -13.626643180847168,
      "logits/rejected": -13.34447956085205,
      "logps/chosen": -157.9033660888672,
      "logps/rejected": -197.5281219482422,
      "loss": 1.2885,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.310997009277344,
      "rewards/margins": 3.9491775035858154,
      "rewards/rejected": -12.260174751281738,
      "step": 3410
    },
    {
      "epoch": 2.18816,
      "grad_norm": 1.6927839517593384,
      "learning_rate": 3.733619626500968e-05,
      "logits/chosen": -14.058308601379395,
      "logits/rejected": -13.954632759094238,
      "logps/chosen": -162.97177124023438,
      "logps/rejected": -201.98184204101562,
      "loss": 1.2211,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.514245986938477,
      "rewards/margins": 3.975074291229248,
      "rewards/rejected": -12.489320755004883,
      "step": 3420
    },
    {
      "epoch": 2.19456,
      "grad_norm": 1.9724222421646118,
      "learning_rate": 3.678771094371288e-05,
      "logits/chosen": -14.293927192687988,
      "logits/rejected": -14.311139106750488,
      "logps/chosen": -162.72848510742188,
      "logps/rejected": -201.39797973632812,
      "loss": 1.2811,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.641923904418945,
      "rewards/margins": 3.8913254737854004,
      "rewards/rejected": -12.533249855041504,
      "step": 3430
    },
    {
      "epoch": 2.20096,
      "grad_norm": 2.4352970123291016,
      "learning_rate": 3.6242374706603754e-05,
      "logits/chosen": -14.54351806640625,
      "logits/rejected": -14.383050918579102,
      "logps/chosen": -159.80992126464844,
      "logps/rejected": -200.82534790039062,
      "loss": 1.2769,
      "rewards/accuracies": 0.956250011920929,
      "rewards/chosen": -8.597359657287598,
      "rewards/margins": 3.9947915077209473,
      "rewards/rejected": -12.592151641845703,
      "step": 3440
    },
    {
      "epoch": 2.20736,
      "grad_norm": 1.5991162061691284,
      "learning_rate": 3.570021472102183e-05,
      "logits/chosen": -14.661489486694336,
      "logits/rejected": -14.77058219909668,
      "logps/chosen": -161.90390014648438,
      "logps/rejected": -200.2891082763672,
      "loss": 1.2506,
      "rewards/accuracies": 0.9546874761581421,
      "rewards/chosen": -8.551977157592773,
      "rewards/margins": 3.87475323677063,
      "rewards/rejected": -12.426729202270508,
      "step": 3450
    },
    {
      "epoch": 2.21376,
      "grad_norm": 1.360635757446289,
      "learning_rate": 3.516125799607354e-05,
      "logits/chosen": -15.669418334960938,
      "logits/rejected": -15.540304183959961,
      "logps/chosen": -159.24960327148438,
      "logps/rejected": -203.77529907226562,
      "loss": 1.2524,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -8.42540168762207,
      "rewards/margins": 4.0971784591674805,
      "rewards/rejected": -12.522579193115234,
      "step": 3460
    },
    {
      "epoch": 2.22016,
      "grad_norm": 2.069000482559204,
      "learning_rate": 3.46255313812864e-05,
      "logits/chosen": -15.124931335449219,
      "logits/rejected": -15.223274230957031,
      "logps/chosen": -162.07403564453125,
      "logps/rejected": -204.642578125,
      "loss": 1.2933,
      "rewards/accuracies": 0.956250011920929,
      "rewards/chosen": -8.658784866333008,
      "rewards/margins": 4.10263729095459,
      "rewards/rejected": -12.761423110961914,
      "step": 3470
    },
    {
      "epoch": 2.22656,
      "grad_norm": 1.8831336498260498,
      "learning_rate": 3.409306156527181e-05,
      "logits/chosen": -14.836688041687012,
      "logits/rejected": -14.482078552246094,
      "logps/chosen": -163.76107788085938,
      "logps/rejected": -204.03695678710938,
      "loss": 1.2211,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.760765075683594,
      "rewards/margins": 4.0480756759643555,
      "rewards/rejected": -12.80884075164795,
      "step": 3480
    },
    {
      "epoch": 2.23296,
      "grad_norm": 1.662839651107788,
      "learning_rate": 3.356387507439511e-05,
      "logits/chosen": -14.122937202453613,
      "logits/rejected": -14.456350326538086,
      "logps/chosen": -161.03201293945312,
      "logps/rejected": -207.5089874267578,
      "loss": 1.3093,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.787223815917969,
      "rewards/margins": 4.143978118896484,
      "rewards/rejected": -12.931200981140137,
      "step": 3490
    },
    {
      "epoch": 2.23936,
      "grad_norm": 0.9599984884262085,
      "learning_rate": 3.3037998271454374e-05,
      "logits/chosen": -14.159489631652832,
      "logits/rejected": -14.116551399230957,
      "logps/chosen": -164.27731323242188,
      "logps/rejected": -202.29513549804688,
      "loss": 1.2898,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -8.699321746826172,
      "rewards/margins": 3.8319084644317627,
      "rewards/rejected": -12.531229972839355,
      "step": 3500
    },
    {
      "epoch": 2.24576,
      "grad_norm": 1.1886472702026367,
      "learning_rate": 3.251545735436695e-05,
      "logits/chosen": -14.082173347473145,
      "logits/rejected": -14.297861099243164,
      "logps/chosen": -160.1431427001953,
      "logps/rejected": -202.66064453125,
      "loss": 1.243,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.618627548217773,
      "rewards/margins": 3.8897666931152344,
      "rewards/rejected": -12.508394241333008,
      "step": 3510
    },
    {
      "epoch": 2.25216,
      "grad_norm": 1.8137086629867554,
      "learning_rate": 3.199627835486436e-05,
      "logits/chosen": -14.803863525390625,
      "logits/rejected": -14.791061401367188,
      "logps/chosen": -162.86788940429688,
      "logps/rejected": -205.356689453125,
      "loss": 1.2307,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.616860389709473,
      "rewards/margins": 4.162071228027344,
      "rewards/rejected": -12.778931617736816,
      "step": 3520
    },
    {
      "epoch": 2.25856,
      "grad_norm": 2.33494234085083,
      "learning_rate": 3.148048713719558e-05,
      "logits/chosen": -14.176702499389648,
      "logits/rejected": -14.139982223510742,
      "logps/chosen": -160.0326690673828,
      "logps/rejected": -204.2474365234375,
      "loss": 1.2877,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.559357643127441,
      "rewards/margins": 4.147338390350342,
      "rewards/rejected": -12.706695556640625,
      "step": 3530
    },
    {
      "epoch": 2.26496,
      "grad_norm": 1.345629096031189,
      "learning_rate": 3.0968109396838294e-05,
      "logits/chosen": -12.879328727722168,
      "logits/rejected": -12.862325668334961,
      "logps/chosen": -161.8211212158203,
      "logps/rejected": -200.13369750976562,
      "loss": 1.2237,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.658966064453125,
      "rewards/margins": 3.942162036895752,
      "rewards/rejected": -12.601127624511719,
      "step": 3540
    },
    {
      "epoch": 2.27136,
      "grad_norm": 2.3406999111175537,
      "learning_rate": 3.0459170659219105e-05,
      "logits/chosen": -12.511835098266602,
      "logits/rejected": -12.756061553955078,
      "logps/chosen": -161.99171447753906,
      "logps/rejected": -203.40420532226562,
      "loss": 1.2694,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.579462051391602,
      "rewards/margins": 4.007598876953125,
      "rewards/rejected": -12.587060928344727,
      "step": 3550
    },
    {
      "epoch": 2.27776,
      "grad_norm": 1.449479341506958,
      "learning_rate": 2.9953696278441668e-05,
      "logits/chosen": -12.703699111938477,
      "logits/rejected": -12.700642585754395,
      "logps/chosen": -161.57550048828125,
      "logps/rejected": -203.03248596191406,
      "loss": 1.277,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.700963020324707,
      "rewards/margins": 3.869724988937378,
      "rewards/rejected": -12.570688247680664,
      "step": 3560
    },
    {
      "epoch": 2.28416,
      "grad_norm": 1.615312933921814,
      "learning_rate": 2.9451711436023723e-05,
      "logits/chosen": -13.143499374389648,
      "logits/rejected": -13.199618339538574,
      "logps/chosen": -163.01210021972656,
      "logps/rejected": -207.25711059570312,
      "loss": 1.2296,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.717796325683594,
      "rewards/margins": 4.137458324432373,
      "rewards/rejected": -12.855255126953125,
      "step": 3570
    },
    {
      "epoch": 2.29056,
      "grad_norm": 1.2655668258666992,
      "learning_rate": 2.8953241139642683e-05,
      "logits/chosen": -14.817156791687012,
      "logits/rejected": -14.842679023742676,
      "logps/chosen": -158.6171417236328,
      "logps/rejected": -204.9302215576172,
      "loss": 1.3375,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.503945350646973,
      "rewards/margins": 4.123570442199707,
      "rewards/rejected": -12.62751579284668,
      "step": 3580
    },
    {
      "epoch": 2.29696,
      "grad_norm": 1.791825294494629,
      "learning_rate": 2.845831022188965e-05,
      "logits/chosen": -15.579442977905273,
      "logits/rejected": -15.238471984863281,
      "logps/chosen": -158.47439575195312,
      "logps/rejected": -201.26589965820312,
      "loss": 1.2532,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.304001808166504,
      "rewards/margins": 4.163234710693359,
      "rewards/rejected": -12.467236518859863,
      "step": 3590
    },
    {
      "epoch": 2.30336,
      "grad_norm": 1.3011560440063477,
      "learning_rate": 2.7966943339032404e-05,
      "logits/chosen": -15.22569751739502,
      "logits/rejected": -15.582969665527344,
      "logps/chosen": -157.06973266601562,
      "logps/rejected": -200.49635314941406,
      "loss": 1.251,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.371960639953613,
      "rewards/margins": 4.058351039886475,
      "rewards/rejected": -12.430312156677246,
      "step": 3600
    },
    {
      "epoch": 2.30976,
      "grad_norm": 2.2973172664642334,
      "learning_rate": 2.7479164969787118e-05,
      "logits/chosen": -15.34765338897705,
      "logits/rejected": -15.509328842163086,
      "logps/chosen": -160.87600708007812,
      "logps/rejected": -201.53555297851562,
      "loss": 1.2255,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.397082328796387,
      "rewards/margins": 4.0592145919799805,
      "rewards/rejected": -12.456298828125,
      "step": 3610
    },
    {
      "epoch": 2.31616,
      "grad_norm": 1.74185311794281,
      "learning_rate": 2.6994999414098787e-05,
      "logits/chosen": -15.341219902038574,
      "logits/rejected": -15.136674880981445,
      "logps/chosen": -162.91090393066406,
      "logps/rejected": -204.185791015625,
      "loss": 1.2183,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -8.45826244354248,
      "rewards/margins": 4.062300205230713,
      "rewards/rejected": -12.520563125610352,
      "step": 3620
    },
    {
      "epoch": 2.32256,
      "grad_norm": 1.3113644123077393,
      "learning_rate": 2.6514470791930835e-05,
      "logits/chosen": -14.475980758666992,
      "logits/rejected": -14.906648635864258,
      "logps/chosen": -158.68191528320312,
      "logps/rejected": -200.6653289794922,
      "loss": 1.2415,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.443656921386719,
      "rewards/margins": 4.003170967102051,
      "rewards/rejected": -12.44682788848877,
      "step": 3630
    },
    {
      "epoch": 2.32896,
      "grad_norm": 1.934539794921875,
      "learning_rate": 2.6037603042063274e-05,
      "logits/chosen": -14.771631240844727,
      "logits/rejected": -14.618914604187012,
      "logps/chosen": -165.022216796875,
      "logps/rejected": -207.07504272460938,
      "loss": 1.2693,
      "rewards/accuracies": 0.964062511920929,
      "rewards/chosen": -8.736024856567383,
      "rewards/margins": 4.140927314758301,
      "rewards/rejected": -12.876951217651367,
      "step": 3640
    },
    {
      "epoch": 2.33536,
      "grad_norm": 1.749548077583313,
      "learning_rate": 2.5564419920900384e-05,
      "logits/chosen": -14.908487319946289,
      "logits/rejected": -14.54912281036377,
      "logps/chosen": -163.10638427734375,
      "logps/rejected": -204.1059112548828,
      "loss": 1.2212,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -8.707132339477539,
      "rewards/margins": 3.814471483230591,
      "rewards/rejected": -12.52160358428955,
      "step": 3650
    },
    {
      "epoch": 2.34176,
      "grad_norm": 1.4239932298660278,
      "learning_rate": 2.5094945001287018e-05,
      "logits/chosen": -15.481046676635742,
      "logits/rejected": -15.477185249328613,
      "logps/chosen": -162.15115356445312,
      "logps/rejected": -201.88485717773438,
      "loss": 1.2686,
      "rewards/accuracies": 0.956250011920929,
      "rewards/chosen": -8.720738410949707,
      "rewards/margins": 3.911877155303955,
      "rewards/rejected": -12.63261604309082,
      "step": 3660
    },
    {
      "epoch": 2.34816,
      "grad_norm": 1.1609585285186768,
      "learning_rate": 2.4629201671334357e-05,
      "logits/chosen": -14.932966232299805,
      "logits/rejected": -14.857197761535645,
      "logps/chosen": -161.7471466064453,
      "logps/rejected": -204.12545776367188,
      "loss": 1.2436,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -8.669650077819824,
      "rewards/margins": 4.134722709655762,
      "rewards/rejected": -12.804372787475586,
      "step": 3670
    },
    {
      "epoch": 2.35456,
      "grad_norm": 2.1678507328033447,
      "learning_rate": 2.4167213133254874e-05,
      "logits/chosen": -15.129472732543945,
      "logits/rejected": -15.212173461914062,
      "logps/chosen": -166.40492248535156,
      "logps/rejected": -208.36050415039062,
      "loss": 1.2408,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -8.867666244506836,
      "rewards/margins": 4.111430644989014,
      "rewards/rejected": -12.979097366333008,
      "step": 3680
    },
    {
      "epoch": 2.36096,
      "grad_norm": 1.3982994556427002,
      "learning_rate": 2.3709002402206126e-05,
      "logits/chosen": -15.180084228515625,
      "logits/rejected": -15.203142166137695,
      "logps/chosen": -162.4635772705078,
      "logps/rejected": -204.9064178466797,
      "loss": 1.2576,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.769036293029785,
      "rewards/margins": 4.06702184677124,
      "rewards/rejected": -12.83605670928955,
      "step": 3690
    },
    {
      "epoch": 2.36736,
      "grad_norm": 2.003344774246216,
      "learning_rate": 2.325459230514462e-05,
      "logits/chosen": -15.175883293151855,
      "logits/rejected": -15.641805648803711,
      "logps/chosen": -163.27105712890625,
      "logps/rejected": -206.65853881835938,
      "loss": 1.2574,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.770498275756836,
      "rewards/margins": 4.059257984161377,
      "rewards/rejected": -12.829757690429688,
      "step": 3700
    },
    {
      "epoch": 2.37376,
      "grad_norm": 1.488471269607544,
      "learning_rate": 2.2804005479688295e-05,
      "logits/chosen": -15.160601615905762,
      "logits/rejected": -15.191965103149414,
      "logps/chosen": -161.71170043945312,
      "logps/rejected": -203.3802947998047,
      "loss": 1.2756,
      "rewards/accuracies": 0.964062511920929,
      "rewards/chosen": -8.62528133392334,
      "rewards/margins": 4.095872402191162,
      "rewards/rejected": -12.721153259277344,
      "step": 3710
    },
    {
      "epoch": 2.38016,
      "grad_norm": 1.6258409023284912,
      "learning_rate": 2.2357264372988995e-05,
      "logits/chosen": -14.480412483215332,
      "logits/rejected": -14.326147079467773,
      "logps/chosen": -165.11129760742188,
      "logps/rejected": -210.10873413085938,
      "loss": 1.2502,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -8.857948303222656,
      "rewards/margins": 4.2992353439331055,
      "rewards/rejected": -13.157183647155762,
      "step": 3720
    },
    {
      "epoch": 2.3865600000000002,
      "grad_norm": 1.9479199647903442,
      "learning_rate": 2.1914391240613997e-05,
      "logits/chosen": -14.273442268371582,
      "logits/rejected": -14.10148811340332,
      "logps/chosen": -163.10586547851562,
      "logps/rejected": -206.59603881835938,
      "loss": 1.2858,
      "rewards/accuracies": 0.953125,
      "rewards/chosen": -8.871098518371582,
      "rewards/margins": 4.216250896453857,
      "rewards/rejected": -13.087348937988281,
      "step": 3730
    },
    {
      "epoch": 2.39296,
      "grad_norm": 1.7776892185211182,
      "learning_rate": 2.1475408145437457e-05,
      "logits/chosen": -13.113540649414062,
      "logits/rejected": -12.814920425415039,
      "logps/chosen": -167.94813537597656,
      "logps/rejected": -210.50424194335938,
      "loss": 1.2763,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -9.043420791625977,
      "rewards/margins": 4.280800819396973,
      "rewards/rejected": -13.32422161102295,
      "step": 3740
    },
    {
      "epoch": 2.39936,
      "grad_norm": 1.9632364511489868,
      "learning_rate": 2.104033695654126e-05,
      "logits/chosen": -12.684772491455078,
      "logits/rejected": -12.411706924438477,
      "logps/chosen": -165.80667114257812,
      "logps/rejected": -209.87353515625,
      "loss": 1.2173,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -9.00284194946289,
      "rewards/margins": 4.296941757202148,
      "rewards/rejected": -13.299783706665039,
      "step": 3750
    },
    {
      "epoch": 2.40576,
      "grad_norm": 1.287738561630249,
      "learning_rate": 2.0609199348125462e-05,
      "logits/chosen": -11.795000076293945,
      "logits/rejected": -11.929022789001465,
      "logps/chosen": -166.23646545410156,
      "logps/rejected": -208.1143035888672,
      "loss": 1.2418,
      "rewards/accuracies": 0.9546874761581421,
      "rewards/chosen": -9.05449104309082,
      "rewards/margins": 4.162383079528809,
      "rewards/rejected": -13.216876029968262,
      "step": 3760
    },
    {
      "epoch": 2.41216,
      "grad_norm": 1.5865049362182617,
      "learning_rate": 2.0182016798428714e-05,
      "logits/chosen": -12.029245376586914,
      "logits/rejected": -11.818649291992188,
      "logps/chosen": -163.9508056640625,
      "logps/rejected": -207.1068878173828,
      "loss": 1.2378,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -9.014806747436523,
      "rewards/margins": 4.222416877746582,
      "rewards/rejected": -13.237225532531738,
      "step": 3770
    },
    {
      "epoch": 2.41856,
      "grad_norm": 1.7366209030151367,
      "learning_rate": 1.9758810588657973e-05,
      "logits/chosen": -11.721059799194336,
      "logits/rejected": -11.742297172546387,
      "logps/chosen": -164.07839965820312,
      "logps/rejected": -209.24826049804688,
      "loss": 1.2769,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -8.881341934204102,
      "rewards/margins": 4.367497444152832,
      "rewards/rejected": -13.248838424682617,
      "step": 3780
    },
    {
      "epoch": 2.42496,
      "grad_norm": 1.505773901939392,
      "learning_rate": 1.9339601801928707e-05,
      "logits/chosen": -11.983248710632324,
      "logits/rejected": -11.798786163330078,
      "logps/chosen": -165.7200469970703,
      "logps/rejected": -207.848876953125,
      "loss": 1.2797,
      "rewards/accuracies": 0.964062511920929,
      "rewards/chosen": -9.093235969543457,
      "rewards/margins": 4.105976104736328,
      "rewards/rejected": -13.199211120605469,
      "step": 3790
    },
    {
      "epoch": 2.43136,
      "grad_norm": 1.812117099761963,
      "learning_rate": 1.8924411322214252e-05,
      "logits/chosen": -12.678540229797363,
      "logits/rejected": -12.555041313171387,
      "logps/chosen": -164.3771209716797,
      "logps/rejected": -211.70034790039062,
      "loss": 1.2282,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -8.860040664672852,
      "rewards/margins": 4.41860294342041,
      "rewards/rejected": -13.278643608093262,
      "step": 3800
    },
    {
      "epoch": 2.43776,
      "grad_norm": 0.9433198571205139,
      "learning_rate": 1.8513259833305564e-05,
      "logits/chosen": -13.476472854614258,
      "logits/rejected": -13.282147407531738,
      "logps/chosen": -164.3009796142578,
      "logps/rejected": -211.80746459960938,
      "loss": 1.1976,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -8.964932441711426,
      "rewards/margins": 4.2920684814453125,
      "rewards/rejected": -13.256999015808105,
      "step": 3810
    },
    {
      "epoch": 2.44416,
      "grad_norm": 1.6078695058822632,
      "learning_rate": 1.8106167817780884e-05,
      "logits/chosen": -13.611468315124512,
      "logits/rejected": -13.765085220336914,
      "logps/chosen": -165.29315185546875,
      "logps/rejected": -210.64987182617188,
      "loss": 1.2901,
      "rewards/accuracies": 0.953125,
      "rewards/chosen": -8.977886199951172,
      "rewards/margins": 4.301407814025879,
      "rewards/rejected": -13.27929401397705,
      "step": 3820
    },
    {
      "epoch": 2.45056,
      "grad_norm": 1.2473325729370117,
      "learning_rate": 1.770315555598514e-05,
      "logits/chosen": -14.288599967956543,
      "logits/rejected": -14.201635360717773,
      "logps/chosen": -161.92990112304688,
      "logps/rejected": -208.28988647460938,
      "loss": 1.2145,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.807635307312012,
      "rewards/margins": 4.3878607749938965,
      "rewards/rejected": -13.1954984664917,
      "step": 3830
    },
    {
      "epoch": 2.45696,
      "grad_norm": 2.063035249710083,
      "learning_rate": 1.7304243125019848e-05,
      "logits/chosen": -13.976885795593262,
      "logits/rejected": -13.941821098327637,
      "logps/chosen": -161.9630889892578,
      "logps/rejected": -207.00503540039062,
      "loss": 1.2708,
      "rewards/accuracies": 0.956250011920929,
      "rewards/chosen": -8.780211448669434,
      "rewards/margins": 4.373695373535156,
      "rewards/rejected": -13.153905868530273,
      "step": 3840
    },
    {
      "epoch": 2.4633599999999998,
      "grad_norm": 1.3761895895004272,
      "learning_rate": 1.6909450397742723e-05,
      "logits/chosen": -14.580947875976562,
      "logits/rejected": -14.74474048614502,
      "logps/chosen": -163.7233428955078,
      "logps/rejected": -212.93612670898438,
      "loss": 1.3038,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -9.124855041503906,
      "rewards/margins": 4.375690460205078,
      "rewards/rejected": -13.5005464553833,
      "step": 3850
    },
    {
      "epoch": 2.46976,
      "grad_norm": 2.1698012351989746,
      "learning_rate": 1.651879704177779e-05,
      "logits/chosen": -14.294034004211426,
      "logits/rejected": -14.12419319152832,
      "logps/chosen": -164.76220703125,
      "logps/rejected": -204.7892608642578,
      "loss": 1.2516,
      "rewards/accuracies": 0.964062511920929,
      "rewards/chosen": -8.965580940246582,
      "rewards/margins": 4.127730369567871,
      "rewards/rejected": -13.09331226348877,
      "step": 3860
    },
    {
      "epoch": 2.47616,
      "grad_norm": 1.5426082611083984,
      "learning_rate": 1.613230251853556e-05,
      "logits/chosen": -14.194798469543457,
      "logits/rejected": -14.099821090698242,
      "logps/chosen": -163.29254150390625,
      "logps/rejected": -203.90476989746094,
      "loss": 1.1798,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.867244720458984,
      "rewards/margins": 4.062439918518066,
      "rewards/rejected": -12.929682731628418,
      "step": 3870
    },
    {
      "epoch": 2.48256,
      "grad_norm": 1.5567233562469482,
      "learning_rate": 1.5749986082243472e-05,
      "logits/chosen": -14.488153457641602,
      "logits/rejected": -14.893412590026855,
      "logps/chosen": -164.7168731689453,
      "logps/rejected": -208.53109741210938,
      "loss": 1.247,
      "rewards/accuracies": 0.9546874761581421,
      "rewards/chosen": -8.899255752563477,
      "rewards/margins": 4.216252326965332,
      "rewards/rejected": -13.115507125854492,
      "step": 3880
    },
    {
      "epoch": 2.48896,
      "grad_norm": 1.1955599784851074,
      "learning_rate": 1.5371866778986777e-05,
      "logits/chosen": -14.798741340637207,
      "logits/rejected": -14.92137622833252,
      "logps/chosen": -164.6940155029297,
      "logps/rejected": -208.51492309570312,
      "loss": 1.2215,
      "rewards/accuracies": 0.9765625,
      "rewards/chosen": -8.963912963867188,
      "rewards/margins": 4.228631496429443,
      "rewards/rejected": -13.192544937133789,
      "step": 3890
    },
    {
      "epoch": 2.49536,
      "grad_norm": 1.9547501802444458,
      "learning_rate": 1.499796344575959e-05,
      "logits/chosen": -14.639802932739258,
      "logits/rejected": -14.614217758178711,
      "logps/chosen": -166.29714965820312,
      "logps/rejected": -210.5738983154297,
      "loss": 1.2368,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.990636825561523,
      "rewards/margins": 4.358151912689209,
      "rewards/rejected": -13.348790168762207,
      "step": 3900
    },
    {
      "epoch": 2.50176,
      "grad_norm": 1.195235252380371,
      "learning_rate": 1.4628294709526613e-05,
      "logits/chosen": -14.186544418334961,
      "logits/rejected": -14.227795600891113,
      "logps/chosen": -163.93003845214844,
      "logps/rejected": -205.2239990234375,
      "loss": 1.2349,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.96541690826416,
      "rewards/margins": 4.164242744445801,
      "rewards/rejected": -13.129658699035645,
      "step": 3910
    },
    {
      "epoch": 2.50816,
      "grad_norm": 2.248589277267456,
      "learning_rate": 1.4262878986295047e-05,
      "logits/chosen": -14.175585746765137,
      "logits/rejected": -14.06677532196045,
      "logps/chosen": -163.53443908691406,
      "logps/rejected": -207.9038543701172,
      "loss": 1.2652,
      "rewards/accuracies": 0.9515625238418579,
      "rewards/chosen": -8.894224166870117,
      "rewards/margins": 4.1159563064575195,
      "rewards/rejected": -13.01017951965332,
      "step": 3920
    },
    {
      "epoch": 2.51456,
      "grad_norm": 1.511198878288269,
      "learning_rate": 1.3901734480197215e-05,
      "logits/chosen": -13.87812614440918,
      "logits/rejected": -13.817270278930664,
      "logps/chosen": -163.71554565429688,
      "logps/rejected": -209.69033813476562,
      "loss": 1.2274,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.655890464782715,
      "rewards/margins": 4.465310096740723,
      "rewards/rejected": -13.12120246887207,
      "step": 3930
    },
    {
      "epoch": 2.52096,
      "grad_norm": 1.9173160791397095,
      "learning_rate": 1.3544879182583748e-05,
      "logits/chosen": -12.91357421875,
      "logits/rejected": -12.92475414276123,
      "logps/chosen": -163.0397186279297,
      "logps/rejected": -208.2424774169922,
      "loss": 1.2304,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.743481636047363,
      "rewards/margins": 4.305502891540527,
      "rewards/rejected": -13.048985481262207,
      "step": 3940
    },
    {
      "epoch": 2.52736,
      "grad_norm": 1.396233081817627,
      "learning_rate": 1.3192330871127134e-05,
      "logits/chosen": -13.066886901855469,
      "logits/rejected": -12.555364608764648,
      "logps/chosen": -160.92849731445312,
      "logps/rejected": -203.24688720703125,
      "loss": 1.2943,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -8.488804817199707,
      "rewards/margins": 4.224676132202148,
      "rewards/rejected": -12.713480949401855,
      "step": 3950
    },
    {
      "epoch": 2.53376,
      "grad_norm": 1.811269760131836,
      "learning_rate": 1.2844107108936288e-05,
      "logits/chosen": -12.653494834899902,
      "logits/rejected": -13.005874633789062,
      "logps/chosen": -162.8949432373047,
      "logps/rejected": -207.87301635742188,
      "loss": 1.246,
      "rewards/accuracies": 0.9781249761581421,
      "rewards/chosen": -8.672369003295898,
      "rewards/margins": 4.199176788330078,
      "rewards/rejected": -12.871545791625977,
      "step": 3960
    },
    {
      "epoch": 2.54016,
      "grad_norm": 1.9216924905776978,
      "learning_rate": 1.2500225243681319e-05,
      "logits/chosen": -12.821096420288086,
      "logits/rejected": -12.880996704101562,
      "logps/chosen": -163.04568481445312,
      "logps/rejected": -204.0800018310547,
      "loss": 1.3093,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -8.673397064208984,
      "rewards/margins": 4.209224224090576,
      "rewards/rejected": -12.882619857788086,
      "step": 3970
    },
    {
      "epoch": 2.54656,
      "grad_norm": 1.810299277305603,
      "learning_rate": 1.216070240672964e-05,
      "logits/chosen": -12.925732612609863,
      "logits/rejected": -13.1163969039917,
      "logps/chosen": -161.12371826171875,
      "logps/rejected": -203.66539001464844,
      "loss": 1.2441,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -8.629298210144043,
      "rewards/margins": 4.061579704284668,
      "rewards/rejected": -12.690877914428711,
      "step": 3980
    },
    {
      "epoch": 2.55296,
      "grad_norm": 1.1916013956069946,
      "learning_rate": 1.1825555512292263e-05,
      "logits/chosen": -12.992671012878418,
      "logits/rejected": -13.52136516571045,
      "logps/chosen": -159.70663452148438,
      "logps/rejected": -206.46255493164062,
      "loss": 1.2283,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.778570175170898,
      "rewards/margins": 4.140465259552002,
      "rewards/rejected": -12.919034957885742,
      "step": 3990
    },
    {
      "epoch": 2.55936,
      "grad_norm": 1.357262372970581,
      "learning_rate": 1.1494801256581267e-05,
      "logits/chosen": -13.982684135437012,
      "logits/rejected": -14.072291374206543,
      "logps/chosen": -163.25535583496094,
      "logps/rejected": -205.1995086669922,
      "loss": 1.2478,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -8.682943344116211,
      "rewards/margins": 4.26019287109375,
      "rewards/rejected": -12.943136215209961,
      "step": 4000
    },
    {
      "epoch": 2.56576,
      "grad_norm": 2.2080812454223633,
      "learning_rate": 1.1168456116978121e-05,
      "logits/chosen": -13.648588180541992,
      "logits/rejected": -13.623878479003906,
      "logps/chosen": -165.03128051757812,
      "logps/rejected": -209.672607421875,
      "loss": 1.3039,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.764687538146973,
      "rewards/margins": 4.325015544891357,
      "rewards/rejected": -13.089703559875488,
      "step": 4010
    },
    {
      "epoch": 2.5721600000000002,
      "grad_norm": 2.074406623840332,
      "learning_rate": 1.0846536351212622e-05,
      "logits/chosen": -13.793683052062988,
      "logits/rejected": -14.074931144714355,
      "logps/chosen": -160.68923950195312,
      "logps/rejected": -206.3498077392578,
      "loss": 1.2808,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -8.841227531433105,
      "rewards/margins": 4.213184356689453,
      "rewards/rejected": -13.054412841796875,
      "step": 4020
    },
    {
      "epoch": 2.57856,
      "grad_norm": 1.664778709411621,
      "learning_rate": 1.0529057996553181e-05,
      "logits/chosen": -14.173932075500488,
      "logits/rejected": -14.438947677612305,
      "logps/chosen": -163.2525177001953,
      "logps/rejected": -207.1506805419922,
      "loss": 1.2321,
      "rewards/accuracies": 0.9781249761581421,
      "rewards/chosen": -8.848123550415039,
      "rewards/margins": 4.152501106262207,
      "rewards/rejected": -13.000625610351562,
      "step": 4030
    },
    {
      "epoch": 2.58496,
      "grad_norm": 0.9164110422134399,
      "learning_rate": 1.021603686900775e-05,
      "logits/chosen": -14.152458190917969,
      "logits/rejected": -14.09130573272705,
      "logps/chosen": -162.14358520507812,
      "logps/rejected": -204.63067626953125,
      "loss": 1.2585,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -8.706708908081055,
      "rewards/margins": 4.20816707611084,
      "rewards/rejected": -12.914878845214844,
      "step": 4040
    },
    {
      "epoch": 2.59136,
      "grad_norm": 1.772959589958191,
      "learning_rate": 9.907488562535927e-06,
      "logits/chosen": -13.684820175170898,
      "logits/rejected": -13.823343276977539,
      "logps/chosen": -166.751953125,
      "logps/rejected": -207.787841796875,
      "loss": 1.2549,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.88181209564209,
      "rewards/margins": 4.223282337188721,
      "rewards/rejected": -13.105093002319336,
      "step": 4050
    },
    {
      "epoch": 2.59776,
      "grad_norm": 1.1867843866348267,
      "learning_rate": 9.603428448272179e-06,
      "logits/chosen": -14.081164360046387,
      "logits/rejected": -14.339035034179688,
      "logps/chosen": -161.1685791015625,
      "logps/rejected": -208.37130737304688,
      "loss": 1.2435,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -8.868361473083496,
      "rewards/margins": 4.221526145935059,
      "rewards/rejected": -13.089887619018555,
      "step": 4060
    },
    {
      "epoch": 2.6041600000000003,
      "grad_norm": 1.2810876369476318,
      "learning_rate": 9.303871673759955e-06,
      "logits/chosen": -13.992513656616211,
      "logits/rejected": -14.117731094360352,
      "logps/chosen": -164.8451385498047,
      "logps/rejected": -210.572509765625,
      "loss": 1.2369,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -8.920143127441406,
      "rewards/margins": 4.400969505310059,
      "rewards/rejected": -13.321111679077148,
      "step": 4070
    },
    {
      "epoch": 2.61056,
      "grad_norm": 1.3538721799850464,
      "learning_rate": 9.00883316219725e-06,
      "logits/chosen": -13.457498550415039,
      "logits/rejected": -13.727838516235352,
      "logps/chosen": -166.28363037109375,
      "logps/rejected": -212.07009887695312,
      "loss": 1.2548,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -9.018159866333008,
      "rewards/margins": 4.295169353485107,
      "rewards/rejected": -13.313328742980957,
      "step": 4080
    },
    {
      "epoch": 2.6169599999999997,
      "grad_norm": 2.2946808338165283,
      "learning_rate": 8.718327611692967e-06,
      "logits/chosen": -14.035879135131836,
      "logits/rejected": -14.053329467773438,
      "logps/chosen": -166.21739196777344,
      "logps/rejected": -212.12643432617188,
      "loss": 1.2412,
      "rewards/accuracies": 0.9765625,
      "rewards/chosen": -9.016112327575684,
      "rewards/margins": 4.552868366241455,
      "rewards/rejected": -13.568982124328613,
      "step": 4090
    },
    {
      "epoch": 2.62336,
      "grad_norm": 0.9782627820968628,
      "learning_rate": 8.432369494534887e-06,
      "logits/chosen": -13.773515701293945,
      "logits/rejected": -13.39673137664795,
      "logps/chosen": -164.10504150390625,
      "logps/rejected": -208.1514892578125,
      "loss": 1.1875,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -8.931913375854492,
      "rewards/margins": 4.350639820098877,
      "rewards/rejected": -13.282552719116211,
      "step": 4100
    },
    {
      "epoch": 2.62976,
      "grad_norm": 1.4783905744552612,
      "learning_rate": 8.150973056468513e-06,
      "logits/chosen": -14.075340270996094,
      "logits/rejected": -14.139071464538574,
      "logps/chosen": -168.11746215820312,
      "logps/rejected": -213.9027557373047,
      "loss": 1.2011,
      "rewards/accuracies": 0.9781249761581421,
      "rewards/chosen": -9.085890769958496,
      "rewards/margins": 4.513937950134277,
      "rewards/rejected": -13.599828720092773,
      "step": 4110
    },
    {
      "epoch": 2.63616,
      "grad_norm": 1.6742349863052368,
      "learning_rate": 7.874152315987515e-06,
      "logits/chosen": -14.393569946289062,
      "logits/rejected": -14.14985179901123,
      "logps/chosen": -166.76129150390625,
      "logps/rejected": -210.7138671875,
      "loss": 1.3107,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.995828628540039,
      "rewards/margins": 4.328873634338379,
      "rewards/rejected": -13.32470417022705,
      "step": 4120
    },
    {
      "epoch": 2.64256,
      "grad_norm": 1.8679252862930298,
      "learning_rate": 7.601921063635342e-06,
      "logits/chosen": -13.737228393554688,
      "logits/rejected": -14.17352294921875,
      "logps/chosen": -162.3965301513672,
      "logps/rejected": -210.00192260742188,
      "loss": 1.2822,
      "rewards/accuracies": 0.9453125,
      "rewards/chosen": -8.94965934753418,
      "rewards/margins": 4.477412223815918,
      "rewards/rejected": -13.427070617675781,
      "step": 4130
    },
    {
      "epoch": 2.6489599999999998,
      "grad_norm": 1.7721196413040161,
      "learning_rate": 7.334292861318126e-06,
      "logits/chosen": -15.261631965637207,
      "logits/rejected": -14.599992752075195,
      "logps/chosen": -167.73281860351562,
      "logps/rejected": -208.958984375,
      "loss": 1.2731,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -9.111242294311523,
      "rewards/margins": 4.2383131980896,
      "rewards/rejected": -13.349557876586914,
      "step": 4140
    },
    {
      "epoch": 2.65536,
      "grad_norm": 1.6945708990097046,
      "learning_rate": 7.071281041629141e-06,
      "logits/chosen": -14.577857971191406,
      "logits/rejected": -14.612161636352539,
      "logps/chosen": -165.574951171875,
      "logps/rejected": -210.40524291992188,
      "loss": 1.2558,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -9.032865524291992,
      "rewards/margins": 4.331129550933838,
      "rewards/rejected": -13.363995552062988,
      "step": 4150
    },
    {
      "epoch": 2.66176,
      "grad_norm": 2.0052618980407715,
      "learning_rate": 6.81289870718459e-06,
      "logits/chosen": -14.686487197875977,
      "logits/rejected": -14.723388671875,
      "logps/chosen": -167.95858764648438,
      "logps/rejected": -211.28738403320312,
      "loss": 1.3033,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.150971412658691,
      "rewards/margins": 4.180916786193848,
      "rewards/rejected": -13.331889152526855,
      "step": 4160
    },
    {
      "epoch": 2.66816,
      "grad_norm": 2.207364320755005,
      "learning_rate": 6.559158729970827e-06,
      "logits/chosen": -14.684298515319824,
      "logits/rejected": -14.753683090209961,
      "logps/chosen": -168.60952758789062,
      "logps/rejected": -210.8955078125,
      "loss": 1.3146,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -9.139199256896973,
      "rewards/margins": 4.263424873352051,
      "rewards/rejected": -13.402624130249023,
      "step": 4170
    },
    {
      "epoch": 2.67456,
      "grad_norm": 1.0033442974090576,
      "learning_rate": 6.310073750703216e-06,
      "logits/chosen": -14.782434463500977,
      "logits/rejected": -15.235403060913086,
      "logps/chosen": -163.90586853027344,
      "logps/rejected": -208.56033325195312,
      "loss": 1.2439,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.959257125854492,
      "rewards/margins": 4.169898986816406,
      "rewards/rejected": -13.129155158996582,
      "step": 4180
    },
    {
      "epoch": 2.68096,
      "grad_norm": 1.4934422969818115,
      "learning_rate": 6.065656178196221e-06,
      "logits/chosen": -14.643152236938477,
      "logits/rejected": -14.652348518371582,
      "logps/chosen": -163.82638549804688,
      "logps/rejected": -210.36306762695312,
      "loss": 1.229,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -9.007317543029785,
      "rewards/margins": 4.389458656311035,
      "rewards/rejected": -13.396774291992188,
      "step": 4190
    },
    {
      "epoch": 2.68736,
      "grad_norm": 2.2424521446228027,
      "learning_rate": 5.825918188745405e-06,
      "logits/chosen": -15.055908203125,
      "logits/rejected": -15.149706840515137,
      "logps/chosen": -165.19296264648438,
      "logps/rejected": -205.82876586914062,
      "loss": 1.2483,
      "rewards/accuracies": 0.949999988079071,
      "rewards/chosen": -8.90677261352539,
      "rewards/margins": 4.033688545227051,
      "rewards/rejected": -12.940460205078125,
      "step": 4200
    },
    {
      "epoch": 2.69376,
      "grad_norm": 0.9266585111618042,
      "learning_rate": 5.5908717255207075e-06,
      "logits/chosen": -15.23652172088623,
      "logits/rejected": -14.891035079956055,
      "logps/chosen": -164.46484375,
      "logps/rejected": -208.83218383789062,
      "loss": 1.3156,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -8.987249374389648,
      "rewards/margins": 4.369117736816406,
      "rewards/rejected": -13.356367111206055,
      "step": 4210
    },
    {
      "epoch": 2.70016,
      "grad_norm": 2.0241143703460693,
      "learning_rate": 5.360528497971528e-06,
      "logits/chosen": -14.5733003616333,
      "logits/rejected": -14.355413436889648,
      "logps/chosen": -165.1309356689453,
      "logps/rejected": -207.2318115234375,
      "loss": 1.208,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.937612533569336,
      "rewards/margins": 4.239074230194092,
      "rewards/rejected": -13.17668628692627,
      "step": 4220
    },
    {
      "epoch": 2.70656,
      "grad_norm": 1.4455277919769287,
      "learning_rate": 5.134899981243424e-06,
      "logits/chosen": -14.444117546081543,
      "logits/rejected": -14.57244873046875,
      "logps/chosen": -161.136474609375,
      "logps/rejected": -209.64028930664062,
      "loss": 1.2642,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -8.866300582885742,
      "rewards/margins": 4.303069114685059,
      "rewards/rejected": -13.1693696975708,
      "step": 4230
    },
    {
      "epoch": 2.71296,
      "grad_norm": 1.3809022903442383,
      "learning_rate": 4.913997415606342e-06,
      "logits/chosen": -15.243173599243164,
      "logits/rejected": -15.020196914672852,
      "logps/chosen": -166.0286407470703,
      "logps/rejected": -209.2540283203125,
      "loss": 1.223,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.95722770690918,
      "rewards/margins": 4.334796905517578,
      "rewards/rejected": -13.292025566101074,
      "step": 4240
    },
    {
      "epoch": 2.71936,
      "grad_norm": 1.6504312753677368,
      "learning_rate": 4.697831805894725e-06,
      "logits/chosen": -14.727411270141602,
      "logits/rejected": -14.783029556274414,
      "logps/chosen": -166.3818359375,
      "logps/rejected": -208.5824737548828,
      "loss": 1.2795,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -8.94408893585205,
      "rewards/margins": 4.303214073181152,
      "rewards/rejected": -13.24730396270752,
      "step": 4250
    },
    {
      "epoch": 2.72576,
      "grad_norm": 2.3940961360931396,
      "learning_rate": 4.486413920959287e-06,
      "logits/chosen": -14.3902587890625,
      "logits/rejected": -14.743902206420898,
      "logps/chosen": -161.7819366455078,
      "logps/rejected": -209.2224884033203,
      "loss": 1.2146,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.86568832397461,
      "rewards/margins": 4.2347412109375,
      "rewards/rejected": -13.100428581237793,
      "step": 4260
    },
    {
      "epoch": 2.73216,
      "grad_norm": 1.08775794506073,
      "learning_rate": 4.279754293130511e-06,
      "logits/chosen": -14.025190353393555,
      "logits/rejected": -14.029454231262207,
      "logps/chosen": -162.00454711914062,
      "logps/rejected": -204.66796875,
      "loss": 1.2003,
      "rewards/accuracies": 0.9765625,
      "rewards/chosen": -8.762985229492188,
      "rewards/margins": 4.206006050109863,
      "rewards/rejected": -12.96899127960205,
      "step": 4270
    },
    {
      "epoch": 2.73856,
      "grad_norm": 2.414522171020508,
      "learning_rate": 4.077863217693934e-06,
      "logits/chosen": -14.87928581237793,
      "logits/rejected": -14.562782287597656,
      "logps/chosen": -163.68783569335938,
      "logps/rejected": -207.8114471435547,
      "loss": 1.253,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.97351360321045,
      "rewards/margins": 4.362026691436768,
      "rewards/rejected": -13.335540771484375,
      "step": 4280
    },
    {
      "epoch": 2.74496,
      "grad_norm": 1.8412401676177979,
      "learning_rate": 3.880750752377293e-06,
      "logits/chosen": -14.508641242980957,
      "logits/rejected": -14.643987655639648,
      "logps/chosen": -166.11122131347656,
      "logps/rejected": -209.10891723632812,
      "loss": 1.249,
      "rewards/accuracies": 0.964062511920929,
      "rewards/chosen": -8.939329147338867,
      "rewards/margins": 4.244555473327637,
      "rewards/rejected": -13.18388557434082,
      "step": 4290
    },
    {
      "epoch": 2.75136,
      "grad_norm": 2.111499071121216,
      "learning_rate": 3.6884267168495025e-06,
      "logits/chosen": -14.347959518432617,
      "logits/rejected": -14.543551445007324,
      "logps/chosen": -163.911376953125,
      "logps/rejected": -209.70205688476562,
      "loss": 1.2781,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -8.947604179382324,
      "rewards/margins": 4.350162982940674,
      "rewards/rejected": -13.297765731811523,
      "step": 4300
    },
    {
      "epoch": 2.75776,
      "grad_norm": 1.6353633403778076,
      "learning_rate": 3.500900692231346e-06,
      "logits/chosen": -14.638005256652832,
      "logits/rejected": -14.584783554077148,
      "logps/chosen": -164.0821075439453,
      "logps/rejected": -209.48397827148438,
      "loss": 1.3037,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -9.013267517089844,
      "rewards/margins": 4.2762932777404785,
      "rewards/rejected": -13.289560317993164,
      "step": 4310
    },
    {
      "epoch": 2.76416,
      "grad_norm": 1.6884806156158447,
      "learning_rate": 3.318182020618321e-06,
      "logits/chosen": -14.66047191619873,
      "logits/rejected": -14.815513610839844,
      "logps/chosen": -162.12091064453125,
      "logps/rejected": -214.02725219726562,
      "loss": 1.2436,
      "rewards/accuracies": 0.9750000238418579,
      "rewards/chosen": -8.835168838500977,
      "rewards/margins": 4.658259391784668,
      "rewards/rejected": -13.493426322937012,
      "step": 4320
    },
    {
      "epoch": 2.77056,
      "grad_norm": 1.190964937210083,
      "learning_rate": 3.1402798046151317e-06,
      "logits/chosen": -14.405130386352539,
      "logits/rejected": -14.301294326782227,
      "logps/chosen": -163.94009399414062,
      "logps/rejected": -205.7428436279297,
      "loss": 1.2214,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -8.837282180786133,
      "rewards/margins": 4.216500759124756,
      "rewards/rejected": -13.053784370422363,
      "step": 4330
    },
    {
      "epoch": 2.77696,
      "grad_norm": 1.307544469833374,
      "learning_rate": 2.967202906882216e-06,
      "logits/chosen": -14.471888542175293,
      "logits/rejected": -14.349848747253418,
      "logps/chosen": -166.49560546875,
      "logps/rejected": -209.54721069335938,
      "loss": 1.2621,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.904314994812012,
      "rewards/margins": 4.249325275421143,
      "rewards/rejected": -13.153640747070312,
      "step": 4340
    },
    {
      "epoch": 2.78336,
      "grad_norm": 1.9574933052062988,
      "learning_rate": 2.798959949694324e-06,
      "logits/chosen": -14.334402084350586,
      "logits/rejected": -14.481791496276855,
      "logps/chosen": -165.8270721435547,
      "logps/rejected": -207.9853515625,
      "loss": 1.2578,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.947961807250977,
      "rewards/margins": 4.242127418518066,
      "rewards/rejected": -13.190089225769043,
      "step": 4350
    },
    {
      "epoch": 2.7897600000000002,
      "grad_norm": 1.8992537260055542,
      "learning_rate": 2.635559314510849e-06,
      "logits/chosen": -14.364219665527344,
      "logits/rejected": -14.208993911743164,
      "logps/chosen": -163.5023956298828,
      "logps/rejected": -205.9712677001953,
      "loss": 1.1911,
      "rewards/accuracies": 0.971875011920929,
      "rewards/chosen": -8.859029769897461,
      "rewards/margins": 4.184072017669678,
      "rewards/rejected": -13.043103218078613,
      "step": 4360
    },
    {
      "epoch": 2.79616,
      "grad_norm": 1.0153790712356567,
      "learning_rate": 2.4770091415584283e-06,
      "logits/chosen": -14.591758728027344,
      "logits/rejected": -14.377693176269531,
      "logps/chosen": -165.81185913085938,
      "logps/rejected": -211.1229248046875,
      "loss": 1.2252,
      "rewards/accuracies": 0.9828125238418579,
      "rewards/chosen": -8.93702507019043,
      "rewards/margins": 4.394364356994629,
      "rewards/rejected": -13.331387519836426,
      "step": 4370
    },
    {
      "epoch": 2.80256,
      "grad_norm": 2.0766351222991943,
      "learning_rate": 2.3233173294252676e-06,
      "logits/chosen": -14.31822395324707,
      "logits/rejected": -14.169092178344727,
      "logps/chosen": -161.92616271972656,
      "logps/rejected": -209.9960479736328,
      "loss": 1.2863,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -9.007112503051758,
      "rewards/margins": 4.296326637268066,
      "rewards/rejected": -13.303438186645508,
      "step": 4380
    },
    {
      "epoch": 2.80896,
      "grad_norm": 2.053292751312256,
      "learning_rate": 2.174491534667766e-06,
      "logits/chosen": -14.002012252807617,
      "logits/rejected": -13.768915176391602,
      "logps/chosen": -161.2444305419922,
      "logps/rejected": -205.65390014648438,
      "loss": 1.2426,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.992876052856445,
      "rewards/margins": 4.149871826171875,
      "rewards/rejected": -13.14274787902832,
      "step": 4390
    },
    {
      "epoch": 2.81536,
      "grad_norm": 1.313151240348816,
      "learning_rate": 2.0305391714290245e-06,
      "logits/chosen": -14.425732612609863,
      "logits/rejected": -14.186485290527344,
      "logps/chosen": -164.2488250732422,
      "logps/rejected": -210.1909637451172,
      "loss": 1.247,
      "rewards/accuracies": 0.9609375,
      "rewards/chosen": -8.934436798095703,
      "rewards/margins": 4.522635459899902,
      "rewards/rejected": -13.457072257995605,
      "step": 4400
    },
    {
      "epoch": 2.8217600000000003,
      "grad_norm": 1.9513691663742065,
      "learning_rate": 1.891467411069492e-06,
      "logits/chosen": -14.227699279785156,
      "logits/rejected": -14.413698196411133,
      "logps/chosen": -165.0352325439453,
      "logps/rejected": -207.95175170898438,
      "loss": 1.2429,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -8.892181396484375,
      "rewards/margins": 4.185555934906006,
      "rewards/rejected": -13.077737808227539,
      "step": 4410
    },
    {
      "epoch": 2.82816,
      "grad_norm": 1.8202450275421143,
      "learning_rate": 1.7572831818097878e-06,
      "logits/chosen": -14.566442489624023,
      "logits/rejected": -14.041302680969238,
      "logps/chosen": -164.72781372070312,
      "logps/rejected": -210.28707885742188,
      "loss": 1.271,
      "rewards/accuracies": 0.9671875238418579,
      "rewards/chosen": -8.735881805419922,
      "rewards/margins": 4.367342948913574,
      "rewards/rejected": -13.103225708007812,
      "step": 4420
    },
    {
      "epoch": 2.8345599999999997,
      "grad_norm": 1.2045352458953857,
      "learning_rate": 1.6279931683853889e-06,
      "logits/chosen": -14.95686149597168,
      "logits/rejected": -14.96924877166748,
      "logps/chosen": -164.4827117919922,
      "logps/rejected": -214.2165985107422,
      "loss": 1.251,
      "rewards/accuracies": 0.965624988079071,
      "rewards/chosen": -8.935277938842773,
      "rewards/margins": 4.505336284637451,
      "rewards/rejected": -13.440614700317383,
      "step": 4430
    },
    {
      "epoch": 2.84096,
      "grad_norm": 1.4029048681259155,
      "learning_rate": 1.503603811713794e-06,
      "logits/chosen": -14.461207389831543,
      "logits/rejected": -14.5075101852417,
      "logps/chosen": -164.70407104492188,
      "logps/rejected": -207.9832305908203,
      "loss": 1.2921,
      "rewards/accuracies": 0.9593750238418579,
      "rewards/chosen": -8.960817337036133,
      "rewards/margins": 4.1994218826293945,
      "rewards/rejected": -13.160238265991211,
      "step": 4440
    },
    {
      "epoch": 2.84736,
      "grad_norm": 1.4142175912857056,
      "learning_rate": 1.3841213085735383e-06,
      "logits/chosen": -15.213488578796387,
      "logits/rejected": -15.099238395690918,
      "logps/chosen": -165.254150390625,
      "logps/rejected": -207.869140625,
      "loss": 1.2448,
      "rewards/accuracies": 0.956250011920929,
      "rewards/chosen": -8.927569389343262,
      "rewards/margins": 4.217569828033447,
      "rewards/rejected": -13.14513874053955,
      "step": 4450
    },
    {
      "epoch": 2.85376,
      "grad_norm": 1.0605708360671997,
      "learning_rate": 1.2695516112955275e-06,
      "logits/chosen": -14.912742614746094,
      "logits/rejected": -14.909980773925781,
      "logps/chosen": -165.52774047851562,
      "logps/rejected": -210.8725128173828,
      "loss": 1.2952,
      "rewards/accuracies": 0.96875,
      "rewards/chosen": -8.882487297058105,
      "rewards/margins": 4.2871994972229,
      "rewards/rejected": -13.169687271118164,
      "step": 4460
    },
    {
      "epoch": 2.86016,
      "grad_norm": 1.7058566808700562,
      "learning_rate": 1.159900427466476e-06,
      "logits/chosen": -14.563224792480469,
      "logits/rejected": -14.155171394348145,
      "logps/chosen": -163.8551483154297,
      "logps/rejected": -208.41842651367188,
      "loss": 1.2328,
      "rewards/accuracies": 0.973437488079071,
      "rewards/chosen": -8.858180046081543,
      "rewards/margins": 4.407573223114014,
      "rewards/rejected": -13.265752792358398,
      "step": 4470
    },
    {
      "epoch": 2.8665599999999998,
      "grad_norm": 1.4046971797943115,
      "learning_rate": 1.0551732196446008e-06,
      "logits/chosen": -14.48193359375,
      "logits/rejected": -14.467702865600586,
      "logps/chosen": -163.21856689453125,
      "logps/rejected": -206.1652069091797,
      "loss": 1.267,
      "rewards/accuracies": 0.957812488079071,
      "rewards/chosen": -8.803041458129883,
      "rewards/margins": 4.2303972244262695,
      "rewards/rejected": -13.033437728881836,
      "step": 4480
    },
    {
      "epoch": 2.87296,
      "grad_norm": 1.8356972932815552,
      "learning_rate": 9.553752050875054e-07,
      "logits/chosen": -14.5734281539917,
      "logits/rejected": -14.744829177856445,
      "logps/chosen": -163.4520263671875,
      "logps/rejected": -208.92709350585938,
      "loss": 1.2829,
      "rewards/accuracies": 0.9703124761581421,
      "rewards/chosen": -8.93796443939209,
      "rewards/margins": 4.296166896820068,
      "rewards/rejected": -13.234130859375,
      "step": 4490
    },
    {
      "epoch": 2.87936,
      "grad_norm": 1.6823476552963257,
      "learning_rate": 8.605113554921885e-07,
      "logits/chosen": -14.623011589050293,
      "logits/rejected": -14.43847942352295,
      "logps/chosen": -167.64688110351562,
      "logps/rejected": -211.09033203125,
      "loss": 1.2622,
      "rewards/accuracies": 0.9624999761581421,
      "rewards/chosen": -9.073270797729492,
      "rewards/margins": 4.252714157104492,
      "rewards/rejected": -13.3259859085083,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 4686,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
